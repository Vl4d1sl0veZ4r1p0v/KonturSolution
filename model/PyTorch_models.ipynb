{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch_models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f6bphNMkiVR",
        "outputId": "789045bb-a314-4762-8ad4-9f20e5f48fce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayDcp2W_k73e",
        "outputId": "991bf0d0-777e-40e3-d6a2-aa2b4f202873"
      },
      "source": [
        "!git clone https://github.com/raymondhs/pytorch-char-rnn-truecase.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-char-rnn-truecase'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 55 (delta 21), reused 51 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO7ADdcMfgaA"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "main_folder = Path(\"/content/drive/MyDrive/Kontur_task/to_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PagW5plvfe5D"
      },
      "source": [
        "# prepare data for test\n",
        "data = None\n",
        "with open(main_folder / \"input.txt\") as fin:\n",
        "  data = [line.strip() for line in fin.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG6wCj5jlACi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, [line.lower() for line in data],\n",
        "                                                    test_size=0.3, random_state=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4tABILRlAAd"
      },
      "source": [
        "with open(main_folder / \"test.txt\", \"w\") as y_test_fout, \\\n",
        "     open(main_folder / \"test.lower.txt\", \"w\") as X_test_fout:\n",
        "    for point in y_test:\n",
        "      print(point, file=y_test_fout)\n",
        "    for point in X_test:\n",
        "      print(point, file=X_test_fout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vR_w-SllAFZ",
        "outputId": "b14b9ac8-3b52-4569-f3a1-d09180fceafd"
      },
      "source": [
        "!python ./pytorch-char-rnn-truecase/train.py -data_dir \"/content/drive/MyDrive/Kontur_task/to_train\" -gpuid=0 -learning_rate=0.01 -batch_size=128 -max_epochs=10 -checkpoint_dir=\"/content/drive/MyDrive/Kontur_task/check\" -seq_length=359 -dropout=0.25 -num_layers=2 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "59757/63080 (epoch 9.473), train_loss = 0.65063965, time/batch = 0.0526s\n",
            "59758/63080 (epoch 9.473), train_loss = 0.65975654, time/batch = 0.0515s\n",
            "59759/63080 (epoch 9.474), train_loss = 0.65456998, time/batch = 0.0518s\n",
            "59760/63080 (epoch 9.474), train_loss = 0.63999265, time/batch = 0.0524s\n",
            "59761/63080 (epoch 9.474), train_loss = 0.64096397, time/batch = 0.0516s\n",
            "59762/63080 (epoch 9.474), train_loss = 0.65397960, time/batch = 0.0515s\n",
            "59763/63080 (epoch 9.474), train_loss = 0.65302271, time/batch = 0.0525s\n",
            "59764/63080 (epoch 9.474), train_loss = 0.63246161, time/batch = 0.0514s\n",
            "59765/63080 (epoch 9.474), train_loss = 0.64609748, time/batch = 0.0527s\n",
            "59766/63080 (epoch 9.475), train_loss = 0.65898025, time/batch = 0.0526s\n",
            "59767/63080 (epoch 9.475), train_loss = 0.65149951, time/batch = 0.0525s\n",
            "59768/63080 (epoch 9.475), train_loss = 0.62552148, time/batch = 0.0521s\n",
            "59769/63080 (epoch 9.475), train_loss = 0.66467953, time/batch = 0.0521s\n",
            "59770/63080 (epoch 9.475), train_loss = 0.65408838, time/batch = 0.0518s\n",
            "59771/63080 (epoch 9.475), train_loss = 0.64543146, time/batch = 0.0517s\n",
            "59772/63080 (epoch 9.476), train_loss = 0.66239297, time/batch = 0.0514s\n",
            "59773/63080 (epoch 9.476), train_loss = 0.64655793, time/batch = 0.0517s\n",
            "59774/63080 (epoch 9.476), train_loss = 0.65978211, time/batch = 0.0519s\n",
            "59775/63080 (epoch 9.476), train_loss = 0.65337819, time/batch = 0.0516s\n",
            "59776/63080 (epoch 9.476), train_loss = 0.65070820, time/batch = 0.0518s\n",
            "59777/63080 (epoch 9.476), train_loss = 0.63355434, time/batch = 0.0528s\n",
            "59778/63080 (epoch 9.477), train_loss = 0.66317016, time/batch = 0.0522s\n",
            "59779/63080 (epoch 9.477), train_loss = 0.64330757, time/batch = 0.0515s\n",
            "59780/63080 (epoch 9.477), train_loss = 0.64732152, time/batch = 0.0516s\n",
            "59781/63080 (epoch 9.477), train_loss = 0.67483270, time/batch = 0.0509s\n",
            "59782/63080 (epoch 9.477), train_loss = 0.63887310, time/batch = 0.0519s\n",
            "59783/63080 (epoch 9.477), train_loss = 0.61010206, time/batch = 0.0513s\n",
            "59784/63080 (epoch 9.477), train_loss = 0.63966489, time/batch = 0.0517s\n",
            "59785/63080 (epoch 9.478), train_loss = 0.66677332, time/batch = 0.0521s\n",
            "59786/63080 (epoch 9.478), train_loss = 0.66027093, time/batch = 0.0518s\n",
            "59787/63080 (epoch 9.478), train_loss = 0.64418262, time/batch = 0.0515s\n",
            "59788/63080 (epoch 9.478), train_loss = 0.66152668, time/batch = 0.0517s\n",
            "59789/63080 (epoch 9.478), train_loss = 0.65055758, time/batch = 0.0520s\n",
            "59790/63080 (epoch 9.478), train_loss = 0.66277242, time/batch = 0.0520s\n",
            "59791/63080 (epoch 9.479), train_loss = 0.64816278, time/batch = 0.0512s\n",
            "59792/63080 (epoch 9.479), train_loss = 0.67165446, time/batch = 0.0524s\n",
            "59793/63080 (epoch 9.479), train_loss = 0.66305512, time/batch = 0.0517s\n",
            "59794/63080 (epoch 9.479), train_loss = 0.66896790, time/batch = 0.0526s\n",
            "59795/63080 (epoch 9.479), train_loss = 0.65198433, time/batch = 0.0518s\n",
            "59796/63080 (epoch 9.479), train_loss = 0.63821387, time/batch = 0.0518s\n",
            "59797/63080 (epoch 9.480), train_loss = 0.65451825, time/batch = 0.0518s\n",
            "59798/63080 (epoch 9.480), train_loss = 0.66383374, time/batch = 0.0516s\n",
            "59799/63080 (epoch 9.480), train_loss = 0.64275503, time/batch = 0.0516s\n",
            "59800/63080 (epoch 9.480), train_loss = 0.68042916, time/batch = 0.0525s\n",
            "59801/63080 (epoch 9.480), train_loss = 0.67336285, time/batch = 0.0512s\n",
            "59802/63080 (epoch 9.480), train_loss = 0.67222410, time/batch = 0.0522s\n",
            "59803/63080 (epoch 9.481), train_loss = 0.64161438, time/batch = 0.0517s\n",
            "59804/63080 (epoch 9.481), train_loss = 0.65043724, time/batch = 0.0516s\n",
            "59805/63080 (epoch 9.481), train_loss = 0.66831332, time/batch = 0.0517s\n",
            "59806/63080 (epoch 9.481), train_loss = 0.66275358, time/batch = 0.0516s\n",
            "59807/63080 (epoch 9.481), train_loss = 0.66453344, time/batch = 0.0521s\n",
            "59808/63080 (epoch 9.481), train_loss = 0.66030359, time/batch = 0.0506s\n",
            "59809/63080 (epoch 9.481), train_loss = 0.66299045, time/batch = 0.0520s\n",
            "59810/63080 (epoch 9.482), train_loss = 0.64384156, time/batch = 0.0516s\n",
            "59811/63080 (epoch 9.482), train_loss = 0.64234626, time/batch = 0.0512s\n",
            "59812/63080 (epoch 9.482), train_loss = 0.62335706, time/batch = 0.0520s\n",
            "59813/63080 (epoch 9.482), train_loss = 0.63226765, time/batch = 0.0520s\n",
            "59814/63080 (epoch 9.482), train_loss = 0.65064818, time/batch = 0.0515s\n",
            "59815/63080 (epoch 9.482), train_loss = 0.64687777, time/batch = 0.0518s\n",
            "59816/63080 (epoch 9.483), train_loss = 0.65181166, time/batch = 0.0517s\n",
            "59817/63080 (epoch 9.483), train_loss = 0.65684003, time/batch = 0.0522s\n",
            "59818/63080 (epoch 9.483), train_loss = 0.63429016, time/batch = 0.0519s\n",
            "59819/63080 (epoch 9.483), train_loss = 0.63929403, time/batch = 0.0514s\n",
            "59820/63080 (epoch 9.483), train_loss = 0.65594572, time/batch = 0.0520s\n",
            "59821/63080 (epoch 9.483), train_loss = 0.66104454, time/batch = 0.0519s\n",
            "59822/63080 (epoch 9.484), train_loss = 0.64023376, time/batch = 0.0506s\n",
            "59823/63080 (epoch 9.484), train_loss = 0.63077778, time/batch = 0.0518s\n",
            "59824/63080 (epoch 9.484), train_loss = 0.64094788, time/batch = 0.0515s\n",
            "59825/63080 (epoch 9.484), train_loss = 0.62175810, time/batch = 0.0517s\n",
            "59826/63080 (epoch 9.484), train_loss = 0.62693435, time/batch = 0.0514s\n",
            "59827/63080 (epoch 9.484), train_loss = 0.66056073, time/batch = 0.0517s\n",
            "59828/63080 (epoch 9.484), train_loss = 0.64566803, time/batch = 0.0515s\n",
            "59829/63080 (epoch 9.485), train_loss = 0.65323091, time/batch = 0.0517s\n",
            "59830/63080 (epoch 9.485), train_loss = 0.64561766, time/batch = 0.0534s\n",
            "59831/63080 (epoch 9.485), train_loss = 0.65795434, time/batch = 0.0513s\n",
            "59832/63080 (epoch 9.485), train_loss = 0.68581933, time/batch = 0.0526s\n",
            "59833/63080 (epoch 9.485), train_loss = 0.64203084, time/batch = 0.0512s\n",
            "59834/63080 (epoch 9.485), train_loss = 0.65462911, time/batch = 0.0515s\n",
            "59835/63080 (epoch 9.486), train_loss = 0.64847648, time/batch = 0.0518s\n",
            "59836/63080 (epoch 9.486), train_loss = 0.65217197, time/batch = 0.0513s\n",
            "59837/63080 (epoch 9.486), train_loss = 0.62706608, time/batch = 0.0516s\n",
            "59838/63080 (epoch 9.486), train_loss = 0.66810006, time/batch = 0.0519s\n",
            "59839/63080 (epoch 9.486), train_loss = 0.63293147, time/batch = 0.0511s\n",
            "59840/63080 (epoch 9.486), train_loss = 0.66522241, time/batch = 0.0523s\n",
            "59841/63080 (epoch 9.487), train_loss = 0.66589260, time/batch = 0.0511s\n",
            "59842/63080 (epoch 9.487), train_loss = 0.65028167, time/batch = 0.0517s\n",
            "59843/63080 (epoch 9.487), train_loss = 0.65400690, time/batch = 0.0516s\n",
            "59844/63080 (epoch 9.487), train_loss = 0.62069845, time/batch = 0.0527s\n",
            "59845/63080 (epoch 9.487), train_loss = 0.61018366, time/batch = 0.0523s\n",
            "59846/63080 (epoch 9.487), train_loss = 0.62692982, time/batch = 0.0518s\n",
            "59847/63080 (epoch 9.487), train_loss = 0.66472614, time/batch = 0.0515s\n",
            "59848/63080 (epoch 9.488), train_loss = 0.64160234, time/batch = 0.0518s\n",
            "59849/63080 (epoch 9.488), train_loss = 0.63200665, time/batch = 0.0516s\n",
            "59850/63080 (epoch 9.488), train_loss = 0.63836986, time/batch = 0.0522s\n",
            "59851/63080 (epoch 9.488), train_loss = 0.64178592, time/batch = 0.0514s\n",
            "59852/63080 (epoch 9.488), train_loss = 0.65905797, time/batch = 0.0517s\n",
            "59853/63080 (epoch 9.488), train_loss = 0.63440537, time/batch = 0.0519s\n",
            "59854/63080 (epoch 9.489), train_loss = 0.65347379, time/batch = 0.0526s\n",
            "59855/63080 (epoch 9.489), train_loss = 0.65699273, time/batch = 0.0518s\n",
            "59856/63080 (epoch 9.489), train_loss = 0.63899845, time/batch = 0.0522s\n",
            "59857/63080 (epoch 9.489), train_loss = 0.66992491, time/batch = 0.0517s\n",
            "59858/63080 (epoch 9.489), train_loss = 0.66010290, time/batch = 0.0519s\n",
            "59859/63080 (epoch 9.489), train_loss = 0.64657664, time/batch = 0.0514s\n",
            "59860/63080 (epoch 9.490), train_loss = 0.64780015, time/batch = 0.0533s\n",
            "59861/63080 (epoch 9.490), train_loss = 0.64342594, time/batch = 0.0513s\n",
            "59862/63080 (epoch 9.490), train_loss = 0.64491677, time/batch = 0.0520s\n",
            "59863/63080 (epoch 9.490), train_loss = 0.63390750, time/batch = 0.0515s\n",
            "59864/63080 (epoch 9.490), train_loss = 0.65499735, time/batch = 0.0511s\n",
            "59865/63080 (epoch 9.490), train_loss = 0.66264218, time/batch = 0.0517s\n",
            "59866/63080 (epoch 9.490), train_loss = 0.65367919, time/batch = 0.0525s\n",
            "59867/63080 (epoch 9.491), train_loss = 0.67000484, time/batch = 0.0513s\n",
            "59868/63080 (epoch 9.491), train_loss = 0.65739506, time/batch = 0.0520s\n",
            "59869/63080 (epoch 9.491), train_loss = 0.66357338, time/batch = 0.0521s\n",
            "59870/63080 (epoch 9.491), train_loss = 0.69721264, time/batch = 0.0521s\n",
            "59871/63080 (epoch 9.491), train_loss = 0.67215800, time/batch = 0.0509s\n",
            "59872/63080 (epoch 9.491), train_loss = 0.66317725, time/batch = 0.0523s\n",
            "59873/63080 (epoch 9.492), train_loss = 0.68179417, time/batch = 0.0515s\n",
            "59874/63080 (epoch 9.492), train_loss = 0.66433769, time/batch = 0.0527s\n",
            "59875/63080 (epoch 9.492), train_loss = 0.66649532, time/batch = 0.0515s\n",
            "59876/63080 (epoch 9.492), train_loss = 0.64427698, time/batch = 0.0525s\n",
            "59877/63080 (epoch 9.492), train_loss = 0.65458566, time/batch = 0.0517s\n",
            "59878/63080 (epoch 9.492), train_loss = 0.65577489, time/batch = 0.0519s\n",
            "59879/63080 (epoch 9.493), train_loss = 0.65449768, time/batch = 0.0512s\n",
            "59880/63080 (epoch 9.493), train_loss = 0.64411861, time/batch = 0.0517s\n",
            "59881/63080 (epoch 9.493), train_loss = 0.63984555, time/batch = 0.0514s\n",
            "59882/63080 (epoch 9.493), train_loss = 0.63533074, time/batch = 0.0514s\n",
            "59883/63080 (epoch 9.493), train_loss = 0.64560872, time/batch = 0.0523s\n",
            "59884/63080 (epoch 9.493), train_loss = 0.64763725, time/batch = 0.0518s\n",
            "59885/63080 (epoch 9.494), train_loss = 0.66375190, time/batch = 0.0518s\n",
            "59886/63080 (epoch 9.494), train_loss = 0.67786509, time/batch = 0.0521s\n",
            "59887/63080 (epoch 9.494), train_loss = 0.67014033, time/batch = 0.0522s\n",
            "59888/63080 (epoch 9.494), train_loss = 0.64043838, time/batch = 0.0517s\n",
            "59889/63080 (epoch 9.494), train_loss = 0.66811240, time/batch = 0.0518s\n",
            "59890/63080 (epoch 9.494), train_loss = 0.65974873, time/batch = 0.0520s\n",
            "59891/63080 (epoch 9.494), train_loss = 0.63735312, time/batch = 0.0513s\n",
            "59892/63080 (epoch 9.495), train_loss = 0.62919366, time/batch = 0.0517s\n",
            "59893/63080 (epoch 9.495), train_loss = 0.65887666, time/batch = 0.0522s\n",
            "59894/63080 (epoch 9.495), train_loss = 0.69007891, time/batch = 0.0514s\n",
            "59895/63080 (epoch 9.495), train_loss = 0.67724830, time/batch = 0.0518s\n",
            "59896/63080 (epoch 9.495), train_loss = 0.65871060, time/batch = 0.0516s\n",
            "59897/63080 (epoch 9.495), train_loss = 0.66265017, time/batch = 0.0518s\n",
            "59898/63080 (epoch 9.496), train_loss = 0.64670849, time/batch = 0.0515s\n",
            "59899/63080 (epoch 9.496), train_loss = 0.67678607, time/batch = 0.0526s\n",
            "59900/63080 (epoch 9.496), train_loss = 0.66879839, time/batch = 0.0518s\n",
            "59901/63080 (epoch 9.496), train_loss = 0.66721505, time/batch = 0.0509s\n",
            "59902/63080 (epoch 9.496), train_loss = 0.66095865, time/batch = 0.0515s\n",
            "59903/63080 (epoch 9.496), train_loss = 0.65305787, time/batch = 0.0519s\n",
            "59904/63080 (epoch 9.497), train_loss = 0.65547854, time/batch = 0.0522s\n",
            "59905/63080 (epoch 9.497), train_loss = 0.67473781, time/batch = 0.0516s\n",
            "59906/63080 (epoch 9.497), train_loss = 0.67995346, time/batch = 0.0518s\n",
            "59907/63080 (epoch 9.497), train_loss = 0.66077751, time/batch = 0.0513s\n",
            "59908/63080 (epoch 9.497), train_loss = 0.66053039, time/batch = 0.0517s\n",
            "59909/63080 (epoch 9.497), train_loss = 0.65114868, time/batch = 0.0515s\n",
            "59910/63080 (epoch 9.497), train_loss = 0.65537113, time/batch = 0.0520s\n",
            "59911/63080 (epoch 9.498), train_loss = 0.64616817, time/batch = 0.0513s\n",
            "59912/63080 (epoch 9.498), train_loss = 0.67964327, time/batch = 0.0519s\n",
            "59913/63080 (epoch 9.498), train_loss = 0.64864123, time/batch = 0.0517s\n",
            "59914/63080 (epoch 9.498), train_loss = 0.64710903, time/batch = 0.0517s\n",
            "59915/63080 (epoch 9.498), train_loss = 0.66181779, time/batch = 0.0514s\n",
            "59916/63080 (epoch 9.498), train_loss = 0.66882682, time/batch = 0.0517s\n",
            "59917/63080 (epoch 9.499), train_loss = 0.64535129, time/batch = 0.0515s\n",
            "59918/63080 (epoch 9.499), train_loss = 0.64681774, time/batch = 0.0507s\n",
            "59919/63080 (epoch 9.499), train_loss = 0.64144737, time/batch = 0.0515s\n",
            "59920/63080 (epoch 9.499), train_loss = 0.66486645, time/batch = 0.0521s\n",
            "59921/63080 (epoch 9.499), train_loss = 0.67797017, time/batch = 0.0511s\n",
            "59922/63080 (epoch 9.499), train_loss = 0.64089179, time/batch = 0.0517s\n",
            "59923/63080 (epoch 9.500), train_loss = 0.66742665, time/batch = 0.0518s\n",
            "59924/63080 (epoch 9.500), train_loss = 0.67530537, time/batch = 0.0522s\n",
            "59925/63080 (epoch 9.500), train_loss = 0.65499032, time/batch = 0.0516s\n",
            "59926/63080 (epoch 9.500), train_loss = 0.64813387, time/batch = 0.0522s\n",
            "59927/63080 (epoch 9.500), train_loss = 0.66274709, time/batch = 0.0523s\n",
            "59928/63080 (epoch 9.500), train_loss = 0.65912139, time/batch = 0.0525s\n",
            "59929/63080 (epoch 9.500), train_loss = 0.65784407, time/batch = 0.0514s\n",
            "59930/63080 (epoch 9.501), train_loss = 0.66232324, time/batch = 0.0516s\n",
            "59931/63080 (epoch 9.501), train_loss = 0.64654624, time/batch = 0.0523s\n",
            "59932/63080 (epoch 9.501), train_loss = 0.66917086, time/batch = 0.0513s\n",
            "59933/63080 (epoch 9.501), train_loss = 0.67547154, time/batch = 0.0526s\n",
            "59934/63080 (epoch 9.501), train_loss = 0.66947734, time/batch = 0.0514s\n",
            "59935/63080 (epoch 9.501), train_loss = 0.67002964, time/batch = 0.0511s\n",
            "59936/63080 (epoch 9.502), train_loss = 0.67292851, time/batch = 0.0520s\n",
            "59937/63080 (epoch 9.502), train_loss = 0.66225684, time/batch = 0.0518s\n",
            "59938/63080 (epoch 9.502), train_loss = 0.65968955, time/batch = 0.0516s\n",
            "59939/63080 (epoch 9.502), train_loss = 0.66336036, time/batch = 0.0517s\n",
            "59940/63080 (epoch 9.502), train_loss = 0.66640830, time/batch = 0.0526s\n",
            "59941/63080 (epoch 9.502), train_loss = 0.65075940, time/batch = 0.0512s\n",
            "59942/63080 (epoch 9.503), train_loss = 0.68510705, time/batch = 0.0514s\n",
            "59943/63080 (epoch 9.503), train_loss = 0.68023467, time/batch = 0.0514s\n",
            "59944/63080 (epoch 9.503), train_loss = 0.66137791, time/batch = 0.0525s\n",
            "59945/63080 (epoch 9.503), train_loss = 0.67680901, time/batch = 0.0526s\n",
            "59946/63080 (epoch 9.503), train_loss = 0.66809970, time/batch = 0.0516s\n",
            "59947/63080 (epoch 9.503), train_loss = 0.65195745, time/batch = 0.0523s\n",
            "59948/63080 (epoch 9.503), train_loss = 0.65992486, time/batch = 0.0517s\n",
            "59949/63080 (epoch 9.504), train_loss = 0.67775601, time/batch = 0.0527s\n",
            "59950/63080 (epoch 9.504), train_loss = 0.68781233, time/batch = 0.0516s\n",
            "59951/63080 (epoch 9.504), train_loss = 0.68389791, time/batch = 0.0515s\n",
            "59952/63080 (epoch 9.504), train_loss = 0.67457509, time/batch = 0.0514s\n",
            "59953/63080 (epoch 9.504), train_loss = 0.67868263, time/batch = 0.0514s\n",
            "59954/63080 (epoch 9.504), train_loss = 0.66144586, time/batch = 0.0512s\n",
            "59955/63080 (epoch 9.505), train_loss = 0.65047902, time/batch = 0.0524s\n",
            "59956/63080 (epoch 9.505), train_loss = 0.66209853, time/batch = 0.0514s\n",
            "59957/63080 (epoch 9.505), train_loss = 0.65462846, time/batch = 0.0522s\n",
            "59958/63080 (epoch 9.505), train_loss = 0.70165807, time/batch = 0.0516s\n",
            "59959/63080 (epoch 9.505), train_loss = 0.66782647, time/batch = 0.0524s\n",
            "59960/63080 (epoch 9.505), train_loss = 0.67266512, time/batch = 0.0517s\n",
            "59961/63080 (epoch 9.506), train_loss = 0.64710307, time/batch = 0.0510s\n",
            "59962/63080 (epoch 9.506), train_loss = 0.66717350, time/batch = 0.0515s\n",
            "59963/63080 (epoch 9.506), train_loss = 0.67849505, time/batch = 0.0531s\n",
            "59964/63080 (epoch 9.506), train_loss = 0.66226274, time/batch = 0.0516s\n",
            "59965/63080 (epoch 9.506), train_loss = 0.66840369, time/batch = 0.0523s\n",
            "59966/63080 (epoch 9.506), train_loss = 0.66820973, time/batch = 0.0516s\n",
            "59967/63080 (epoch 9.506), train_loss = 0.66514993, time/batch = 0.0524s\n",
            "59968/63080 (epoch 9.507), train_loss = 0.65646958, time/batch = 0.0526s\n",
            "59969/63080 (epoch 9.507), train_loss = 0.63139617, time/batch = 0.0518s\n",
            "59970/63080 (epoch 9.507), train_loss = 0.68781471, time/batch = 0.0521s\n",
            "59971/63080 (epoch 9.507), train_loss = 0.65680307, time/batch = 0.0517s\n",
            "59972/63080 (epoch 9.507), train_loss = 0.67729205, time/batch = 0.0526s\n",
            "59973/63080 (epoch 9.507), train_loss = 0.67368585, time/batch = 0.0525s\n",
            "59974/63080 (epoch 9.508), train_loss = 0.64032483, time/batch = 0.0516s\n",
            "59975/63080 (epoch 9.508), train_loss = 0.65147364, time/batch = 0.0518s\n",
            "59976/63080 (epoch 9.508), train_loss = 0.66672784, time/batch = 0.0522s\n",
            "59977/63080 (epoch 9.508), train_loss = 0.67525870, time/batch = 0.0518s\n",
            "59978/63080 (epoch 9.508), train_loss = 0.67186654, time/batch = 0.0520s\n",
            "59979/63080 (epoch 9.508), train_loss = 0.65296161, time/batch = 0.0522s\n",
            "59980/63080 (epoch 9.509), train_loss = 0.68320274, time/batch = 0.0522s\n",
            "59981/63080 (epoch 9.509), train_loss = 0.66977471, time/batch = 0.0513s\n",
            "59982/63080 (epoch 9.509), train_loss = 0.67041653, time/batch = 0.0519s\n",
            "59983/63080 (epoch 9.509), train_loss = 0.65636486, time/batch = 0.0512s\n",
            "59984/63080 (epoch 9.509), train_loss = 0.66590500, time/batch = 0.0520s\n",
            "59985/63080 (epoch 9.509), train_loss = 0.67241859, time/batch = 0.0531s\n",
            "59986/63080 (epoch 9.510), train_loss = 0.68335152, time/batch = 0.0519s\n",
            "59987/63080 (epoch 9.510), train_loss = 0.66359925, time/batch = 0.0523s\n",
            "59988/63080 (epoch 9.510), train_loss = 0.67324930, time/batch = 0.0514s\n",
            "59989/63080 (epoch 9.510), train_loss = 0.65514153, time/batch = 0.0526s\n",
            "59990/63080 (epoch 9.510), train_loss = 0.65579617, time/batch = 0.0520s\n",
            "59991/63080 (epoch 9.510), train_loss = 0.66647756, time/batch = 0.0537s\n",
            "59992/63080 (epoch 9.510), train_loss = 0.68049729, time/batch = 0.0517s\n",
            "59993/63080 (epoch 9.511), train_loss = 0.67733324, time/batch = 0.0524s\n",
            "59994/63080 (epoch 9.511), train_loss = 0.64807922, time/batch = 0.0518s\n",
            "59995/63080 (epoch 9.511), train_loss = 0.65485632, time/batch = 0.0528s\n",
            "59996/63080 (epoch 9.511), train_loss = 0.66063511, time/batch = 0.0517s\n",
            "59997/63080 (epoch 9.511), train_loss = 0.66644132, time/batch = 0.0520s\n",
            "59998/63080 (epoch 9.511), train_loss = 0.66977894, time/batch = 0.0525s\n",
            "59999/63080 (epoch 9.512), train_loss = 0.67440301, time/batch = 0.0517s\n",
            "evaluating loss over split index 1\n",
            "1/333...\n",
            "2/333...\n",
            "3/333...\n",
            "4/333...\n",
            "5/333...\n",
            "6/333...\n",
            "7/333...\n",
            "8/333...\n",
            "9/333...\n",
            "10/333...\n",
            "11/333...\n",
            "12/333...\n",
            "13/333...\n",
            "14/333...\n",
            "15/333...\n",
            "16/333...\n",
            "17/333...\n",
            "18/333...\n",
            "19/333...\n",
            "20/333...\n",
            "21/333...\n",
            "22/333...\n",
            "23/333...\n",
            "24/333...\n",
            "25/333...\n",
            "26/333...\n",
            "27/333...\n",
            "28/333...\n",
            "29/333...\n",
            "30/333...\n",
            "31/333...\n",
            "32/333...\n",
            "33/333...\n",
            "34/333...\n",
            "35/333...\n",
            "36/333...\n",
            "37/333...\n",
            "38/333...\n",
            "39/333...\n",
            "40/333...\n",
            "41/333...\n",
            "42/333...\n",
            "43/333...\n",
            "44/333...\n",
            "45/333...\n",
            "46/333...\n",
            "47/333...\n",
            "48/333...\n",
            "49/333...\n",
            "50/333...\n",
            "51/333...\n",
            "52/333...\n",
            "53/333...\n",
            "54/333...\n",
            "55/333...\n",
            "56/333...\n",
            "57/333...\n",
            "58/333...\n",
            "59/333...\n",
            "60/333...\n",
            "61/333...\n",
            "62/333...\n",
            "63/333...\n",
            "64/333...\n",
            "65/333...\n",
            "66/333...\n",
            "67/333...\n",
            "68/333...\n",
            "69/333...\n",
            "70/333...\n",
            "71/333...\n",
            "72/333...\n",
            "73/333...\n",
            "74/333...\n",
            "75/333...\n",
            "76/333...\n",
            "77/333...\n",
            "78/333...\n",
            "79/333...\n",
            "80/333...\n",
            "81/333...\n",
            "82/333...\n",
            "83/333...\n",
            "84/333...\n",
            "85/333...\n",
            "86/333...\n",
            "87/333...\n",
            "88/333...\n",
            "89/333...\n",
            "90/333...\n",
            "91/333...\n",
            "92/333...\n",
            "93/333...\n",
            "94/333...\n",
            "95/333...\n",
            "96/333...\n",
            "97/333...\n",
            "98/333...\n",
            "99/333...\n",
            "100/333...\n",
            "101/333...\n",
            "102/333...\n",
            "103/333...\n",
            "104/333...\n",
            "105/333...\n",
            "106/333...\n",
            "107/333...\n",
            "108/333...\n",
            "109/333...\n",
            "110/333...\n",
            "111/333...\n",
            "112/333...\n",
            "113/333...\n",
            "114/333...\n",
            "115/333...\n",
            "116/333...\n",
            "117/333...\n",
            "118/333...\n",
            "119/333...\n",
            "120/333...\n",
            "121/333...\n",
            "122/333...\n",
            "123/333...\n",
            "124/333...\n",
            "125/333...\n",
            "126/333...\n",
            "127/333...\n",
            "128/333...\n",
            "129/333...\n",
            "130/333...\n",
            "131/333...\n",
            "132/333...\n",
            "133/333...\n",
            "134/333...\n",
            "135/333...\n",
            "136/333...\n",
            "137/333...\n",
            "138/333...\n",
            "139/333...\n",
            "140/333...\n",
            "141/333...\n",
            "142/333...\n",
            "143/333...\n",
            "144/333...\n",
            "145/333...\n",
            "146/333...\n",
            "147/333...\n",
            "148/333...\n",
            "149/333...\n",
            "150/333...\n",
            "151/333...\n",
            "152/333...\n",
            "153/333...\n",
            "154/333...\n",
            "155/333...\n",
            "156/333...\n",
            "157/333...\n",
            "158/333...\n",
            "159/333...\n",
            "160/333...\n",
            "161/333...\n",
            "162/333...\n",
            "163/333...\n",
            "164/333...\n",
            "165/333...\n",
            "166/333...\n",
            "167/333...\n",
            "168/333...\n",
            "169/333...\n",
            "170/333...\n",
            "171/333...\n",
            "172/333...\n",
            "173/333...\n",
            "174/333...\n",
            "175/333...\n",
            "176/333...\n",
            "177/333...\n",
            "178/333...\n",
            "179/333...\n",
            "180/333...\n",
            "181/333...\n",
            "182/333...\n",
            "183/333...\n",
            "184/333...\n",
            "185/333...\n",
            "186/333...\n",
            "187/333...\n",
            "188/333...\n",
            "189/333...\n",
            "190/333...\n",
            "191/333...\n",
            "192/333...\n",
            "193/333...\n",
            "194/333...\n",
            "195/333...\n",
            "196/333...\n",
            "197/333...\n",
            "198/333...\n",
            "199/333...\n",
            "200/333...\n",
            "201/333...\n",
            "202/333...\n",
            "203/333...\n",
            "204/333...\n",
            "205/333...\n",
            "206/333...\n",
            "207/333...\n",
            "208/333...\n",
            "209/333...\n",
            "210/333...\n",
            "211/333...\n",
            "212/333...\n",
            "213/333...\n",
            "214/333...\n",
            "215/333...\n",
            "216/333...\n",
            "217/333...\n",
            "218/333...\n",
            "219/333...\n",
            "220/333...\n",
            "221/333...\n",
            "222/333...\n",
            "223/333...\n",
            "224/333...\n",
            "225/333...\n",
            "226/333...\n",
            "227/333...\n",
            "228/333...\n",
            "229/333...\n",
            "230/333...\n",
            "231/333...\n",
            "232/333...\n",
            "233/333...\n",
            "234/333...\n",
            "235/333...\n",
            "236/333...\n",
            "237/333...\n",
            "238/333...\n",
            "239/333...\n",
            "240/333...\n",
            "241/333...\n",
            "242/333...\n",
            "243/333...\n",
            "244/333...\n",
            "245/333...\n",
            "246/333...\n",
            "247/333...\n",
            "248/333...\n",
            "249/333...\n",
            "250/333...\n",
            "251/333...\n",
            "252/333...\n",
            "253/333...\n",
            "254/333...\n",
            "255/333...\n",
            "256/333...\n",
            "257/333...\n",
            "258/333...\n",
            "259/333...\n",
            "260/333...\n",
            "261/333...\n",
            "262/333...\n",
            "263/333...\n",
            "264/333...\n",
            "265/333...\n",
            "266/333...\n",
            "267/333...\n",
            "268/333...\n",
            "269/333...\n",
            "270/333...\n",
            "271/333...\n",
            "272/333...\n",
            "273/333...\n",
            "274/333...\n",
            "275/333...\n",
            "276/333...\n",
            "277/333...\n",
            "278/333...\n",
            "279/333...\n",
            "280/333...\n",
            "281/333...\n",
            "282/333...\n",
            "283/333...\n",
            "284/333...\n",
            "285/333...\n",
            "286/333...\n",
            "287/333...\n",
            "288/333...\n",
            "289/333...\n",
            "290/333...\n",
            "291/333...\n",
            "292/333...\n",
            "293/333...\n",
            "294/333...\n",
            "295/333...\n",
            "296/333...\n",
            "297/333...\n",
            "298/333...\n",
            "299/333...\n",
            "300/333...\n",
            "301/333...\n",
            "302/333...\n",
            "303/333...\n",
            "304/333...\n",
            "305/333...\n",
            "306/333...\n",
            "307/333...\n",
            "308/333...\n",
            "309/333...\n",
            "310/333...\n",
            "311/333...\n",
            "312/333...\n",
            "313/333...\n",
            "314/333...\n",
            "315/333...\n",
            "316/333...\n",
            "317/333...\n",
            "318/333...\n",
            "319/333...\n",
            "320/333...\n",
            "321/333...\n",
            "322/333...\n",
            "323/333...\n",
            "324/333...\n",
            "325/333...\n",
            "326/333...\n",
            "327/333...\n",
            "328/333...\n",
            "329/333...\n",
            "330/333...\n",
            "331/333...\n",
            "332/333...\n",
            "333/333...\n",
            "saving checkpoint to /content/drive/MyDrive/Kontur_task/check/lm_lstm_epoch9.51_0.6116.pt\n",
            "60000/63080 (epoch 9.512), train_loss = 0.68162960, time/batch = 0.0518s\n",
            "60001/63080 (epoch 9.512), train_loss = 0.66728836, time/batch = 0.0607s\n",
            "60002/63080 (epoch 9.512), train_loss = 0.67862946, time/batch = 0.0573s\n",
            "60003/63080 (epoch 9.512), train_loss = 0.67430872, time/batch = 0.0585s\n",
            "60004/63080 (epoch 9.512), train_loss = 0.67499787, time/batch = 0.0555s\n",
            "60005/63080 (epoch 9.513), train_loss = 0.65711153, time/batch = 0.0544s\n",
            "60006/63080 (epoch 9.513), train_loss = 0.68941718, time/batch = 0.0529s\n",
            "60007/63080 (epoch 9.513), train_loss = 0.67611206, time/batch = 0.0526s\n",
            "60008/63080 (epoch 9.513), train_loss = 0.69290799, time/batch = 0.0526s\n",
            "60009/63080 (epoch 9.513), train_loss = 0.70382845, time/batch = 0.0523s\n",
            "60010/63080 (epoch 9.513), train_loss = 0.66065466, time/batch = 0.0526s\n",
            "60011/63080 (epoch 9.513), train_loss = 0.67324322, time/batch = 0.0525s\n",
            "60012/63080 (epoch 9.514), train_loss = 0.66406035, time/batch = 0.0523s\n",
            "60013/63080 (epoch 9.514), train_loss = 0.68026888, time/batch = 0.0525s\n",
            "60014/63080 (epoch 9.514), train_loss = 0.66721851, time/batch = 0.0528s\n",
            "60015/63080 (epoch 9.514), train_loss = 0.66597003, time/batch = 0.0525s\n",
            "60016/63080 (epoch 9.514), train_loss = 0.64176065, time/batch = 0.0527s\n",
            "60017/63080 (epoch 9.514), train_loss = 0.65036225, time/batch = 0.0527s\n",
            "60018/63080 (epoch 9.515), train_loss = 0.65536034, time/batch = 0.0525s\n",
            "60019/63080 (epoch 9.515), train_loss = 0.67639804, time/batch = 0.0525s\n",
            "60020/63080 (epoch 9.515), train_loss = 0.67474204, time/batch = 0.0527s\n",
            "60021/63080 (epoch 9.515), train_loss = 0.68557304, time/batch = 0.0526s\n",
            "60022/63080 (epoch 9.515), train_loss = 0.68465632, time/batch = 0.0524s\n",
            "60023/63080 (epoch 9.515), train_loss = 0.66543782, time/batch = 0.0539s\n",
            "60024/63080 (epoch 9.516), train_loss = 0.66270590, time/batch = 0.0528s\n",
            "60025/63080 (epoch 9.516), train_loss = 0.64948803, time/batch = 0.0525s\n",
            "60026/63080 (epoch 9.516), train_loss = 0.63723814, time/batch = 0.0536s\n",
            "60027/63080 (epoch 9.516), train_loss = 0.66855454, time/batch = 0.0528s\n",
            "60028/63080 (epoch 9.516), train_loss = 0.67042214, time/batch = 0.0529s\n",
            "60029/63080 (epoch 9.516), train_loss = 0.69119936, time/batch = 0.0523s\n",
            "60030/63080 (epoch 9.516), train_loss = 0.66816926, time/batch = 0.0530s\n",
            "60031/63080 (epoch 9.517), train_loss = 0.67781538, time/batch = 0.0521s\n",
            "60032/63080 (epoch 9.517), train_loss = 0.68728483, time/batch = 0.0530s\n",
            "60033/63080 (epoch 9.517), train_loss = 0.67937553, time/batch = 0.0526s\n",
            "60034/63080 (epoch 9.517), train_loss = 0.67286164, time/batch = 0.0524s\n",
            "60035/63080 (epoch 9.517), train_loss = 0.66982806, time/batch = 0.0525s\n",
            "60036/63080 (epoch 9.517), train_loss = 0.65795022, time/batch = 0.0527s\n",
            "60037/63080 (epoch 9.518), train_loss = 0.69012469, time/batch = 0.0524s\n",
            "60038/63080 (epoch 9.518), train_loss = 0.69326210, time/batch = 0.0521s\n",
            "60039/63080 (epoch 9.518), train_loss = 0.66383111, time/batch = 0.0523s\n",
            "60040/63080 (epoch 9.518), train_loss = 0.65506172, time/batch = 0.0525s\n",
            "60041/63080 (epoch 9.518), train_loss = 0.67030454, time/batch = 0.0526s\n",
            "60042/63080 (epoch 9.518), train_loss = 0.67181253, time/batch = 0.0528s\n",
            "60043/63080 (epoch 9.519), train_loss = 0.67865872, time/batch = 0.0534s\n",
            "60044/63080 (epoch 9.519), train_loss = 0.65071839, time/batch = 0.0526s\n",
            "60045/63080 (epoch 9.519), train_loss = 0.67110395, time/batch = 0.0530s\n",
            "60046/63080 (epoch 9.519), train_loss = 0.66338682, time/batch = 0.0527s\n",
            "60047/63080 (epoch 9.519), train_loss = 0.68695384, time/batch = 0.0527s\n",
            "60048/63080 (epoch 9.519), train_loss = 0.66525471, time/batch = 0.0524s\n",
            "60049/63080 (epoch 9.519), train_loss = 0.65570742, time/batch = 0.0527s\n",
            "60050/63080 (epoch 9.520), train_loss = 0.66812897, time/batch = 0.0527s\n",
            "60051/63080 (epoch 9.520), train_loss = 0.67093897, time/batch = 0.0527s\n",
            "60052/63080 (epoch 9.520), train_loss = 0.67386454, time/batch = 0.0526s\n",
            "60053/63080 (epoch 9.520), train_loss = 0.64824015, time/batch = 0.0544s\n",
            "60054/63080 (epoch 9.520), train_loss = 0.66605735, time/batch = 0.0527s\n",
            "60055/63080 (epoch 9.520), train_loss = 0.66794699, time/batch = 0.0526s\n",
            "60056/63080 (epoch 9.521), train_loss = 0.67034292, time/batch = 0.0524s\n",
            "60057/63080 (epoch 9.521), train_loss = 0.66925913, time/batch = 0.0533s\n",
            "60058/63080 (epoch 9.521), train_loss = 0.66803700, time/batch = 0.0529s\n",
            "60059/63080 (epoch 9.521), train_loss = 0.65555596, time/batch = 0.0526s\n",
            "60060/63080 (epoch 9.521), train_loss = 0.66689521, time/batch = 0.0536s\n",
            "60061/63080 (epoch 9.521), train_loss = 0.65631229, time/batch = 0.0526s\n",
            "60062/63080 (epoch 9.522), train_loss = 0.63602376, time/batch = 0.0528s\n",
            "60063/63080 (epoch 9.522), train_loss = 0.66793066, time/batch = 0.0527s\n",
            "60064/63080 (epoch 9.522), train_loss = 0.65376568, time/batch = 0.0529s\n",
            "60065/63080 (epoch 9.522), train_loss = 0.66757077, time/batch = 0.0526s\n",
            "60066/63080 (epoch 9.522), train_loss = 0.68170309, time/batch = 0.0529s\n",
            "60067/63080 (epoch 9.522), train_loss = 0.65471250, time/batch = 0.0527s\n",
            "60068/63080 (epoch 9.523), train_loss = 0.67042601, time/batch = 0.0526s\n",
            "60069/63080 (epoch 9.523), train_loss = 0.67097145, time/batch = 0.0536s\n",
            "60070/63080 (epoch 9.523), train_loss = 0.67119288, time/batch = 0.0528s\n",
            "60071/63080 (epoch 9.523), train_loss = 0.64169246, time/batch = 0.0525s\n",
            "60072/63080 (epoch 9.523), train_loss = 0.65634382, time/batch = 0.0533s\n",
            "60073/63080 (epoch 9.523), train_loss = 0.65664333, time/batch = 0.0529s\n",
            "60074/63080 (epoch 9.523), train_loss = 0.67836171, time/batch = 0.0528s\n",
            "60075/63080 (epoch 9.524), train_loss = 0.67872077, time/batch = 0.0527s\n",
            "60076/63080 (epoch 9.524), train_loss = 0.66365886, time/batch = 0.0524s\n",
            "60077/63080 (epoch 9.524), train_loss = 0.64351994, time/batch = 0.0521s\n",
            "60078/63080 (epoch 9.524), train_loss = 0.66827476, time/batch = 0.0519s\n",
            "60079/63080 (epoch 9.524), train_loss = 0.67174810, time/batch = 0.0530s\n",
            "60080/63080 (epoch 9.524), train_loss = 0.66120148, time/batch = 0.0520s\n",
            "60081/63080 (epoch 9.525), train_loss = 0.64882284, time/batch = 0.0524s\n",
            "60082/63080 (epoch 9.525), train_loss = 0.67171967, time/batch = 0.0529s\n",
            "60083/63080 (epoch 9.525), train_loss = 0.63890582, time/batch = 0.0538s\n",
            "60084/63080 (epoch 9.525), train_loss = 0.66225791, time/batch = 0.0527s\n",
            "60085/63080 (epoch 9.525), train_loss = 0.69272101, time/batch = 0.0530s\n",
            "60086/63080 (epoch 9.525), train_loss = 0.67107171, time/batch = 0.0526s\n",
            "60087/63080 (epoch 9.526), train_loss = 0.65624940, time/batch = 0.0527s\n",
            "60088/63080 (epoch 9.526), train_loss = 0.68431342, time/batch = 0.0528s\n",
            "60089/63080 (epoch 9.526), train_loss = 0.67826420, time/batch = 0.0524s\n",
            "60090/63080 (epoch 9.526), train_loss = 0.68043083, time/batch = 0.0528s\n",
            "60091/63080 (epoch 9.526), train_loss = 0.63981932, time/batch = 0.0534s\n",
            "60092/63080 (epoch 9.526), train_loss = 0.68035191, time/batch = 0.0547s\n",
            "60093/63080 (epoch 9.526), train_loss = 0.68909788, time/batch = 0.0531s\n",
            "60094/63080 (epoch 9.527), train_loss = 0.66956413, time/batch = 0.0527s\n",
            "60095/63080 (epoch 9.527), train_loss = 0.66519618, time/batch = 0.0525s\n",
            "60096/63080 (epoch 9.527), train_loss = 0.67912996, time/batch = 0.0524s\n",
            "60097/63080 (epoch 9.527), train_loss = 0.63209552, time/batch = 0.0539s\n",
            "60098/63080 (epoch 9.527), train_loss = 0.68058056, time/batch = 0.0530s\n",
            "60099/63080 (epoch 9.527), train_loss = 0.67888749, time/batch = 0.0525s\n",
            "60100/63080 (epoch 9.528), train_loss = 0.65597457, time/batch = 0.0536s\n",
            "60101/63080 (epoch 9.528), train_loss = 0.66356707, time/batch = 0.0522s\n",
            "60102/63080 (epoch 9.528), train_loss = 0.64586723, time/batch = 0.0542s\n",
            "60103/63080 (epoch 9.528), train_loss = 0.63386983, time/batch = 0.0526s\n",
            "60104/63080 (epoch 9.528), train_loss = 0.64431524, time/batch = 0.0534s\n",
            "60105/63080 (epoch 9.528), train_loss = 0.63255203, time/batch = 0.0527s\n",
            "60106/63080 (epoch 9.529), train_loss = 0.64518780, time/batch = 0.0527s\n",
            "60107/63080 (epoch 9.529), train_loss = 0.64606434, time/batch = 0.0526s\n",
            "60108/63080 (epoch 9.529), train_loss = 0.64621776, time/batch = 0.0523s\n",
            "60109/63080 (epoch 9.529), train_loss = 0.67209387, time/batch = 0.0524s\n",
            "60110/63080 (epoch 9.529), train_loss = 0.64620501, time/batch = 0.0528s\n",
            "60111/63080 (epoch 9.529), train_loss = 0.65576237, time/batch = 0.0522s\n",
            "60112/63080 (epoch 9.529), train_loss = 0.65346515, time/batch = 0.0526s\n",
            "60113/63080 (epoch 9.530), train_loss = 0.66467917, time/batch = 0.0526s\n",
            "60114/63080 (epoch 9.530), train_loss = 0.66539168, time/batch = 0.0528s\n",
            "60115/63080 (epoch 9.530), train_loss = 0.64806485, time/batch = 0.0526s\n",
            "60116/63080 (epoch 9.530), train_loss = 0.67754364, time/batch = 0.0525s\n",
            "60117/63080 (epoch 9.530), train_loss = 0.67301232, time/batch = 0.0526s\n",
            "60118/63080 (epoch 9.530), train_loss = 0.66553968, time/batch = 0.0519s\n",
            "60119/63080 (epoch 9.531), train_loss = 0.65374929, time/batch = 0.0528s\n",
            "60120/63080 (epoch 9.531), train_loss = 0.66418147, time/batch = 0.0525s\n",
            "60121/63080 (epoch 9.531), train_loss = 0.65475976, time/batch = 0.0530s\n",
            "60122/63080 (epoch 9.531), train_loss = 0.64060432, time/batch = 0.0525s\n",
            "60123/63080 (epoch 9.531), train_loss = 0.66600764, time/batch = 0.0529s\n",
            "60124/63080 (epoch 9.531), train_loss = 0.65383488, time/batch = 0.0529s\n",
            "60125/63080 (epoch 9.532), train_loss = 0.65999901, time/batch = 0.0529s\n",
            "60126/63080 (epoch 9.532), train_loss = 0.65398079, time/batch = 0.0526s\n",
            "60127/63080 (epoch 9.532), train_loss = 0.67443842, time/batch = 0.0529s\n",
            "60128/63080 (epoch 9.532), train_loss = 0.66251934, time/batch = 0.0526s\n",
            "60129/63080 (epoch 9.532), train_loss = 0.69412404, time/batch = 0.0526s\n",
            "60130/63080 (epoch 9.532), train_loss = 0.65052652, time/batch = 0.0527s\n",
            "60131/63080 (epoch 9.532), train_loss = 0.68333548, time/batch = 0.0523s\n",
            "60132/63080 (epoch 9.533), train_loss = 0.69206512, time/batch = 0.0522s\n",
            "60133/63080 (epoch 9.533), train_loss = 0.65774423, time/batch = 0.0529s\n",
            "60134/63080 (epoch 9.533), train_loss = 0.67392451, time/batch = 0.0525s\n",
            "60135/63080 (epoch 9.533), train_loss = 0.64735687, time/batch = 0.0529s\n",
            "60136/63080 (epoch 9.533), train_loss = 0.66886681, time/batch = 0.0522s\n",
            "60137/63080 (epoch 9.533), train_loss = 0.67355102, time/batch = 0.0543s\n",
            "60138/63080 (epoch 9.534), train_loss = 0.66814184, time/batch = 0.0523s\n",
            "60139/63080 (epoch 9.534), train_loss = 0.68680924, time/batch = 0.0535s\n",
            "60140/63080 (epoch 9.534), train_loss = 0.66913855, time/batch = 0.0527s\n",
            "60141/63080 (epoch 9.534), train_loss = 0.69142538, time/batch = 0.0524s\n",
            "60142/63080 (epoch 9.534), train_loss = 0.63641125, time/batch = 0.0532s\n",
            "60143/63080 (epoch 9.534), train_loss = 0.64273828, time/batch = 0.0523s\n",
            "60144/63080 (epoch 9.535), train_loss = 0.66356575, time/batch = 0.0525s\n",
            "60145/63080 (epoch 9.535), train_loss = 0.68350333, time/batch = 0.0528s\n",
            "60146/63080 (epoch 9.535), train_loss = 0.65316868, time/batch = 0.0525s\n",
            "60147/63080 (epoch 9.535), train_loss = 0.68016118, time/batch = 0.0522s\n",
            "60148/63080 (epoch 9.535), train_loss = 0.66162473, time/batch = 0.0524s\n",
            "60149/63080 (epoch 9.535), train_loss = 0.67362434, time/batch = 0.0528s\n",
            "60150/63080 (epoch 9.536), train_loss = 0.64658117, time/batch = 0.0526s\n",
            "60151/63080 (epoch 9.536), train_loss = 0.67590016, time/batch = 0.0528s\n",
            "60152/63080 (epoch 9.536), train_loss = 0.67405385, time/batch = 0.0521s\n",
            "60153/63080 (epoch 9.536), train_loss = 0.67687768, time/batch = 0.0526s\n",
            "60154/63080 (epoch 9.536), train_loss = 0.67388761, time/batch = 0.0525s\n",
            "60155/63080 (epoch 9.536), train_loss = 0.65795434, time/batch = 0.0530s\n",
            "60156/63080 (epoch 9.536), train_loss = 0.67694342, time/batch = 0.0543s\n",
            "60157/63080 (epoch 9.537), train_loss = 0.64292222, time/batch = 0.0523s\n",
            "60158/63080 (epoch 9.537), train_loss = 0.65493715, time/batch = 0.0532s\n",
            "60159/63080 (epoch 9.537), train_loss = 0.65141165, time/batch = 0.0527s\n",
            "60160/63080 (epoch 9.537), train_loss = 0.67416418, time/batch = 0.0533s\n",
            "60161/63080 (epoch 9.537), train_loss = 0.65526968, time/batch = 0.0526s\n",
            "60162/63080 (epoch 9.537), train_loss = 0.65622813, time/batch = 0.0523s\n",
            "60163/63080 (epoch 9.538), train_loss = 0.66910732, time/batch = 0.0528s\n",
            "60164/63080 (epoch 9.538), train_loss = 0.65603995, time/batch = 0.0525s\n",
            "60165/63080 (epoch 9.538), train_loss = 0.65679985, time/batch = 0.0524s\n",
            "60166/63080 (epoch 9.538), train_loss = 0.65889692, time/batch = 0.0525s\n",
            "60167/63080 (epoch 9.538), train_loss = 0.66889083, time/batch = 0.0523s\n",
            "60168/63080 (epoch 9.538), train_loss = 0.64778441, time/batch = 0.0528s\n",
            "60169/63080 (epoch 9.539), train_loss = 0.63592702, time/batch = 0.0523s\n",
            "60170/63080 (epoch 9.539), train_loss = 0.66710603, time/batch = 0.0531s\n",
            "60171/63080 (epoch 9.539), train_loss = 0.64504212, time/batch = 0.0520s\n",
            "60172/63080 (epoch 9.539), train_loss = 0.65951723, time/batch = 0.0524s\n",
            "60173/63080 (epoch 9.539), train_loss = 0.66752881, time/batch = 0.0524s\n",
            "60174/63080 (epoch 9.539), train_loss = 0.67884070, time/batch = 0.0524s\n",
            "60175/63080 (epoch 9.539), train_loss = 0.63310564, time/batch = 0.0525s\n",
            "60176/63080 (epoch 9.540), train_loss = 0.64338261, time/batch = 0.0525s\n",
            "60177/63080 (epoch 9.540), train_loss = 0.63775140, time/batch = 0.0519s\n",
            "60178/63080 (epoch 9.540), train_loss = 0.66613483, time/batch = 0.0525s\n",
            "60179/63080 (epoch 9.540), train_loss = 0.66605270, time/batch = 0.0523s\n",
            "60180/63080 (epoch 9.540), train_loss = 0.67618322, time/batch = 0.0530s\n",
            "60181/63080 (epoch 9.540), train_loss = 0.68117136, time/batch = 0.0527s\n",
            "60182/63080 (epoch 9.541), train_loss = 0.66977751, time/batch = 0.0529s\n",
            "60183/63080 (epoch 9.541), train_loss = 0.68069667, time/batch = 0.0527s\n",
            "60184/63080 (epoch 9.541), train_loss = 0.69530487, time/batch = 0.0526s\n",
            "60185/63080 (epoch 9.541), train_loss = 0.65858793, time/batch = 0.0525s\n",
            "60186/63080 (epoch 9.541), train_loss = 0.66123831, time/batch = 0.0528s\n",
            "60187/63080 (epoch 9.541), train_loss = 0.68882030, time/batch = 0.0524s\n",
            "60188/63080 (epoch 9.542), train_loss = 0.67242002, time/batch = 0.0527s\n",
            "60189/63080 (epoch 9.542), train_loss = 0.65964729, time/batch = 0.0524s\n",
            "60190/63080 (epoch 9.542), train_loss = 0.67143714, time/batch = 0.0527s\n",
            "60191/63080 (epoch 9.542), train_loss = 0.66501278, time/batch = 0.0534s\n",
            "60192/63080 (epoch 9.542), train_loss = 0.66597706, time/batch = 0.0526s\n",
            "60193/63080 (epoch 9.542), train_loss = 0.65224594, time/batch = 0.0524s\n",
            "60194/63080 (epoch 9.542), train_loss = 0.66424423, time/batch = 0.0532s\n",
            "60195/63080 (epoch 9.543), train_loss = 0.66236198, time/batch = 0.0528s\n",
            "60196/63080 (epoch 9.543), train_loss = 0.66468465, time/batch = 0.0529s\n",
            "60197/63080 (epoch 9.543), train_loss = 0.66329223, time/batch = 0.0522s\n",
            "60198/63080 (epoch 9.543), train_loss = 0.66193438, time/batch = 0.0526s\n",
            "60199/63080 (epoch 9.543), train_loss = 0.64603662, time/batch = 0.0521s\n",
            "60200/63080 (epoch 9.543), train_loss = 0.66182810, time/batch = 0.0530s\n",
            "60201/63080 (epoch 9.544), train_loss = 0.65160888, time/batch = 0.0526s\n",
            "60202/63080 (epoch 9.544), train_loss = 0.63643992, time/batch = 0.0525s\n",
            "60203/63080 (epoch 9.544), train_loss = 0.63804811, time/batch = 0.0522s\n",
            "60204/63080 (epoch 9.544), train_loss = 0.65672117, time/batch = 0.0529s\n",
            "60205/63080 (epoch 9.544), train_loss = 0.65101862, time/batch = 0.0531s\n",
            "60206/63080 (epoch 9.544), train_loss = 0.62861514, time/batch = 0.0532s\n",
            "60207/63080 (epoch 9.545), train_loss = 0.66780323, time/batch = 0.0527s\n",
            "60208/63080 (epoch 9.545), train_loss = 0.65656227, time/batch = 0.0524s\n",
            "60209/63080 (epoch 9.545), train_loss = 0.69009572, time/batch = 0.0526s\n",
            "60210/63080 (epoch 9.545), train_loss = 0.67364895, time/batch = 0.0527s\n",
            "60211/63080 (epoch 9.545), train_loss = 0.68525755, time/batch = 0.0524s\n",
            "60212/63080 (epoch 9.545), train_loss = 0.68506789, time/batch = 0.0523s\n",
            "60213/63080 (epoch 9.545), train_loss = 0.66368234, time/batch = 0.0526s\n",
            "60214/63080 (epoch 9.546), train_loss = 0.64953917, time/batch = 0.0531s\n",
            "60215/63080 (epoch 9.546), train_loss = 0.67954326, time/batch = 0.0530s\n",
            "60216/63080 (epoch 9.546), train_loss = 0.64377284, time/batch = 0.0527s\n",
            "60217/63080 (epoch 9.546), train_loss = 0.67263293, time/batch = 0.0530s\n",
            "60218/63080 (epoch 9.546), train_loss = 0.65873373, time/batch = 0.0526s\n",
            "60219/63080 (epoch 9.546), train_loss = 0.64240307, time/batch = 0.0527s\n",
            "60220/63080 (epoch 9.547), train_loss = 0.65886563, time/batch = 0.0528s\n",
            "60221/63080 (epoch 9.547), train_loss = 0.63562477, time/batch = 0.0537s\n",
            "60222/63080 (epoch 9.547), train_loss = 0.65077454, time/batch = 0.0524s\n",
            "60223/63080 (epoch 9.547), train_loss = 0.65264291, time/batch = 0.0526s\n",
            "60224/63080 (epoch 9.547), train_loss = 0.66132909, time/batch = 0.0524s\n",
            "60225/63080 (epoch 9.547), train_loss = 0.65830362, time/batch = 0.0527s\n",
            "60226/63080 (epoch 9.548), train_loss = 0.64680636, time/batch = 0.0524s\n",
            "60227/63080 (epoch 9.548), train_loss = 0.68944621, time/batch = 0.0516s\n",
            "60228/63080 (epoch 9.548), train_loss = 0.64261806, time/batch = 0.0523s\n",
            "60229/63080 (epoch 9.548), train_loss = 0.69937354, time/batch = 0.0524s\n",
            "60230/63080 (epoch 9.548), train_loss = 0.64637601, time/batch = 0.0527s\n",
            "60231/63080 (epoch 9.548), train_loss = 0.66833156, time/batch = 0.0525s\n",
            "60232/63080 (epoch 9.549), train_loss = 0.69571990, time/batch = 0.0526s\n",
            "60233/63080 (epoch 9.549), train_loss = 0.65134698, time/batch = 0.0529s\n",
            "60234/63080 (epoch 9.549), train_loss = 0.66423768, time/batch = 0.0537s\n",
            "60235/63080 (epoch 9.549), train_loss = 0.63547248, time/batch = 0.0527s\n",
            "60236/63080 (epoch 9.549), train_loss = 0.62704927, time/batch = 0.0532s\n",
            "60237/63080 (epoch 9.549), train_loss = 0.63875353, time/batch = 0.0524s\n",
            "60238/63080 (epoch 9.549), train_loss = 0.63874125, time/batch = 0.0527s\n",
            "60239/63080 (epoch 9.550), train_loss = 0.64968699, time/batch = 0.0528s\n",
            "60240/63080 (epoch 9.550), train_loss = 0.66204906, time/batch = 0.0529s\n",
            "60241/63080 (epoch 9.550), train_loss = 0.66900647, time/batch = 0.0526s\n",
            "60242/63080 (epoch 9.550), train_loss = 0.66066384, time/batch = 0.0523s\n",
            "60243/63080 (epoch 9.550), train_loss = 0.66405636, time/batch = 0.0526s\n",
            "60244/63080 (epoch 9.550), train_loss = 0.64479500, time/batch = 0.0524s\n",
            "60245/63080 (epoch 9.551), train_loss = 0.64285582, time/batch = 0.0526s\n",
            "60246/63080 (epoch 9.551), train_loss = 0.64776427, time/batch = 0.0543s\n",
            "60247/63080 (epoch 9.551), train_loss = 0.66992205, time/batch = 0.0525s\n",
            "60248/63080 (epoch 9.551), train_loss = 0.63851130, time/batch = 0.0523s\n",
            "60249/63080 (epoch 9.551), train_loss = 0.64287287, time/batch = 0.0524s\n",
            "60250/63080 (epoch 9.551), train_loss = 0.65346038, time/batch = 0.0537s\n",
            "60251/63080 (epoch 9.552), train_loss = 0.64808190, time/batch = 0.0540s\n",
            "60252/63080 (epoch 9.552), train_loss = 0.64998960, time/batch = 0.0532s\n",
            "60253/63080 (epoch 9.552), train_loss = 0.66775942, time/batch = 0.0524s\n",
            "60254/63080 (epoch 9.552), train_loss = 0.64556968, time/batch = 0.0537s\n",
            "60255/63080 (epoch 9.552), train_loss = 0.62915319, time/batch = 0.0530s\n",
            "60256/63080 (epoch 9.552), train_loss = 0.65292484, time/batch = 0.0524s\n",
            "60257/63080 (epoch 9.552), train_loss = 0.64758825, time/batch = 0.0526s\n",
            "60258/63080 (epoch 9.553), train_loss = 0.61901355, time/batch = 0.0526s\n",
            "60259/63080 (epoch 9.553), train_loss = 0.65744162, time/batch = 0.0525s\n",
            "60260/63080 (epoch 9.553), train_loss = 0.63416970, time/batch = 0.0541s\n",
            "60261/63080 (epoch 9.553), train_loss = 0.65860593, time/batch = 0.0529s\n",
            "60262/63080 (epoch 9.553), train_loss = 0.64664537, time/batch = 0.0525s\n",
            "60263/63080 (epoch 9.553), train_loss = 0.65834999, time/batch = 0.0531s\n",
            "60264/63080 (epoch 9.554), train_loss = 0.67239624, time/batch = 0.0522s\n",
            "60265/63080 (epoch 9.554), train_loss = 0.66385257, time/batch = 0.0531s\n",
            "60266/63080 (epoch 9.554), train_loss = 0.65518665, time/batch = 0.0523s\n",
            "60267/63080 (epoch 9.554), train_loss = 0.67339176, time/batch = 0.0529s\n",
            "60268/63080 (epoch 9.554), train_loss = 0.65959901, time/batch = 0.0525s\n",
            "60269/63080 (epoch 9.554), train_loss = 0.66864407, time/batch = 0.0526s\n",
            "60270/63080 (epoch 9.555), train_loss = 0.66335446, time/batch = 0.0532s\n",
            "60271/63080 (epoch 9.555), train_loss = 0.66209078, time/batch = 0.0533s\n",
            "60272/63080 (epoch 9.555), train_loss = 0.66374499, time/batch = 0.0523s\n",
            "60273/63080 (epoch 9.555), train_loss = 0.66315717, time/batch = 0.0530s\n",
            "60274/63080 (epoch 9.555), train_loss = 0.66053420, time/batch = 0.0526s\n",
            "60275/63080 (epoch 9.555), train_loss = 0.67316407, time/batch = 0.0534s\n",
            "60276/63080 (epoch 9.555), train_loss = 0.67026848, time/batch = 0.0530s\n",
            "60277/63080 (epoch 9.556), train_loss = 0.64851403, time/batch = 0.0526s\n",
            "60278/63080 (epoch 9.556), train_loss = 0.67430353, time/batch = 0.0528s\n",
            "60279/63080 (epoch 9.556), train_loss = 0.68069023, time/batch = 0.0528s\n",
            "60280/63080 (epoch 9.556), train_loss = 0.67314363, time/batch = 0.0534s\n",
            "60281/63080 (epoch 9.556), train_loss = 0.68226838, time/batch = 0.0524s\n",
            "60282/63080 (epoch 9.556), train_loss = 0.67353767, time/batch = 0.0525s\n",
            "60283/63080 (epoch 9.557), train_loss = 0.65469605, time/batch = 0.0529s\n",
            "60284/63080 (epoch 9.557), train_loss = 0.65816289, time/batch = 0.0528s\n",
            "60285/63080 (epoch 9.557), train_loss = 0.67715544, time/batch = 0.0528s\n",
            "60286/63080 (epoch 9.557), train_loss = 0.65840870, time/batch = 0.0527s\n",
            "60287/63080 (epoch 9.557), train_loss = 0.65751636, time/batch = 0.0523s\n",
            "60288/63080 (epoch 9.557), train_loss = 0.68434674, time/batch = 0.0525s\n",
            "60289/63080 (epoch 9.558), train_loss = 0.64999008, time/batch = 0.0527s\n",
            "60290/63080 (epoch 9.558), train_loss = 0.66252846, time/batch = 0.0524s\n",
            "60291/63080 (epoch 9.558), train_loss = 0.66660196, time/batch = 0.0527s\n",
            "60292/63080 (epoch 9.558), train_loss = 0.67658585, time/batch = 0.0525s\n",
            "60293/63080 (epoch 9.558), train_loss = 0.66613877, time/batch = 0.0527s\n",
            "60294/63080 (epoch 9.558), train_loss = 0.65967530, time/batch = 0.0526s\n",
            "60295/63080 (epoch 9.558), train_loss = 0.69372892, time/batch = 0.0527s\n",
            "60296/63080 (epoch 9.559), train_loss = 0.68934166, time/batch = 0.0529s\n",
            "60297/63080 (epoch 9.559), train_loss = 0.67606503, time/batch = 0.0527s\n",
            "60298/63080 (epoch 9.559), train_loss = 0.68754077, time/batch = 0.0526s\n",
            "60299/63080 (epoch 9.559), train_loss = 0.69327521, time/batch = 0.0531s\n",
            "60300/63080 (epoch 9.559), train_loss = 0.68826407, time/batch = 0.0530s\n",
            "60301/63080 (epoch 9.559), train_loss = 0.66327304, time/batch = 0.0547s\n",
            "60302/63080 (epoch 9.560), train_loss = 0.65606016, time/batch = 0.0527s\n",
            "60303/63080 (epoch 9.560), train_loss = 0.66985738, time/batch = 0.0534s\n",
            "60304/63080 (epoch 9.560), train_loss = 0.64766598, time/batch = 0.0532s\n",
            "60305/63080 (epoch 9.560), train_loss = 0.66554254, time/batch = 0.0529s\n",
            "60306/63080 (epoch 9.560), train_loss = 0.66534501, time/batch = 0.0529s\n",
            "60307/63080 (epoch 9.560), train_loss = 0.65336496, time/batch = 0.0523s\n",
            "60308/63080 (epoch 9.561), train_loss = 0.65870172, time/batch = 0.0528s\n",
            "60309/63080 (epoch 9.561), train_loss = 0.65707791, time/batch = 0.0527s\n",
            "60310/63080 (epoch 9.561), train_loss = 0.67871422, time/batch = 0.0528s\n",
            "60311/63080 (epoch 9.561), train_loss = 0.67666644, time/batch = 0.0520s\n",
            "60312/63080 (epoch 9.561), train_loss = 0.66609323, time/batch = 0.0526s\n",
            "60313/63080 (epoch 9.561), train_loss = 0.62809598, time/batch = 0.0527s\n",
            "60314/63080 (epoch 9.562), train_loss = 0.65238273, time/batch = 0.0529s\n",
            "60315/63080 (epoch 9.562), train_loss = 0.65937895, time/batch = 0.0524s\n",
            "60316/63080 (epoch 9.562), train_loss = 0.65196115, time/batch = 0.0535s\n",
            "60317/63080 (epoch 9.562), train_loss = 0.64795172, time/batch = 0.0524s\n",
            "60318/63080 (epoch 9.562), train_loss = 0.67998546, time/batch = 0.0527s\n",
            "60319/63080 (epoch 9.562), train_loss = 0.67734897, time/batch = 0.0525s\n",
            "60320/63080 (epoch 9.562), train_loss = 0.68521136, time/batch = 0.0534s\n",
            "60321/63080 (epoch 9.563), train_loss = 0.65620720, time/batch = 0.0527s\n",
            "60322/63080 (epoch 9.563), train_loss = 0.63878632, time/batch = 0.0527s\n",
            "60323/63080 (epoch 9.563), train_loss = 0.67755765, time/batch = 0.0523s\n",
            "60324/63080 (epoch 9.563), train_loss = 0.66045022, time/batch = 0.0526s\n",
            "60325/63080 (epoch 9.563), train_loss = 0.66900259, time/batch = 0.0525s\n",
            "60326/63080 (epoch 9.563), train_loss = 0.65634930, time/batch = 0.0521s\n",
            "60327/63080 (epoch 9.564), train_loss = 0.64008141, time/batch = 0.0525s\n",
            "60328/63080 (epoch 9.564), train_loss = 0.65203315, time/batch = 0.0526s\n",
            "60329/63080 (epoch 9.564), train_loss = 0.65912658, time/batch = 0.0525s\n",
            "60330/63080 (epoch 9.564), train_loss = 0.66857791, time/batch = 0.0534s\n",
            "60331/63080 (epoch 9.564), train_loss = 0.66954476, time/batch = 0.0524s\n",
            "60332/63080 (epoch 9.564), train_loss = 0.67015564, time/batch = 0.0529s\n",
            "60333/63080 (epoch 9.565), train_loss = 0.69829702, time/batch = 0.0528s\n",
            "60334/63080 (epoch 9.565), train_loss = 0.66913778, time/batch = 0.0530s\n",
            "60335/63080 (epoch 9.565), train_loss = 0.66185802, time/batch = 0.0525s\n",
            "60336/63080 (epoch 9.565), train_loss = 0.66670358, time/batch = 0.0522s\n",
            "60337/63080 (epoch 9.565), train_loss = 0.66975158, time/batch = 0.0531s\n",
            "60338/63080 (epoch 9.565), train_loss = 0.67105949, time/batch = 0.0533s\n",
            "60339/63080 (epoch 9.565), train_loss = 0.67234129, time/batch = 0.0533s\n",
            "60340/63080 (epoch 9.566), train_loss = 0.69083172, time/batch = 0.0527s\n",
            "60341/63080 (epoch 9.566), train_loss = 0.70825684, time/batch = 0.0524s\n",
            "60342/63080 (epoch 9.566), train_loss = 0.67968404, time/batch = 0.0523s\n",
            "60343/63080 (epoch 9.566), train_loss = 0.68589640, time/batch = 0.0527s\n",
            "60344/63080 (epoch 9.566), train_loss = 0.66681361, time/batch = 0.0528s\n",
            "60345/63080 (epoch 9.566), train_loss = 0.65255523, time/batch = 0.0537s\n",
            "60346/63080 (epoch 9.567), train_loss = 0.66271037, time/batch = 0.0528s\n",
            "60347/63080 (epoch 9.567), train_loss = 0.69384360, time/batch = 0.0524s\n",
            "60348/63080 (epoch 9.567), train_loss = 0.65535736, time/batch = 0.0536s\n",
            "60349/63080 (epoch 9.567), train_loss = 0.67208332, time/batch = 0.0525s\n",
            "60350/63080 (epoch 9.567), train_loss = 0.67111802, time/batch = 0.0537s\n",
            "60351/63080 (epoch 9.567), train_loss = 0.67005986, time/batch = 0.0523s\n",
            "60352/63080 (epoch 9.568), train_loss = 0.65513897, time/batch = 0.0529s\n",
            "60353/63080 (epoch 9.568), train_loss = 0.66497838, time/batch = 0.0526s\n",
            "60354/63080 (epoch 9.568), train_loss = 0.64463097, time/batch = 0.0528s\n",
            "60355/63080 (epoch 9.568), train_loss = 0.65504402, time/batch = 0.0524s\n",
            "60356/63080 (epoch 9.568), train_loss = 0.66433835, time/batch = 0.0524s\n",
            "60357/63080 (epoch 9.568), train_loss = 0.67496490, time/batch = 0.0527s\n",
            "60358/63080 (epoch 9.568), train_loss = 0.67495692, time/batch = 0.0525s\n",
            "60359/63080 (epoch 9.569), train_loss = 0.68389422, time/batch = 0.0525s\n",
            "60360/63080 (epoch 9.569), train_loss = 0.67225879, time/batch = 0.0534s\n",
            "60361/63080 (epoch 9.569), train_loss = 0.65977991, time/batch = 0.0529s\n",
            "60362/63080 (epoch 9.569), train_loss = 0.69083828, time/batch = 0.0524s\n",
            "60363/63080 (epoch 9.569), train_loss = 0.68661863, time/batch = 0.0529s\n",
            "60364/63080 (epoch 9.569), train_loss = 0.68143404, time/batch = 0.0533s\n",
            "60365/63080 (epoch 9.570), train_loss = 0.64275759, time/batch = 0.0526s\n",
            "60366/63080 (epoch 9.570), train_loss = 0.65312308, time/batch = 0.0523s\n",
            "60367/63080 (epoch 9.570), train_loss = 0.65976834, time/batch = 0.0531s\n",
            "60368/63080 (epoch 9.570), train_loss = 0.67386830, time/batch = 0.0526s\n",
            "60369/63080 (epoch 9.570), train_loss = 0.65891904, time/batch = 0.0526s\n",
            "60370/63080 (epoch 9.570), train_loss = 0.65009761, time/batch = 0.0526s\n",
            "60371/63080 (epoch 9.571), train_loss = 0.65831900, time/batch = 0.0516s\n",
            "60372/63080 (epoch 9.571), train_loss = 0.64250886, time/batch = 0.0524s\n",
            "60373/63080 (epoch 9.571), train_loss = 0.66406572, time/batch = 0.0532s\n",
            "60374/63080 (epoch 9.571), train_loss = 0.65546995, time/batch = 0.0530s\n",
            "60375/63080 (epoch 9.571), train_loss = 0.65437007, time/batch = 0.0529s\n",
            "60376/63080 (epoch 9.571), train_loss = 0.63536090, time/batch = 0.0524s\n",
            "60377/63080 (epoch 9.571), train_loss = 0.68188226, time/batch = 0.0531s\n",
            "60378/63080 (epoch 9.572), train_loss = 0.66400456, time/batch = 0.0521s\n",
            "60379/63080 (epoch 9.572), train_loss = 0.67226994, time/batch = 0.0530s\n",
            "60380/63080 (epoch 9.572), train_loss = 0.68340975, time/batch = 0.0528s\n",
            "60381/63080 (epoch 9.572), train_loss = 0.67050564, time/batch = 0.0529s\n",
            "60382/63080 (epoch 9.572), train_loss = 0.66758770, time/batch = 0.0522s\n",
            "60383/63080 (epoch 9.572), train_loss = 0.69086605, time/batch = 0.0535s\n",
            "60384/63080 (epoch 9.573), train_loss = 0.67332363, time/batch = 0.0517s\n",
            "60385/63080 (epoch 9.573), train_loss = 0.66890657, time/batch = 0.0533s\n",
            "60386/63080 (epoch 9.573), train_loss = 0.67381215, time/batch = 0.0527s\n",
            "60387/63080 (epoch 9.573), train_loss = 0.66868436, time/batch = 0.0534s\n",
            "60388/63080 (epoch 9.573), train_loss = 0.65226203, time/batch = 0.0527s\n",
            "60389/63080 (epoch 9.573), train_loss = 0.64753419, time/batch = 0.0527s\n",
            "60390/63080 (epoch 9.574), train_loss = 0.64815480, time/batch = 0.0525s\n",
            "60391/63080 (epoch 9.574), train_loss = 0.65422112, time/batch = 0.0526s\n",
            "60392/63080 (epoch 9.574), train_loss = 0.65382081, time/batch = 0.0524s\n",
            "60393/63080 (epoch 9.574), train_loss = 0.67038673, time/batch = 0.0539s\n",
            "60394/63080 (epoch 9.574), train_loss = 0.66140920, time/batch = 0.0537s\n",
            "60395/63080 (epoch 9.574), train_loss = 0.64850599, time/batch = 0.0524s\n",
            "60396/63080 (epoch 9.575), train_loss = 0.67709947, time/batch = 0.0528s\n",
            "60397/63080 (epoch 9.575), train_loss = 0.64604801, time/batch = 0.0523s\n",
            "60398/63080 (epoch 9.575), train_loss = 0.66740322, time/batch = 0.0526s\n",
            "60399/63080 (epoch 9.575), train_loss = 0.69907767, time/batch = 0.0529s\n",
            "60400/63080 (epoch 9.575), train_loss = 0.66801846, time/batch = 0.0529s\n",
            "60401/63080 (epoch 9.575), train_loss = 0.66769320, time/batch = 0.0524s\n",
            "60402/63080 (epoch 9.575), train_loss = 0.66836256, time/batch = 0.0523s\n",
            "60403/63080 (epoch 9.576), train_loss = 0.65696651, time/batch = 0.0525s\n",
            "60404/63080 (epoch 9.576), train_loss = 0.66447741, time/batch = 0.0529s\n",
            "60405/63080 (epoch 9.576), train_loss = 0.64801109, time/batch = 0.0527s\n",
            "60406/63080 (epoch 9.576), train_loss = 0.65884656, time/batch = 0.0525s\n",
            "60407/63080 (epoch 9.576), train_loss = 0.68213373, time/batch = 0.0525s\n",
            "60408/63080 (epoch 9.576), train_loss = 0.65729600, time/batch = 0.0536s\n",
            "60409/63080 (epoch 9.577), train_loss = 0.69484711, time/batch = 0.0525s\n",
            "60410/63080 (epoch 9.577), train_loss = 0.66054600, time/batch = 0.0525s\n",
            "60411/63080 (epoch 9.577), train_loss = 0.66727978, time/batch = 0.0527s\n",
            "60412/63080 (epoch 9.577), train_loss = 0.68606269, time/batch = 0.0520s\n",
            "60413/63080 (epoch 9.577), train_loss = 0.66858506, time/batch = 0.0523s\n",
            "60414/63080 (epoch 9.577), train_loss = 0.65940082, time/batch = 0.0519s\n",
            "60415/63080 (epoch 9.578), train_loss = 0.65491074, time/batch = 0.0523s\n",
            "60416/63080 (epoch 9.578), train_loss = 0.66976535, time/batch = 0.0522s\n",
            "60417/63080 (epoch 9.578), train_loss = 0.67186457, time/batch = 0.0525s\n",
            "60418/63080 (epoch 9.578), train_loss = 0.67676765, time/batch = 0.0522s\n",
            "60419/63080 (epoch 9.578), train_loss = 0.70295143, time/batch = 0.0524s\n",
            "60420/63080 (epoch 9.578), train_loss = 0.63299495, time/batch = 0.0526s\n",
            "60421/63080 (epoch 9.578), train_loss = 0.67639077, time/batch = 0.0529s\n",
            "60422/63080 (epoch 9.579), train_loss = 0.66195852, time/batch = 0.0528s\n",
            "60423/63080 (epoch 9.579), train_loss = 0.64256293, time/batch = 0.0525s\n",
            "60424/63080 (epoch 9.579), train_loss = 0.65299803, time/batch = 0.0527s\n",
            "60425/63080 (epoch 9.579), train_loss = 0.65480584, time/batch = 0.0525s\n",
            "60426/63080 (epoch 9.579), train_loss = 0.63613129, time/batch = 0.0526s\n",
            "60427/63080 (epoch 9.579), train_loss = 0.64064056, time/batch = 0.0527s\n",
            "60428/63080 (epoch 9.580), train_loss = 0.65710652, time/batch = 0.0526s\n",
            "60429/63080 (epoch 9.580), train_loss = 0.64070714, time/batch = 0.0526s\n",
            "60430/63080 (epoch 9.580), train_loss = 0.67105430, time/batch = 0.0527s\n",
            "60431/63080 (epoch 9.580), train_loss = 0.65055144, time/batch = 0.0523s\n",
            "60432/63080 (epoch 9.580), train_loss = 0.65523398, time/batch = 0.0527s\n",
            "60433/63080 (epoch 9.580), train_loss = 0.65601462, time/batch = 0.0525s\n",
            "60434/63080 (epoch 9.581), train_loss = 0.65659696, time/batch = 0.0524s\n",
            "60435/63080 (epoch 9.581), train_loss = 0.64710307, time/batch = 0.0527s\n",
            "60436/63080 (epoch 9.581), train_loss = 0.63767725, time/batch = 0.0523s\n",
            "60437/63080 (epoch 9.581), train_loss = 0.66702020, time/batch = 0.0525s\n",
            "60438/63080 (epoch 9.581), train_loss = 0.65186840, time/batch = 0.0531s\n",
            "60439/63080 (epoch 9.581), train_loss = 0.64872277, time/batch = 0.0526s\n",
            "60440/63080 (epoch 9.581), train_loss = 0.67519420, time/batch = 0.0529s\n",
            "60441/63080 (epoch 9.582), train_loss = 0.67910165, time/batch = 0.0530s\n",
            "60442/63080 (epoch 9.582), train_loss = 0.64556092, time/batch = 0.0526s\n",
            "60443/63080 (epoch 9.582), train_loss = 0.65617067, time/batch = 0.0525s\n",
            "60444/63080 (epoch 9.582), train_loss = 0.65893990, time/batch = 0.0523s\n",
            "60445/63080 (epoch 9.582), train_loss = 0.66204977, time/batch = 0.0536s\n",
            "60446/63080 (epoch 9.582), train_loss = 0.64639747, time/batch = 0.0528s\n",
            "60447/63080 (epoch 9.583), train_loss = 0.63922215, time/batch = 0.0529s\n",
            "60448/63080 (epoch 9.583), train_loss = 0.64281142, time/batch = 0.0522s\n",
            "60449/63080 (epoch 9.583), train_loss = 0.65197039, time/batch = 0.0529s\n",
            "60450/63080 (epoch 9.583), train_loss = 0.65147287, time/batch = 0.0527s\n",
            "60451/63080 (epoch 9.583), train_loss = 0.65065068, time/batch = 0.0529s\n",
            "60452/63080 (epoch 9.583), train_loss = 0.65897346, time/batch = 0.0516s\n",
            "60453/63080 (epoch 9.584), train_loss = 0.66966581, time/batch = 0.0531s\n",
            "60454/63080 (epoch 9.584), train_loss = 0.64534092, time/batch = 0.0523s\n",
            "60455/63080 (epoch 9.584), train_loss = 0.65699583, time/batch = 0.0538s\n",
            "60456/63080 (epoch 9.584), train_loss = 0.63942409, time/batch = 0.0525s\n",
            "60457/63080 (epoch 9.584), train_loss = 0.66906524, time/batch = 0.0529s\n",
            "60458/63080 (epoch 9.584), train_loss = 0.66035455, time/batch = 0.0525s\n",
            "60459/63080 (epoch 9.584), train_loss = 0.65723836, time/batch = 0.0530s\n",
            "60460/63080 (epoch 9.585), train_loss = 0.68538266, time/batch = 0.0528s\n",
            "60461/63080 (epoch 9.585), train_loss = 0.67000729, time/batch = 0.0521s\n",
            "60462/63080 (epoch 9.585), train_loss = 0.66212773, time/batch = 0.0523s\n",
            "60463/63080 (epoch 9.585), train_loss = 0.65971333, time/batch = 0.0528s\n",
            "60464/63080 (epoch 9.585), train_loss = 0.66769254, time/batch = 0.0525s\n",
            "60465/63080 (epoch 9.585), train_loss = 0.67451108, time/batch = 0.0530s\n",
            "60466/63080 (epoch 9.586), train_loss = 0.64365470, time/batch = 0.0527s\n",
            "60467/63080 (epoch 9.586), train_loss = 0.65425205, time/batch = 0.0526s\n",
            "60468/63080 (epoch 9.586), train_loss = 0.66235912, time/batch = 0.0526s\n",
            "60469/63080 (epoch 9.586), train_loss = 0.67904973, time/batch = 0.0526s\n",
            "60470/63080 (epoch 9.586), train_loss = 0.65779030, time/batch = 0.0527s\n",
            "60471/63080 (epoch 9.586), train_loss = 0.66258055, time/batch = 0.0519s\n",
            "60472/63080 (epoch 9.587), train_loss = 0.66998273, time/batch = 0.0527s\n",
            "60473/63080 (epoch 9.587), train_loss = 0.63876504, time/batch = 0.0527s\n",
            "60474/63080 (epoch 9.587), train_loss = 0.66771293, time/batch = 0.0522s\n",
            "60475/63080 (epoch 9.587), train_loss = 0.64921242, time/batch = 0.0525s\n",
            "60476/63080 (epoch 9.587), train_loss = 0.65888423, time/batch = 0.0524s\n",
            "60477/63080 (epoch 9.587), train_loss = 0.64887643, time/batch = 0.0526s\n",
            "60478/63080 (epoch 9.588), train_loss = 0.67126155, time/batch = 0.0525s\n",
            "60479/63080 (epoch 9.588), train_loss = 0.66014385, time/batch = 0.0525s\n",
            "60480/63080 (epoch 9.588), train_loss = 0.64061135, time/batch = 0.0533s\n",
            "60481/63080 (epoch 9.588), train_loss = 0.65671468, time/batch = 0.0522s\n",
            "60482/63080 (epoch 9.588), train_loss = 0.67604065, time/batch = 0.0522s\n",
            "60483/63080 (epoch 9.588), train_loss = 0.64121246, time/batch = 0.0527s\n",
            "60484/63080 (epoch 9.588), train_loss = 0.65276277, time/batch = 0.0529s\n",
            "60485/63080 (epoch 9.589), train_loss = 0.67838061, time/batch = 0.0538s\n",
            "60486/63080 (epoch 9.589), train_loss = 0.67532271, time/batch = 0.0526s\n",
            "60487/63080 (epoch 9.589), train_loss = 0.66608500, time/batch = 0.0524s\n",
            "60488/63080 (epoch 9.589), train_loss = 0.67124945, time/batch = 0.0526s\n",
            "60489/63080 (epoch 9.589), train_loss = 0.66624910, time/batch = 0.0526s\n",
            "60490/63080 (epoch 9.589), train_loss = 0.68967408, time/batch = 0.0529s\n",
            "60491/63080 (epoch 9.590), train_loss = 0.66952944, time/batch = 0.0520s\n",
            "60492/63080 (epoch 9.590), train_loss = 0.68563956, time/batch = 0.0528s\n",
            "60493/63080 (epoch 9.590), train_loss = 0.65902543, time/batch = 0.0527s\n",
            "60494/63080 (epoch 9.590), train_loss = 0.66033584, time/batch = 0.0527s\n",
            "60495/63080 (epoch 9.590), train_loss = 0.68060237, time/batch = 0.0528s\n",
            "60496/63080 (epoch 9.590), train_loss = 0.67167997, time/batch = 0.0524s\n",
            "60497/63080 (epoch 9.591), train_loss = 0.69030041, time/batch = 0.0527s\n",
            "60498/63080 (epoch 9.591), train_loss = 0.67400277, time/batch = 0.0531s\n",
            "60499/63080 (epoch 9.591), train_loss = 0.66728950, time/batch = 0.0525s\n",
            "60500/63080 (epoch 9.591), train_loss = 0.69224572, time/batch = 0.0528s\n",
            "60501/63080 (epoch 9.591), train_loss = 0.70536691, time/batch = 0.0511s\n",
            "60502/63080 (epoch 9.591), train_loss = 0.69559342, time/batch = 0.0532s\n",
            "60503/63080 (epoch 9.591), train_loss = 0.70405936, time/batch = 0.0525s\n",
            "60504/63080 (epoch 9.592), train_loss = 0.66881388, time/batch = 0.0527s\n",
            "60505/63080 (epoch 9.592), train_loss = 0.65990508, time/batch = 0.0535s\n",
            "60506/63080 (epoch 9.592), train_loss = 0.68310988, time/batch = 0.0526s\n",
            "60507/63080 (epoch 9.592), train_loss = 0.65988076, time/batch = 0.0522s\n",
            "60508/63080 (epoch 9.592), train_loss = 0.67529577, time/batch = 0.0527s\n",
            "60509/63080 (epoch 9.592), train_loss = 0.66788793, time/batch = 0.0524s\n",
            "60510/63080 (epoch 9.593), train_loss = 0.67528749, time/batch = 0.0527s\n",
            "60511/63080 (epoch 9.593), train_loss = 0.67723203, time/batch = 0.0519s\n",
            "60512/63080 (epoch 9.593), train_loss = 0.66629303, time/batch = 0.0524s\n",
            "60513/63080 (epoch 9.593), train_loss = 0.65476584, time/batch = 0.0526s\n",
            "60514/63080 (epoch 9.593), train_loss = 0.64879799, time/batch = 0.0538s\n",
            "60515/63080 (epoch 9.593), train_loss = 0.70524281, time/batch = 0.0524s\n",
            "60516/63080 (epoch 9.594), train_loss = 0.69103593, time/batch = 0.0524s\n",
            "60517/63080 (epoch 9.594), train_loss = 0.69681323, time/batch = 0.0521s\n",
            "60518/63080 (epoch 9.594), train_loss = 0.66599828, time/batch = 0.0523s\n",
            "60519/63080 (epoch 9.594), train_loss = 0.68995762, time/batch = 0.0526s\n",
            "60520/63080 (epoch 9.594), train_loss = 0.68196356, time/batch = 0.0517s\n",
            "60521/63080 (epoch 9.594), train_loss = 0.67746490, time/batch = 0.0525s\n",
            "60522/63080 (epoch 9.594), train_loss = 0.67237550, time/batch = 0.0522s\n",
            "60523/63080 (epoch 9.595), train_loss = 0.66457528, time/batch = 0.0525s\n",
            "60524/63080 (epoch 9.595), train_loss = 0.65763599, time/batch = 0.0528s\n",
            "60525/63080 (epoch 9.595), train_loss = 0.67673904, time/batch = 0.0524s\n",
            "60526/63080 (epoch 9.595), train_loss = 0.65827167, time/batch = 0.0525s\n",
            "60527/63080 (epoch 9.595), train_loss = 0.70661616, time/batch = 0.0523s\n",
            "60528/63080 (epoch 9.595), train_loss = 0.69143271, time/batch = 0.0525s\n",
            "60529/63080 (epoch 9.596), train_loss = 0.69118321, time/batch = 0.0528s\n",
            "60530/63080 (epoch 9.596), train_loss = 0.69059819, time/batch = 0.0521s\n",
            "60531/63080 (epoch 9.596), train_loss = 0.66605705, time/batch = 0.0524s\n",
            "60532/63080 (epoch 9.596), train_loss = 0.66357619, time/batch = 0.0523s\n",
            "60533/63080 (epoch 9.596), train_loss = 0.68587434, time/batch = 0.0524s\n",
            "60534/63080 (epoch 9.596), train_loss = 0.65126204, time/batch = 0.0524s\n",
            "60535/63080 (epoch 9.597), train_loss = 0.63682115, time/batch = 0.0521s\n",
            "60536/63080 (epoch 9.597), train_loss = 0.66523540, time/batch = 0.0526s\n",
            "60537/63080 (epoch 9.597), train_loss = 0.65761811, time/batch = 0.0524s\n",
            "60538/63080 (epoch 9.597), train_loss = 0.65684164, time/batch = 0.0524s\n",
            "60539/63080 (epoch 9.597), train_loss = 0.63468790, time/batch = 0.0546s\n",
            "60540/63080 (epoch 9.597), train_loss = 0.67488164, time/batch = 0.0526s\n",
            "60541/63080 (epoch 9.597), train_loss = 0.66561067, time/batch = 0.0522s\n",
            "60542/63080 (epoch 9.598), train_loss = 0.65598863, time/batch = 0.0524s\n",
            "60543/63080 (epoch 9.598), train_loss = 0.65889770, time/batch = 0.0525s\n",
            "60544/63080 (epoch 9.598), train_loss = 0.66100848, time/batch = 0.0524s\n",
            "60545/63080 (epoch 9.598), train_loss = 0.68384665, time/batch = 0.0526s\n",
            "60546/63080 (epoch 9.598), train_loss = 0.66858160, time/batch = 0.0523s\n",
            "60547/63080 (epoch 9.598), train_loss = 0.64925909, time/batch = 0.0524s\n",
            "60548/63080 (epoch 9.599), train_loss = 0.67005694, time/batch = 0.0530s\n",
            "60549/63080 (epoch 9.599), train_loss = 0.65518814, time/batch = 0.0525s\n",
            "60550/63080 (epoch 9.599), train_loss = 0.65504783, time/batch = 0.0525s\n",
            "60551/63080 (epoch 9.599), train_loss = 0.64220935, time/batch = 0.0528s\n",
            "60552/63080 (epoch 9.599), train_loss = 0.64657241, time/batch = 0.0524s\n",
            "60553/63080 (epoch 9.599), train_loss = 0.64702708, time/batch = 0.0529s\n",
            "60554/63080 (epoch 9.600), train_loss = 0.66077805, time/batch = 0.0525s\n",
            "60555/63080 (epoch 9.600), train_loss = 0.65396851, time/batch = 0.0528s\n",
            "60556/63080 (epoch 9.600), train_loss = 0.65567595, time/batch = 0.0524s\n",
            "60557/63080 (epoch 9.600), train_loss = 0.69026929, time/batch = 0.0528s\n",
            "60558/63080 (epoch 9.600), train_loss = 0.65924436, time/batch = 0.0517s\n",
            "60559/63080 (epoch 9.600), train_loss = 0.67160273, time/batch = 0.0526s\n",
            "60560/63080 (epoch 9.601), train_loss = 0.67184532, time/batch = 0.0529s\n",
            "60561/63080 (epoch 9.601), train_loss = 0.65365207, time/batch = 0.0526s\n",
            "60562/63080 (epoch 9.601), train_loss = 0.67447901, time/batch = 0.0524s\n",
            "60563/63080 (epoch 9.601), train_loss = 0.63282007, time/batch = 0.0543s\n",
            "60564/63080 (epoch 9.601), train_loss = 0.64440316, time/batch = 0.0525s\n",
            "60565/63080 (epoch 9.601), train_loss = 0.65419072, time/batch = 0.0530s\n",
            "60566/63080 (epoch 9.601), train_loss = 0.66071427, time/batch = 0.0525s\n",
            "60567/63080 (epoch 9.602), train_loss = 0.64351237, time/batch = 0.0535s\n",
            "60568/63080 (epoch 9.602), train_loss = 0.66954494, time/batch = 0.0526s\n",
            "60569/63080 (epoch 9.602), train_loss = 0.64044642, time/batch = 0.0524s\n",
            "60570/63080 (epoch 9.602), train_loss = 0.67311996, time/batch = 0.0527s\n",
            "60571/63080 (epoch 9.602), train_loss = 0.63771272, time/batch = 0.0526s\n",
            "60572/63080 (epoch 9.602), train_loss = 0.64841104, time/batch = 0.0523s\n",
            "60573/63080 (epoch 9.603), train_loss = 0.65076846, time/batch = 0.0529s\n",
            "60574/63080 (epoch 9.603), train_loss = 0.65035623, time/batch = 0.0524s\n",
            "60575/63080 (epoch 9.603), train_loss = 0.66345769, time/batch = 0.0525s\n",
            "60576/63080 (epoch 9.603), train_loss = 0.66795355, time/batch = 0.0526s\n",
            "60577/63080 (epoch 9.603), train_loss = 0.66932207, time/batch = 0.0529s\n",
            "60578/63080 (epoch 9.603), train_loss = 0.64334041, time/batch = 0.0538s\n",
            "60579/63080 (epoch 9.604), train_loss = 0.63786548, time/batch = 0.0527s\n",
            "60580/63080 (epoch 9.604), train_loss = 0.64501309, time/batch = 0.0533s\n",
            "60581/63080 (epoch 9.604), train_loss = 0.64784485, time/batch = 0.0526s\n",
            "60582/63080 (epoch 9.604), train_loss = 0.66972935, time/batch = 0.0525s\n",
            "60583/63080 (epoch 9.604), train_loss = 0.65500820, time/batch = 0.0526s\n",
            "60584/63080 (epoch 9.604), train_loss = 0.66705137, time/batch = 0.0528s\n",
            "60585/63080 (epoch 9.604), train_loss = 0.62823409, time/batch = 0.0524s\n",
            "60586/63080 (epoch 9.605), train_loss = 0.65437162, time/batch = 0.0525s\n",
            "60587/63080 (epoch 9.605), train_loss = 0.66094714, time/batch = 0.0529s\n",
            "60588/63080 (epoch 9.605), train_loss = 0.66560471, time/batch = 0.0522s\n",
            "60589/63080 (epoch 9.605), train_loss = 0.65458137, time/batch = 0.0524s\n",
            "60590/63080 (epoch 9.605), train_loss = 0.64825720, time/batch = 0.0528s\n",
            "60591/63080 (epoch 9.605), train_loss = 0.64409858, time/batch = 0.0525s\n",
            "60592/63080 (epoch 9.606), train_loss = 0.65974152, time/batch = 0.0533s\n",
            "60593/63080 (epoch 9.606), train_loss = 0.65552199, time/batch = 0.0524s\n",
            "60594/63080 (epoch 9.606), train_loss = 0.66378039, time/batch = 0.0529s\n",
            "60595/63080 (epoch 9.606), train_loss = 0.63962930, time/batch = 0.0543s\n",
            "60596/63080 (epoch 9.606), train_loss = 0.66273922, time/batch = 0.0525s\n",
            "60597/63080 (epoch 9.606), train_loss = 0.66380936, time/batch = 0.0527s\n",
            "60598/63080 (epoch 9.607), train_loss = 0.66350955, time/batch = 0.0523s\n",
            "60599/63080 (epoch 9.607), train_loss = 0.66270602, time/batch = 0.0523s\n",
            "60600/63080 (epoch 9.607), train_loss = 0.69380325, time/batch = 0.0526s\n",
            "60601/63080 (epoch 9.607), train_loss = 0.64714730, time/batch = 0.0521s\n",
            "60602/63080 (epoch 9.607), train_loss = 0.65092415, time/batch = 0.0524s\n",
            "60603/63080 (epoch 9.607), train_loss = 0.63050956, time/batch = 0.0525s\n",
            "60604/63080 (epoch 9.607), train_loss = 0.65691370, time/batch = 0.0527s\n",
            "60605/63080 (epoch 9.608), train_loss = 0.66145438, time/batch = 0.0524s\n",
            "60606/63080 (epoch 9.608), train_loss = 0.62047714, time/batch = 0.0526s\n",
            "60607/63080 (epoch 9.608), train_loss = 0.63374239, time/batch = 0.0524s\n",
            "60608/63080 (epoch 9.608), train_loss = 0.64698279, time/batch = 0.0526s\n",
            "60609/63080 (epoch 9.608), train_loss = 0.63152534, time/batch = 0.0521s\n",
            "60610/63080 (epoch 9.608), train_loss = 0.65851939, time/batch = 0.0529s\n",
            "60611/63080 (epoch 9.609), train_loss = 0.64088494, time/batch = 0.0530s\n",
            "60612/63080 (epoch 9.609), train_loss = 0.65103674, time/batch = 0.0524s\n",
            "60613/63080 (epoch 9.609), train_loss = 0.65529841, time/batch = 0.0531s\n",
            "60614/63080 (epoch 9.609), train_loss = 0.62729532, time/batch = 0.0525s\n",
            "60615/63080 (epoch 9.609), train_loss = 0.65141922, time/batch = 0.0529s\n",
            "60616/63080 (epoch 9.609), train_loss = 0.63705963, time/batch = 0.0527s\n",
            "60617/63080 (epoch 9.610), train_loss = 0.64861602, time/batch = 0.0523s\n",
            "60618/63080 (epoch 9.610), train_loss = 0.62631434, time/batch = 0.0527s\n",
            "60619/63080 (epoch 9.610), train_loss = 0.64651173, time/batch = 0.0526s\n",
            "60620/63080 (epoch 9.610), train_loss = 0.63274455, time/batch = 0.0531s\n",
            "60621/63080 (epoch 9.610), train_loss = 0.64839810, time/batch = 0.0533s\n",
            "60622/63080 (epoch 9.610), train_loss = 0.65872777, time/batch = 0.0525s\n",
            "60623/63080 (epoch 9.610), train_loss = 0.65617996, time/batch = 0.0525s\n",
            "60624/63080 (epoch 9.611), train_loss = 0.66179436, time/batch = 0.0527s\n",
            "60625/63080 (epoch 9.611), train_loss = 0.63116890, time/batch = 0.0525s\n",
            "60626/63080 (epoch 9.611), train_loss = 0.66363317, time/batch = 0.0516s\n",
            "60627/63080 (epoch 9.611), train_loss = 0.68061197, time/batch = 0.0524s\n",
            "60628/63080 (epoch 9.611), train_loss = 0.67047113, time/batch = 0.0523s\n",
            "60629/63080 (epoch 9.611), train_loss = 0.65506864, time/batch = 0.0525s\n",
            "60630/63080 (epoch 9.612), train_loss = 0.67583841, time/batch = 0.0525s\n",
            "60631/63080 (epoch 9.612), train_loss = 0.65629500, time/batch = 0.0524s\n",
            "60632/63080 (epoch 9.612), train_loss = 0.63887537, time/batch = 0.0524s\n",
            "60633/63080 (epoch 9.612), train_loss = 0.68105924, time/batch = 0.0529s\n",
            "60634/63080 (epoch 9.612), train_loss = 0.64704400, time/batch = 0.0526s\n",
            "60635/63080 (epoch 9.612), train_loss = 0.67469364, time/batch = 0.0531s\n",
            "60636/63080 (epoch 9.613), train_loss = 0.65272766, time/batch = 0.0525s\n",
            "60637/63080 (epoch 9.613), train_loss = 0.65833449, time/batch = 0.0528s\n",
            "60638/63080 (epoch 9.613), train_loss = 0.65628564, time/batch = 0.0524s\n",
            "60639/63080 (epoch 9.613), train_loss = 0.68820274, time/batch = 0.0529s\n",
            "60640/63080 (epoch 9.613), train_loss = 0.66226524, time/batch = 0.0572s\n",
            "60641/63080 (epoch 9.613), train_loss = 0.66958582, time/batch = 0.0525s\n",
            "60642/63080 (epoch 9.614), train_loss = 0.65393525, time/batch = 0.0523s\n",
            "60643/63080 (epoch 9.614), train_loss = 0.65276372, time/batch = 0.0526s\n",
            "60644/63080 (epoch 9.614), train_loss = 0.65514004, time/batch = 0.0525s\n",
            "60645/63080 (epoch 9.614), train_loss = 0.65340650, time/batch = 0.0528s\n",
            "60646/63080 (epoch 9.614), train_loss = 0.63877869, time/batch = 0.0522s\n",
            "60647/63080 (epoch 9.614), train_loss = 0.64225191, time/batch = 0.0528s\n",
            "60648/63080 (epoch 9.614), train_loss = 0.65688562, time/batch = 0.0530s\n",
            "60649/63080 (epoch 9.615), train_loss = 0.65044510, time/batch = 0.0526s\n",
            "60650/63080 (epoch 9.615), train_loss = 0.67142826, time/batch = 0.0539s\n",
            "60651/63080 (epoch 9.615), train_loss = 0.65071607, time/batch = 0.0525s\n",
            "60652/63080 (epoch 9.615), train_loss = 0.64379174, time/batch = 0.0526s\n",
            "60653/63080 (epoch 9.615), train_loss = 0.65650910, time/batch = 0.0525s\n",
            "60654/63080 (epoch 9.615), train_loss = 0.65395451, time/batch = 0.0528s\n",
            "60655/63080 (epoch 9.616), train_loss = 0.65273732, time/batch = 0.0525s\n",
            "60656/63080 (epoch 9.616), train_loss = 0.64499146, time/batch = 0.0521s\n",
            "60657/63080 (epoch 9.616), train_loss = 0.65936267, time/batch = 0.0526s\n",
            "60658/63080 (epoch 9.616), train_loss = 0.65476102, time/batch = 0.0527s\n",
            "60659/63080 (epoch 9.616), train_loss = 0.65900737, time/batch = 0.0526s\n",
            "60660/63080 (epoch 9.616), train_loss = 0.67579210, time/batch = 0.0528s\n",
            "60661/63080 (epoch 9.617), train_loss = 0.63886952, time/batch = 0.0520s\n",
            "60662/63080 (epoch 9.617), train_loss = 0.66211218, time/batch = 0.0525s\n",
            "60663/63080 (epoch 9.617), train_loss = 0.63550097, time/batch = 0.0533s\n",
            "60664/63080 (epoch 9.617), train_loss = 0.64222884, time/batch = 0.0527s\n",
            "60665/63080 (epoch 9.617), train_loss = 0.64764374, time/batch = 0.0536s\n",
            "60666/63080 (epoch 9.617), train_loss = 0.64825523, time/batch = 0.0524s\n",
            "60667/63080 (epoch 9.617), train_loss = 0.62847763, time/batch = 0.0526s\n",
            "60668/63080 (epoch 9.618), train_loss = 0.65889746, time/batch = 0.0525s\n",
            "60669/63080 (epoch 9.618), train_loss = 0.63934213, time/batch = 0.0523s\n",
            "60670/63080 (epoch 9.618), train_loss = 0.66315830, time/batch = 0.0528s\n",
            "60671/63080 (epoch 9.618), train_loss = 0.65270877, time/batch = 0.0519s\n",
            "60672/63080 (epoch 9.618), train_loss = 0.63866907, time/batch = 0.0522s\n",
            "60673/63080 (epoch 9.618), train_loss = 0.65390372, time/batch = 0.0523s\n",
            "60674/63080 (epoch 9.619), train_loss = 0.66260111, time/batch = 0.0526s\n",
            "60675/63080 (epoch 9.619), train_loss = 0.65854275, time/batch = 0.0522s\n",
            "60676/63080 (epoch 9.619), train_loss = 0.66688931, time/batch = 0.0523s\n",
            "60677/63080 (epoch 9.619), train_loss = 0.68366379, time/batch = 0.0525s\n",
            "60678/63080 (epoch 9.619), train_loss = 0.67271179, time/batch = 0.0525s\n",
            "60679/63080 (epoch 9.619), train_loss = 0.65327448, time/batch = 0.0523s\n",
            "60680/63080 (epoch 9.620), train_loss = 0.66452062, time/batch = 0.0526s\n",
            "60681/63080 (epoch 9.620), train_loss = 0.65890527, time/batch = 0.0525s\n",
            "60682/63080 (epoch 9.620), train_loss = 0.68464804, time/batch = 0.0523s\n",
            "60683/63080 (epoch 9.620), train_loss = 0.66944134, time/batch = 0.0526s\n",
            "60684/63080 (epoch 9.620), train_loss = 0.64566386, time/batch = 0.0530s\n",
            "60685/63080 (epoch 9.620), train_loss = 0.63392955, time/batch = 0.0527s\n",
            "60686/63080 (epoch 9.620), train_loss = 0.67696887, time/batch = 0.0523s\n",
            "60687/63080 (epoch 9.621), train_loss = 0.64694238, time/batch = 0.0528s\n",
            "60688/63080 (epoch 9.621), train_loss = 0.69115776, time/batch = 0.0524s\n",
            "60689/63080 (epoch 9.621), train_loss = 0.66219813, time/batch = 0.0536s\n",
            "60690/63080 (epoch 9.621), train_loss = 0.66937262, time/batch = 0.0524s\n",
            "60691/63080 (epoch 9.621), train_loss = 0.67354846, time/batch = 0.0522s\n",
            "60692/63080 (epoch 9.621), train_loss = 0.68640280, time/batch = 0.0524s\n",
            "60693/63080 (epoch 9.622), train_loss = 0.67403710, time/batch = 0.0527s\n",
            "60694/63080 (epoch 9.622), train_loss = 0.66488099, time/batch = 0.0530s\n",
            "60695/63080 (epoch 9.622), train_loss = 0.65868813, time/batch = 0.0523s\n",
            "60696/63080 (epoch 9.622), train_loss = 0.67295492, time/batch = 0.0531s\n",
            "60697/63080 (epoch 9.622), train_loss = 0.65064776, time/batch = 0.0525s\n",
            "60698/63080 (epoch 9.622), train_loss = 0.65633100, time/batch = 0.0529s\n",
            "60699/63080 (epoch 9.623), train_loss = 0.62426901, time/batch = 0.0529s\n",
            "60700/63080 (epoch 9.623), train_loss = 0.65514499, time/batch = 0.0528s\n",
            "60701/63080 (epoch 9.623), train_loss = 0.62071812, time/batch = 0.0533s\n",
            "60702/63080 (epoch 9.623), train_loss = 0.63757873, time/batch = 0.0523s\n",
            "60703/63080 (epoch 9.623), train_loss = 0.64282221, time/batch = 0.0527s\n",
            "60704/63080 (epoch 9.623), train_loss = 0.67181498, time/batch = 0.0519s\n",
            "60705/63080 (epoch 9.623), train_loss = 0.65615970, time/batch = 0.0528s\n",
            "60706/63080 (epoch 9.624), train_loss = 0.64932764, time/batch = 0.0526s\n",
            "60707/63080 (epoch 9.624), train_loss = 0.65697920, time/batch = 0.0527s\n",
            "60708/63080 (epoch 9.624), train_loss = 0.66111594, time/batch = 0.0526s\n",
            "60709/63080 (epoch 9.624), train_loss = 0.66101134, time/batch = 0.0525s\n",
            "60710/63080 (epoch 9.624), train_loss = 0.65586835, time/batch = 0.0524s\n",
            "60711/63080 (epoch 9.624), train_loss = 0.65022087, time/batch = 0.0527s\n",
            "60712/63080 (epoch 9.625), train_loss = 0.66639495, time/batch = 0.0522s\n",
            "60713/63080 (epoch 9.625), train_loss = 0.64205450, time/batch = 0.0528s\n",
            "60714/63080 (epoch 9.625), train_loss = 0.66138947, time/batch = 0.0525s\n",
            "60715/63080 (epoch 9.625), train_loss = 0.66609699, time/batch = 0.0526s\n",
            "60716/63080 (epoch 9.625), train_loss = 0.65047026, time/batch = 0.0524s\n",
            "60717/63080 (epoch 9.625), train_loss = 0.64883435, time/batch = 0.0525s\n",
            "60718/63080 (epoch 9.626), train_loss = 0.66351342, time/batch = 0.0530s\n",
            "60719/63080 (epoch 9.626), train_loss = 0.65643442, time/batch = 0.0532s\n",
            "60720/63080 (epoch 9.626), train_loss = 0.63987315, time/batch = 0.0529s\n",
            "60721/63080 (epoch 9.626), train_loss = 0.64673108, time/batch = 0.0523s\n",
            "60722/63080 (epoch 9.626), train_loss = 0.66099781, time/batch = 0.0530s\n",
            "60723/63080 (epoch 9.626), train_loss = 0.65193856, time/batch = 0.0524s\n",
            "60724/63080 (epoch 9.627), train_loss = 0.67454576, time/batch = 0.0526s\n",
            "60725/63080 (epoch 9.627), train_loss = 0.63945812, time/batch = 0.0524s\n",
            "60726/63080 (epoch 9.627), train_loss = 0.66329253, time/batch = 0.0528s\n",
            "60727/63080 (epoch 9.627), train_loss = 0.66346925, time/batch = 0.0523s\n",
            "60728/63080 (epoch 9.627), train_loss = 0.67376626, time/batch = 0.0526s\n",
            "60729/63080 (epoch 9.627), train_loss = 0.66176516, time/batch = 0.0525s\n",
            "60730/63080 (epoch 9.627), train_loss = 0.64137137, time/batch = 0.0527s\n",
            "60731/63080 (epoch 9.628), train_loss = 0.65772027, time/batch = 0.0522s\n",
            "60732/63080 (epoch 9.628), train_loss = 0.65787214, time/batch = 0.0533s\n",
            "60733/63080 (epoch 9.628), train_loss = 0.66115814, time/batch = 0.0522s\n",
            "60734/63080 (epoch 9.628), train_loss = 0.66322529, time/batch = 0.0525s\n",
            "60735/63080 (epoch 9.628), train_loss = 0.66010392, time/batch = 0.0527s\n",
            "60736/63080 (epoch 9.628), train_loss = 0.68388540, time/batch = 0.0525s\n",
            "60737/63080 (epoch 9.629), train_loss = 0.66948491, time/batch = 0.0540s\n",
            "60738/63080 (epoch 9.629), train_loss = 0.67505985, time/batch = 0.0535s\n",
            "60739/63080 (epoch 9.629), train_loss = 0.65886658, time/batch = 0.0523s\n",
            "60740/63080 (epoch 9.629), train_loss = 0.65282226, time/batch = 0.0532s\n",
            "60741/63080 (epoch 9.629), train_loss = 0.65520853, time/batch = 0.0525s\n",
            "60742/63080 (epoch 9.629), train_loss = 0.68208820, time/batch = 0.0525s\n",
            "60743/63080 (epoch 9.630), train_loss = 0.65985000, time/batch = 0.0526s\n",
            "60744/63080 (epoch 9.630), train_loss = 0.66977572, time/batch = 0.0527s\n",
            "60745/63080 (epoch 9.630), train_loss = 0.64550221, time/batch = 0.0525s\n",
            "60746/63080 (epoch 9.630), train_loss = 0.63261664, time/batch = 0.0526s\n",
            "60747/63080 (epoch 9.630), train_loss = 0.65806615, time/batch = 0.0524s\n",
            "60748/63080 (epoch 9.630), train_loss = 0.64709121, time/batch = 0.0527s\n",
            "60749/63080 (epoch 9.630), train_loss = 0.65657431, time/batch = 0.0523s\n",
            "60750/63080 (epoch 9.631), train_loss = 0.64216316, time/batch = 0.0527s\n",
            "60751/63080 (epoch 9.631), train_loss = 0.66340536, time/batch = 0.0523s\n",
            "60752/63080 (epoch 9.631), train_loss = 0.65165693, time/batch = 0.0542s\n",
            "60753/63080 (epoch 9.631), train_loss = 0.65027380, time/batch = 0.0520s\n",
            "60754/63080 (epoch 9.631), train_loss = 0.65746081, time/batch = 0.0531s\n",
            "60755/63080 (epoch 9.631), train_loss = 0.65381849, time/batch = 0.0525s\n",
            "60756/63080 (epoch 9.632), train_loss = 0.66343576, time/batch = 0.0529s\n",
            "60757/63080 (epoch 9.632), train_loss = 0.66070473, time/batch = 0.0525s\n",
            "60758/63080 (epoch 9.632), train_loss = 0.67625982, time/batch = 0.0525s\n",
            "60759/63080 (epoch 9.632), train_loss = 0.66755527, time/batch = 0.0524s\n",
            "60760/63080 (epoch 9.632), train_loss = 0.63267750, time/batch = 0.0532s\n",
            "60761/63080 (epoch 9.632), train_loss = 0.63873255, time/batch = 0.0529s\n",
            "60762/63080 (epoch 9.633), train_loss = 0.63782674, time/batch = 0.0522s\n",
            "60763/63080 (epoch 9.633), train_loss = 0.66660297, time/batch = 0.0524s\n",
            "60764/63080 (epoch 9.633), train_loss = 0.63905358, time/batch = 0.0525s\n",
            "60765/63080 (epoch 9.633), train_loss = 0.64335209, time/batch = 0.0527s\n",
            "60766/63080 (epoch 9.633), train_loss = 0.64431375, time/batch = 0.0529s\n",
            "60767/63080 (epoch 9.633), train_loss = 0.64923620, time/batch = 0.0526s\n",
            "60768/63080 (epoch 9.633), train_loss = 0.66677314, time/batch = 0.0524s\n",
            "60769/63080 (epoch 9.634), train_loss = 0.66482192, time/batch = 0.0527s\n",
            "60770/63080 (epoch 9.634), train_loss = 0.68213117, time/batch = 0.0525s\n",
            "60771/63080 (epoch 9.634), train_loss = 0.66259074, time/batch = 0.0521s\n",
            "60772/63080 (epoch 9.634), train_loss = 0.67336065, time/batch = 0.0518s\n",
            "60773/63080 (epoch 9.634), train_loss = 0.65786737, time/batch = 0.0523s\n",
            "60774/63080 (epoch 9.634), train_loss = 0.65831095, time/batch = 0.0529s\n",
            "60775/63080 (epoch 9.635), train_loss = 0.65920895, time/batch = 0.0540s\n",
            "60776/63080 (epoch 9.635), train_loss = 0.63794810, time/batch = 0.0525s\n",
            "60777/63080 (epoch 9.635), train_loss = 0.67439687, time/batch = 0.0525s\n",
            "60778/63080 (epoch 9.635), train_loss = 0.65801716, time/batch = 0.0524s\n",
            "60779/63080 (epoch 9.635), train_loss = 0.66116297, time/batch = 0.0527s\n",
            "60780/63080 (epoch 9.635), train_loss = 0.67080730, time/batch = 0.0532s\n",
            "60781/63080 (epoch 9.636), train_loss = 0.67743862, time/batch = 0.0523s\n",
            "60782/63080 (epoch 9.636), train_loss = 0.67095983, time/batch = 0.0527s\n",
            "60783/63080 (epoch 9.636), train_loss = 0.65693271, time/batch = 0.0527s\n",
            "60784/63080 (epoch 9.636), train_loss = 0.66805893, time/batch = 0.0526s\n",
            "60785/63080 (epoch 9.636), train_loss = 0.66078389, time/batch = 0.0526s\n",
            "60786/63080 (epoch 9.636), train_loss = 0.66390735, time/batch = 0.0533s\n",
            "60787/63080 (epoch 9.636), train_loss = 0.67014194, time/batch = 0.0526s\n",
            "60788/63080 (epoch 9.637), train_loss = 0.68057394, time/batch = 0.0525s\n",
            "60789/63080 (epoch 9.637), train_loss = 0.66785806, time/batch = 0.0523s\n",
            "60790/63080 (epoch 9.637), train_loss = 0.68405545, time/batch = 0.0528s\n",
            "60791/63080 (epoch 9.637), train_loss = 0.67186052, time/batch = 0.0527s\n",
            "60792/63080 (epoch 9.637), train_loss = 0.68251294, time/batch = 0.0521s\n",
            "60793/63080 (epoch 9.637), train_loss = 0.66978908, time/batch = 0.0533s\n",
            "60794/63080 (epoch 9.638), train_loss = 0.65751088, time/batch = 0.0524s\n",
            "60795/63080 (epoch 9.638), train_loss = 0.68450785, time/batch = 0.0530s\n",
            "60796/63080 (epoch 9.638), train_loss = 0.65119600, time/batch = 0.0524s\n",
            "60797/63080 (epoch 9.638), train_loss = 0.65565890, time/batch = 0.0524s\n",
            "60798/63080 (epoch 9.638), train_loss = 0.67224431, time/batch = 0.0523s\n",
            "60799/63080 (epoch 9.638), train_loss = 0.63927615, time/batch = 0.0527s\n",
            "60800/63080 (epoch 9.639), train_loss = 0.66758317, time/batch = 0.0535s\n",
            "60801/63080 (epoch 9.639), train_loss = 0.65584528, time/batch = 0.0528s\n",
            "60802/63080 (epoch 9.639), train_loss = 0.64044267, time/batch = 0.0525s\n",
            "60803/63080 (epoch 9.639), train_loss = 0.64899963, time/batch = 0.0527s\n",
            "60804/63080 (epoch 9.639), train_loss = 0.64216763, time/batch = 0.0525s\n",
            "60805/63080 (epoch 9.639), train_loss = 0.66826689, time/batch = 0.0527s\n",
            "60806/63080 (epoch 9.640), train_loss = 0.64288712, time/batch = 0.0523s\n",
            "60807/63080 (epoch 9.640), train_loss = 0.66440088, time/batch = 0.0525s\n",
            "60808/63080 (epoch 9.640), train_loss = 0.68426239, time/batch = 0.0527s\n",
            "60809/63080 (epoch 9.640), train_loss = 0.68400049, time/batch = 0.0526s\n",
            "60810/63080 (epoch 9.640), train_loss = 0.66085714, time/batch = 0.0527s\n",
            "60811/63080 (epoch 9.640), train_loss = 0.67047411, time/batch = 0.0517s\n",
            "60812/63080 (epoch 9.640), train_loss = 0.65662760, time/batch = 0.0523s\n",
            "60813/63080 (epoch 9.641), train_loss = 0.65984869, time/batch = 0.0525s\n",
            "60814/63080 (epoch 9.641), train_loss = 0.65001291, time/batch = 0.0526s\n",
            "60815/63080 (epoch 9.641), train_loss = 0.65643007, time/batch = 0.0529s\n",
            "60816/63080 (epoch 9.641), train_loss = 0.63514394, time/batch = 0.0527s\n",
            "60817/63080 (epoch 9.641), train_loss = 0.64373749, time/batch = 0.0527s\n",
            "60818/63080 (epoch 9.641), train_loss = 0.65073770, time/batch = 0.0520s\n",
            "60819/63080 (epoch 9.642), train_loss = 0.64740396, time/batch = 0.0532s\n",
            "60820/63080 (epoch 9.642), train_loss = 0.65094250, time/batch = 0.0534s\n",
            "60821/63080 (epoch 9.642), train_loss = 0.63844121, time/batch = 0.0522s\n",
            "60822/63080 (epoch 9.642), train_loss = 0.63979870, time/batch = 0.0523s\n",
            "60823/63080 (epoch 9.642), train_loss = 0.64937562, time/batch = 0.0525s\n",
            "60824/63080 (epoch 9.642), train_loss = 0.65153891, time/batch = 0.0554s\n",
            "60825/63080 (epoch 9.643), train_loss = 0.65355933, time/batch = 0.0529s\n",
            "60826/63080 (epoch 9.643), train_loss = 0.64736909, time/batch = 0.0533s\n",
            "60827/63080 (epoch 9.643), train_loss = 0.66765845, time/batch = 0.0528s\n",
            "60828/63080 (epoch 9.643), train_loss = 0.65594858, time/batch = 0.0524s\n",
            "60829/63080 (epoch 9.643), train_loss = 0.66850656, time/batch = 0.0524s\n",
            "60830/63080 (epoch 9.643), train_loss = 0.64571321, time/batch = 0.0525s\n",
            "60831/63080 (epoch 9.643), train_loss = 0.65320963, time/batch = 0.0512s\n",
            "60832/63080 (epoch 9.644), train_loss = 0.64221275, time/batch = 0.0528s\n",
            "60833/63080 (epoch 9.644), train_loss = 0.62965328, time/batch = 0.0528s\n",
            "60834/63080 (epoch 9.644), train_loss = 0.64930928, time/batch = 0.0533s\n",
            "60835/63080 (epoch 9.644), train_loss = 0.64670879, time/batch = 0.0527s\n",
            "60836/63080 (epoch 9.644), train_loss = 0.63992804, time/batch = 0.0528s\n",
            "60837/63080 (epoch 9.644), train_loss = 0.63390529, time/batch = 0.0535s\n",
            "60838/63080 (epoch 9.645), train_loss = 0.62516481, time/batch = 0.0526s\n",
            "60839/63080 (epoch 9.645), train_loss = 0.60083252, time/batch = 0.0542s\n",
            "60840/63080 (epoch 9.645), train_loss = 0.63288468, time/batch = 0.0527s\n",
            "60841/63080 (epoch 9.645), train_loss = 0.62547284, time/batch = 0.0520s\n",
            "60842/63080 (epoch 9.645), train_loss = 0.63616067, time/batch = 0.0523s\n",
            "60843/63080 (epoch 9.645), train_loss = 0.64014566, time/batch = 0.0525s\n",
            "60844/63080 (epoch 9.646), train_loss = 0.62847114, time/batch = 0.0539s\n",
            "60845/63080 (epoch 9.646), train_loss = 0.65882039, time/batch = 0.0523s\n",
            "60846/63080 (epoch 9.646), train_loss = 0.61871195, time/batch = 0.0526s\n",
            "60847/63080 (epoch 9.646), train_loss = 0.64171058, time/batch = 0.0525s\n",
            "60848/63080 (epoch 9.646), train_loss = 0.63770133, time/batch = 0.0528s\n",
            "60849/63080 (epoch 9.646), train_loss = 0.65316999, time/batch = 0.0526s\n",
            "60850/63080 (epoch 9.646), train_loss = 0.64168668, time/batch = 0.0521s\n",
            "60851/63080 (epoch 9.647), train_loss = 0.62772220, time/batch = 0.0524s\n",
            "60852/63080 (epoch 9.647), train_loss = 0.64914560, time/batch = 0.0526s\n",
            "60853/63080 (epoch 9.647), train_loss = 0.64875370, time/batch = 0.0539s\n",
            "60854/63080 (epoch 9.647), train_loss = 0.64429879, time/batch = 0.0528s\n",
            "60855/63080 (epoch 9.647), train_loss = 0.65907305, time/batch = 0.0526s\n",
            "60856/63080 (epoch 9.647), train_loss = 0.64180797, time/batch = 0.0532s\n",
            "60857/63080 (epoch 9.648), train_loss = 0.65297478, time/batch = 0.0525s\n",
            "60858/63080 (epoch 9.648), train_loss = 0.65524071, time/batch = 0.0526s\n",
            "60859/63080 (epoch 9.648), train_loss = 0.67009509, time/batch = 0.0521s\n",
            "60860/63080 (epoch 9.648), train_loss = 0.63720936, time/batch = 0.0528s\n",
            "60861/63080 (epoch 9.648), train_loss = 0.65755212, time/batch = 0.0522s\n",
            "60862/63080 (epoch 9.648), train_loss = 0.64911693, time/batch = 0.0525s\n",
            "60863/63080 (epoch 9.649), train_loss = 0.64182794, time/batch = 0.0528s\n",
            "60864/63080 (epoch 9.649), train_loss = 0.62130147, time/batch = 0.0526s\n",
            "60865/63080 (epoch 9.649), train_loss = 0.65556991, time/batch = 0.0525s\n",
            "60866/63080 (epoch 9.649), train_loss = 0.65437192, time/batch = 0.0529s\n",
            "60867/63080 (epoch 9.649), train_loss = 0.64920485, time/batch = 0.0528s\n",
            "60868/63080 (epoch 9.649), train_loss = 0.65013707, time/batch = 0.0531s\n",
            "60869/63080 (epoch 9.649), train_loss = 0.65803570, time/batch = 0.0519s\n",
            "60870/63080 (epoch 9.650), train_loss = 0.64141536, time/batch = 0.0525s\n",
            "60871/63080 (epoch 9.650), train_loss = 0.62429214, time/batch = 0.0522s\n",
            "60872/63080 (epoch 9.650), train_loss = 0.66572428, time/batch = 0.0529s\n",
            "60873/63080 (epoch 9.650), train_loss = 0.63380873, time/batch = 0.0528s\n",
            "60874/63080 (epoch 9.650), train_loss = 0.61144596, time/batch = 0.0526s\n",
            "60875/63080 (epoch 9.650), train_loss = 0.66042107, time/batch = 0.0525s\n",
            "60876/63080 (epoch 9.651), train_loss = 0.63091666, time/batch = 0.0537s\n",
            "60877/63080 (epoch 9.651), train_loss = 0.65260595, time/batch = 0.0530s\n",
            "60878/63080 (epoch 9.651), train_loss = 0.66168630, time/batch = 0.0524s\n",
            "60879/63080 (epoch 9.651), train_loss = 0.64945412, time/batch = 0.0522s\n",
            "60880/63080 (epoch 9.651), train_loss = 0.64590740, time/batch = 0.0529s\n",
            "60881/63080 (epoch 9.651), train_loss = 0.63585156, time/batch = 0.0528s\n",
            "60882/63080 (epoch 9.652), train_loss = 0.62956482, time/batch = 0.0532s\n",
            "60883/63080 (epoch 9.652), train_loss = 0.64186770, time/batch = 0.0526s\n",
            "60884/63080 (epoch 9.652), train_loss = 0.63817805, time/batch = 0.0524s\n",
            "60885/63080 (epoch 9.652), train_loss = 0.64200830, time/batch = 0.0527s\n",
            "60886/63080 (epoch 9.652), train_loss = 0.64358217, time/batch = 0.0522s\n",
            "60887/63080 (epoch 9.652), train_loss = 0.64530551, time/batch = 0.0529s\n",
            "60888/63080 (epoch 9.653), train_loss = 0.63619047, time/batch = 0.0519s\n",
            "60889/63080 (epoch 9.653), train_loss = 0.62755263, time/batch = 0.0523s\n",
            "60890/63080 (epoch 9.653), train_loss = 0.63472086, time/batch = 0.0529s\n",
            "60891/63080 (epoch 9.653), train_loss = 0.65191638, time/batch = 0.0530s\n",
            "60892/63080 (epoch 9.653), train_loss = 0.65415812, time/batch = 0.0529s\n",
            "60893/63080 (epoch 9.653), train_loss = 0.63061684, time/batch = 0.0529s\n",
            "60894/63080 (epoch 9.653), train_loss = 0.65415299, time/batch = 0.0528s\n",
            "60895/63080 (epoch 9.654), train_loss = 0.64286691, time/batch = 0.0524s\n",
            "60896/63080 (epoch 9.654), train_loss = 0.64073855, time/batch = 0.0525s\n",
            "60897/63080 (epoch 9.654), train_loss = 0.66167349, time/batch = 0.0526s\n",
            "60898/63080 (epoch 9.654), train_loss = 0.66523588, time/batch = 0.0524s\n",
            "60899/63080 (epoch 9.654), train_loss = 0.64543295, time/batch = 0.0523s\n",
            "60900/63080 (epoch 9.654), train_loss = 0.64165264, time/batch = 0.0526s\n",
            "60901/63080 (epoch 9.655), train_loss = 0.64360154, time/batch = 0.0525s\n",
            "60902/63080 (epoch 9.655), train_loss = 0.65069705, time/batch = 0.0531s\n",
            "60903/63080 (epoch 9.655), train_loss = 0.65901846, time/batch = 0.0527s\n",
            "60904/63080 (epoch 9.655), train_loss = 0.67196059, time/batch = 0.0523s\n",
            "60905/63080 (epoch 9.655), train_loss = 0.67579776, time/batch = 0.0530s\n",
            "60906/63080 (epoch 9.655), train_loss = 0.62819940, time/batch = 0.0527s\n",
            "60907/63080 (epoch 9.656), train_loss = 0.64578831, time/batch = 0.0525s\n",
            "60908/63080 (epoch 9.656), train_loss = 0.67795175, time/batch = 0.0523s\n",
            "60909/63080 (epoch 9.656), train_loss = 0.66538644, time/batch = 0.0531s\n",
            "60910/63080 (epoch 9.656), train_loss = 0.65801167, time/batch = 0.0530s\n",
            "60911/63080 (epoch 9.656), train_loss = 0.66314709, time/batch = 0.0523s\n",
            "60912/63080 (epoch 9.656), train_loss = 0.64314431, time/batch = 0.0526s\n",
            "60913/63080 (epoch 9.656), train_loss = 0.63194501, time/batch = 0.0524s\n",
            "60914/63080 (epoch 9.657), train_loss = 0.62705815, time/batch = 0.0528s\n",
            "60915/63080 (epoch 9.657), train_loss = 0.64832765, time/batch = 0.0524s\n",
            "60916/63080 (epoch 9.657), train_loss = 0.63474435, time/batch = 0.0526s\n",
            "60917/63080 (epoch 9.657), train_loss = 0.63817030, time/batch = 0.0525s\n",
            "60918/63080 (epoch 9.657), train_loss = 0.63065100, time/batch = 0.0524s\n",
            "60919/63080 (epoch 9.657), train_loss = 0.63301939, time/batch = 0.0526s\n",
            "60920/63080 (epoch 9.658), train_loss = 0.64379680, time/batch = 0.0533s\n",
            "60921/63080 (epoch 9.658), train_loss = 0.63088101, time/batch = 0.0523s\n",
            "60922/63080 (epoch 9.658), train_loss = 0.63493448, time/batch = 0.0523s\n",
            "60923/63080 (epoch 9.658), train_loss = 0.67198378, time/batch = 0.0535s\n",
            "60924/63080 (epoch 9.658), train_loss = 0.65560877, time/batch = 0.0524s\n",
            "60925/63080 (epoch 9.658), train_loss = 0.65823328, time/batch = 0.0530s\n",
            "60926/63080 (epoch 9.659), train_loss = 0.64146888, time/batch = 0.0515s\n",
            "60927/63080 (epoch 9.659), train_loss = 0.65344971, time/batch = 0.0528s\n",
            "60928/63080 (epoch 9.659), train_loss = 0.65201318, time/batch = 0.0525s\n",
            "60929/63080 (epoch 9.659), train_loss = 0.66309392, time/batch = 0.0525s\n",
            "60930/63080 (epoch 9.659), train_loss = 0.65829778, time/batch = 0.0540s\n",
            "60931/63080 (epoch 9.659), train_loss = 0.62816203, time/batch = 0.0523s\n",
            "60932/63080 (epoch 9.659), train_loss = 0.62768716, time/batch = 0.0529s\n",
            "60933/63080 (epoch 9.660), train_loss = 0.64563507, time/batch = 0.0526s\n",
            "60934/63080 (epoch 9.660), train_loss = 0.63799584, time/batch = 0.0525s\n",
            "60935/63080 (epoch 9.660), train_loss = 0.66772038, time/batch = 0.0540s\n",
            "60936/63080 (epoch 9.660), train_loss = 0.64085811, time/batch = 0.0519s\n",
            "60937/63080 (epoch 9.660), train_loss = 0.64130008, time/batch = 0.0525s\n",
            "60938/63080 (epoch 9.660), train_loss = 0.65787470, time/batch = 0.0523s\n",
            "60939/63080 (epoch 9.661), train_loss = 0.66879267, time/batch = 0.0527s\n",
            "60940/63080 (epoch 9.661), train_loss = 0.66623384, time/batch = 0.0530s\n",
            "60941/63080 (epoch 9.661), train_loss = 0.63301063, time/batch = 0.0529s\n",
            "60942/63080 (epoch 9.661), train_loss = 0.64984006, time/batch = 0.0523s\n",
            "60943/63080 (epoch 9.661), train_loss = 0.62635326, time/batch = 0.0529s\n",
            "60944/63080 (epoch 9.661), train_loss = 0.64050806, time/batch = 0.0527s\n",
            "60945/63080 (epoch 9.662), train_loss = 0.64978027, time/batch = 0.0524s\n",
            "60946/63080 (epoch 9.662), train_loss = 0.62828118, time/batch = 0.0524s\n",
            "60947/63080 (epoch 9.662), train_loss = 0.63602328, time/batch = 0.0524s\n",
            "60948/63080 (epoch 9.662), train_loss = 0.65043920, time/batch = 0.0522s\n",
            "60949/63080 (epoch 9.662), train_loss = 0.65335244, time/batch = 0.0527s\n",
            "60950/63080 (epoch 9.662), train_loss = 0.67490214, time/batch = 0.0528s\n",
            "60951/63080 (epoch 9.662), train_loss = 0.66782343, time/batch = 0.0528s\n",
            "60952/63080 (epoch 9.663), train_loss = 0.63875794, time/batch = 0.0525s\n",
            "60953/63080 (epoch 9.663), train_loss = 0.65288752, time/batch = 0.0523s\n",
            "60954/63080 (epoch 9.663), train_loss = 0.66680384, time/batch = 0.0527s\n",
            "60955/63080 (epoch 9.663), train_loss = 0.65239966, time/batch = 0.0525s\n",
            "60956/63080 (epoch 9.663), train_loss = 0.64283895, time/batch = 0.0526s\n",
            "60957/63080 (epoch 9.663), train_loss = 0.65801102, time/batch = 0.0528s\n",
            "60958/63080 (epoch 9.664), train_loss = 0.67652512, time/batch = 0.0525s\n",
            "60959/63080 (epoch 9.664), train_loss = 0.65776253, time/batch = 0.0525s\n",
            "60960/63080 (epoch 9.664), train_loss = 0.64707142, time/batch = 0.0528s\n",
            "60961/63080 (epoch 9.664), train_loss = 0.68330479, time/batch = 0.0525s\n",
            "60962/63080 (epoch 9.664), train_loss = 0.63998896, time/batch = 0.0535s\n",
            "60963/63080 (epoch 9.664), train_loss = 0.67281491, time/batch = 0.0525s\n",
            "60964/63080 (epoch 9.665), train_loss = 0.67713350, time/batch = 0.0521s\n",
            "60965/63080 (epoch 9.665), train_loss = 0.66557854, time/batch = 0.0528s\n",
            "60966/63080 (epoch 9.665), train_loss = 0.66480213, time/batch = 0.0532s\n",
            "60967/63080 (epoch 9.665), train_loss = 0.64901221, time/batch = 0.0525s\n",
            "60968/63080 (epoch 9.665), train_loss = 0.67714828, time/batch = 0.0535s\n",
            "60969/63080 (epoch 9.665), train_loss = 0.62257618, time/batch = 0.0525s\n",
            "60970/63080 (epoch 9.666), train_loss = 0.63831848, time/batch = 0.0525s\n",
            "60971/63080 (epoch 9.666), train_loss = 0.65499568, time/batch = 0.0522s\n",
            "60972/63080 (epoch 9.666), train_loss = 0.66344792, time/batch = 0.0525s\n",
            "60973/63080 (epoch 9.666), train_loss = 0.65730125, time/batch = 0.0534s\n",
            "60974/63080 (epoch 9.666), train_loss = 0.63782310, time/batch = 0.0526s\n",
            "60975/63080 (epoch 9.666), train_loss = 0.64876950, time/batch = 0.0526s\n",
            "60976/63080 (epoch 9.666), train_loss = 0.64034140, time/batch = 0.0529s\n",
            "60977/63080 (epoch 9.667), train_loss = 0.64597243, time/batch = 0.0527s\n",
            "60978/63080 (epoch 9.667), train_loss = 0.63774329, time/batch = 0.0529s\n",
            "60979/63080 (epoch 9.667), train_loss = 0.64503115, time/batch = 0.0526s\n",
            "60980/63080 (epoch 9.667), train_loss = 0.62902552, time/batch = 0.0529s\n",
            "60981/63080 (epoch 9.667), train_loss = 0.65202922, time/batch = 0.0524s\n",
            "60982/63080 (epoch 9.667), train_loss = 0.64167511, time/batch = 0.0524s\n",
            "60983/63080 (epoch 9.668), train_loss = 0.64081478, time/batch = 0.0528s\n",
            "60984/63080 (epoch 9.668), train_loss = 0.63429326, time/batch = 0.0522s\n",
            "60985/63080 (epoch 9.668), train_loss = 0.65022427, time/batch = 0.0523s\n",
            "60986/63080 (epoch 9.668), train_loss = 0.65189368, time/batch = 0.0528s\n",
            "60987/63080 (epoch 9.668), train_loss = 0.66157401, time/batch = 0.0525s\n",
            "60988/63080 (epoch 9.668), train_loss = 0.64882511, time/batch = 0.0525s\n",
            "60989/63080 (epoch 9.669), train_loss = 0.63945323, time/batch = 0.0523s\n",
            "60990/63080 (epoch 9.669), train_loss = 0.65571958, time/batch = 0.0528s\n",
            "60991/63080 (epoch 9.669), train_loss = 0.64195704, time/batch = 0.0524s\n",
            "60992/63080 (epoch 9.669), train_loss = 0.64028281, time/batch = 0.0522s\n",
            "60993/63080 (epoch 9.669), train_loss = 0.65040570, time/batch = 0.0525s\n",
            "60994/63080 (epoch 9.669), train_loss = 0.64789939, time/batch = 0.0526s\n",
            "60995/63080 (epoch 9.669), train_loss = 0.64387977, time/batch = 0.0536s\n",
            "60996/63080 (epoch 9.670), train_loss = 0.64996582, time/batch = 0.0525s\n",
            "60997/63080 (epoch 9.670), train_loss = 0.64949274, time/batch = 0.0523s\n",
            "60998/63080 (epoch 9.670), train_loss = 0.65074408, time/batch = 0.0527s\n",
            "60999/63080 (epoch 9.670), train_loss = 0.66491723, time/batch = 0.0524s\n",
            "evaluating loss over split index 1\n",
            "1/333...\n",
            "2/333...\n",
            "3/333...\n",
            "4/333...\n",
            "5/333...\n",
            "6/333...\n",
            "7/333...\n",
            "8/333...\n",
            "9/333...\n",
            "10/333...\n",
            "11/333...\n",
            "12/333...\n",
            "13/333...\n",
            "14/333...\n",
            "15/333...\n",
            "16/333...\n",
            "17/333...\n",
            "18/333...\n",
            "19/333...\n",
            "20/333...\n",
            "21/333...\n",
            "22/333...\n",
            "23/333...\n",
            "24/333...\n",
            "25/333...\n",
            "26/333...\n",
            "27/333...\n",
            "28/333...\n",
            "29/333...\n",
            "30/333...\n",
            "31/333...\n",
            "32/333...\n",
            "33/333...\n",
            "34/333...\n",
            "35/333...\n",
            "36/333...\n",
            "37/333...\n",
            "38/333...\n",
            "39/333...\n",
            "40/333...\n",
            "41/333...\n",
            "42/333...\n",
            "43/333...\n",
            "44/333...\n",
            "45/333...\n",
            "46/333...\n",
            "47/333...\n",
            "48/333...\n",
            "49/333...\n",
            "50/333...\n",
            "51/333...\n",
            "52/333...\n",
            "53/333...\n",
            "54/333...\n",
            "55/333...\n",
            "56/333...\n",
            "57/333...\n",
            "58/333...\n",
            "59/333...\n",
            "60/333...\n",
            "61/333...\n",
            "62/333...\n",
            "63/333...\n",
            "64/333...\n",
            "65/333...\n",
            "66/333...\n",
            "67/333...\n",
            "68/333...\n",
            "69/333...\n",
            "70/333...\n",
            "71/333...\n",
            "72/333...\n",
            "73/333...\n",
            "74/333...\n",
            "75/333...\n",
            "76/333...\n",
            "77/333...\n",
            "78/333...\n",
            "79/333...\n",
            "80/333...\n",
            "81/333...\n",
            "82/333...\n",
            "83/333...\n",
            "84/333...\n",
            "85/333...\n",
            "86/333...\n",
            "87/333...\n",
            "88/333...\n",
            "89/333...\n",
            "90/333...\n",
            "91/333...\n",
            "92/333...\n",
            "93/333...\n",
            "94/333...\n",
            "95/333...\n",
            "96/333...\n",
            "97/333...\n",
            "98/333...\n",
            "99/333...\n",
            "100/333...\n",
            "101/333...\n",
            "102/333...\n",
            "103/333...\n",
            "104/333...\n",
            "105/333...\n",
            "106/333...\n",
            "107/333...\n",
            "108/333...\n",
            "109/333...\n",
            "110/333...\n",
            "111/333...\n",
            "112/333...\n",
            "113/333...\n",
            "114/333...\n",
            "115/333...\n",
            "116/333...\n",
            "117/333...\n",
            "118/333...\n",
            "119/333...\n",
            "120/333...\n",
            "121/333...\n",
            "122/333...\n",
            "123/333...\n",
            "124/333...\n",
            "125/333...\n",
            "126/333...\n",
            "127/333...\n",
            "128/333...\n",
            "129/333...\n",
            "130/333...\n",
            "131/333...\n",
            "132/333...\n",
            "133/333...\n",
            "134/333...\n",
            "135/333...\n",
            "136/333...\n",
            "137/333...\n",
            "138/333...\n",
            "139/333...\n",
            "140/333...\n",
            "141/333...\n",
            "142/333...\n",
            "143/333...\n",
            "144/333...\n",
            "145/333...\n",
            "146/333...\n",
            "147/333...\n",
            "148/333...\n",
            "149/333...\n",
            "150/333...\n",
            "151/333...\n",
            "152/333...\n",
            "153/333...\n",
            "154/333...\n",
            "155/333...\n",
            "156/333...\n",
            "157/333...\n",
            "158/333...\n",
            "159/333...\n",
            "160/333...\n",
            "161/333...\n",
            "162/333...\n",
            "163/333...\n",
            "164/333...\n",
            "165/333...\n",
            "166/333...\n",
            "167/333...\n",
            "168/333...\n",
            "169/333...\n",
            "170/333...\n",
            "171/333...\n",
            "172/333...\n",
            "173/333...\n",
            "174/333...\n",
            "175/333...\n",
            "176/333...\n",
            "177/333...\n",
            "178/333...\n",
            "179/333...\n",
            "180/333...\n",
            "181/333...\n",
            "182/333...\n",
            "183/333...\n",
            "184/333...\n",
            "185/333...\n",
            "186/333...\n",
            "187/333...\n",
            "188/333...\n",
            "189/333...\n",
            "190/333...\n",
            "191/333...\n",
            "192/333...\n",
            "193/333...\n",
            "194/333...\n",
            "195/333...\n",
            "196/333...\n",
            "197/333...\n",
            "198/333...\n",
            "199/333...\n",
            "200/333...\n",
            "201/333...\n",
            "202/333...\n",
            "203/333...\n",
            "204/333...\n",
            "205/333...\n",
            "206/333...\n",
            "207/333...\n",
            "208/333...\n",
            "209/333...\n",
            "210/333...\n",
            "211/333...\n",
            "212/333...\n",
            "213/333...\n",
            "214/333...\n",
            "215/333...\n",
            "216/333...\n",
            "217/333...\n",
            "218/333...\n",
            "219/333...\n",
            "220/333...\n",
            "221/333...\n",
            "222/333...\n",
            "223/333...\n",
            "224/333...\n",
            "225/333...\n",
            "226/333...\n",
            "227/333...\n",
            "228/333...\n",
            "229/333...\n",
            "230/333...\n",
            "231/333...\n",
            "232/333...\n",
            "233/333...\n",
            "234/333...\n",
            "235/333...\n",
            "236/333...\n",
            "237/333...\n",
            "238/333...\n",
            "239/333...\n",
            "240/333...\n",
            "241/333...\n",
            "242/333...\n",
            "243/333...\n",
            "244/333...\n",
            "245/333...\n",
            "246/333...\n",
            "247/333...\n",
            "248/333...\n",
            "249/333...\n",
            "250/333...\n",
            "251/333...\n",
            "252/333...\n",
            "253/333...\n",
            "254/333...\n",
            "255/333...\n",
            "256/333...\n",
            "257/333...\n",
            "258/333...\n",
            "259/333...\n",
            "260/333...\n",
            "261/333...\n",
            "262/333...\n",
            "263/333...\n",
            "264/333...\n",
            "265/333...\n",
            "266/333...\n",
            "267/333...\n",
            "268/333...\n",
            "269/333...\n",
            "270/333...\n",
            "271/333...\n",
            "272/333...\n",
            "273/333...\n",
            "274/333...\n",
            "275/333...\n",
            "276/333...\n",
            "277/333...\n",
            "278/333...\n",
            "279/333...\n",
            "280/333...\n",
            "281/333...\n",
            "282/333...\n",
            "283/333...\n",
            "284/333...\n",
            "285/333...\n",
            "286/333...\n",
            "287/333...\n",
            "288/333...\n",
            "289/333...\n",
            "290/333...\n",
            "291/333...\n",
            "292/333...\n",
            "293/333...\n",
            "294/333...\n",
            "295/333...\n",
            "296/333...\n",
            "297/333...\n",
            "298/333...\n",
            "299/333...\n",
            "300/333...\n",
            "301/333...\n",
            "302/333...\n",
            "303/333...\n",
            "304/333...\n",
            "305/333...\n",
            "306/333...\n",
            "307/333...\n",
            "308/333...\n",
            "309/333...\n",
            "310/333...\n",
            "311/333...\n",
            "312/333...\n",
            "313/333...\n",
            "314/333...\n",
            "315/333...\n",
            "316/333...\n",
            "317/333...\n",
            "318/333...\n",
            "319/333...\n",
            "320/333...\n",
            "321/333...\n",
            "322/333...\n",
            "323/333...\n",
            "324/333...\n",
            "325/333...\n",
            "326/333...\n",
            "327/333...\n",
            "328/333...\n",
            "329/333...\n",
            "330/333...\n",
            "331/333...\n",
            "332/333...\n",
            "333/333...\n",
            "saving checkpoint to /content/drive/MyDrive/Kontur_task/check/lm_lstm_epoch9.67_0.6106.pt\n",
            "61000/63080 (epoch 9.670), train_loss = 0.64991194, time/batch = 0.0528s\n",
            "61001/63080 (epoch 9.670), train_loss = 0.68650216, time/batch = 0.0599s\n",
            "61002/63080 (epoch 9.671), train_loss = 0.64625120, time/batch = 0.0592s\n",
            "61003/63080 (epoch 9.671), train_loss = 0.64792675, time/batch = 0.0591s\n",
            "61004/63080 (epoch 9.671), train_loss = 0.63168031, time/batch = 0.0555s\n",
            "61005/63080 (epoch 9.671), train_loss = 0.64722675, time/batch = 0.0537s\n",
            "61006/63080 (epoch 9.671), train_loss = 0.67027193, time/batch = 0.0531s\n",
            "61007/63080 (epoch 9.671), train_loss = 0.64499158, time/batch = 0.0525s\n",
            "61008/63080 (epoch 9.672), train_loss = 0.66012579, time/batch = 0.0527s\n",
            "61009/63080 (epoch 9.672), train_loss = 0.67953885, time/batch = 0.0545s\n",
            "61010/63080 (epoch 9.672), train_loss = 0.65677494, time/batch = 0.0524s\n",
            "61011/63080 (epoch 9.672), train_loss = 0.67044669, time/batch = 0.0518s\n",
            "61012/63080 (epoch 9.672), train_loss = 0.64377767, time/batch = 0.0525s\n",
            "61013/63080 (epoch 9.672), train_loss = 0.66313088, time/batch = 0.0535s\n",
            "61014/63080 (epoch 9.672), train_loss = 0.65480006, time/batch = 0.0522s\n",
            "61015/63080 (epoch 9.673), train_loss = 0.66616982, time/batch = 0.0535s\n",
            "61016/63080 (epoch 9.673), train_loss = 0.65909475, time/batch = 0.0523s\n",
            "61017/63080 (epoch 9.673), train_loss = 0.62807864, time/batch = 0.0531s\n",
            "61018/63080 (epoch 9.673), train_loss = 0.64638478, time/batch = 0.0524s\n",
            "61019/63080 (epoch 9.673), train_loss = 0.65815014, time/batch = 0.0532s\n",
            "61020/63080 (epoch 9.673), train_loss = 0.66316873, time/batch = 0.0526s\n",
            "61021/63080 (epoch 9.674), train_loss = 0.66940534, time/batch = 0.0523s\n",
            "61022/63080 (epoch 9.674), train_loss = 0.65379506, time/batch = 0.0525s\n",
            "61023/63080 (epoch 9.674), train_loss = 0.65302497, time/batch = 0.0530s\n",
            "61024/63080 (epoch 9.674), train_loss = 0.62736076, time/batch = 0.0534s\n",
            "61025/63080 (epoch 9.674), train_loss = 0.62482882, time/batch = 0.0526s\n",
            "61026/63080 (epoch 9.674), train_loss = 0.66991258, time/batch = 0.0527s\n",
            "61027/63080 (epoch 9.675), train_loss = 0.64264530, time/batch = 0.0525s\n",
            "61028/63080 (epoch 9.675), train_loss = 0.66911501, time/batch = 0.0539s\n",
            "61029/63080 (epoch 9.675), train_loss = 0.64798784, time/batch = 0.0523s\n",
            "61030/63080 (epoch 9.675), train_loss = 0.66444194, time/batch = 0.0534s\n",
            "61031/63080 (epoch 9.675), train_loss = 0.66366017, time/batch = 0.0532s\n",
            "61032/63080 (epoch 9.675), train_loss = 0.66414022, time/batch = 0.0525s\n",
            "61033/63080 (epoch 9.675), train_loss = 0.66203910, time/batch = 0.0528s\n",
            "61034/63080 (epoch 9.676), train_loss = 0.66060001, time/batch = 0.0526s\n",
            "61035/63080 (epoch 9.676), train_loss = 0.66432816, time/batch = 0.0527s\n",
            "61036/63080 (epoch 9.676), train_loss = 0.68195581, time/batch = 0.0525s\n",
            "61037/63080 (epoch 9.676), train_loss = 0.66667336, time/batch = 0.0526s\n",
            "61038/63080 (epoch 9.676), train_loss = 0.64504421, time/batch = 0.0528s\n",
            "61039/63080 (epoch 9.676), train_loss = 0.66389549, time/batch = 0.0525s\n",
            "61040/63080 (epoch 9.677), train_loss = 0.65507442, time/batch = 0.0527s\n",
            "61041/63080 (epoch 9.677), train_loss = 0.67657638, time/batch = 0.0528s\n",
            "61042/63080 (epoch 9.677), train_loss = 0.66289645, time/batch = 0.0524s\n",
            "61043/63080 (epoch 9.677), train_loss = 0.65037036, time/batch = 0.0522s\n",
            "61044/63080 (epoch 9.677), train_loss = 0.66815454, time/batch = 0.0530s\n",
            "61045/63080 (epoch 9.677), train_loss = 0.67336226, time/batch = 0.0523s\n",
            "61046/63080 (epoch 9.678), train_loss = 0.64637733, time/batch = 0.0539s\n",
            "61047/63080 (epoch 9.678), train_loss = 0.64874583, time/batch = 0.0524s\n",
            "61048/63080 (epoch 9.678), train_loss = 0.63583547, time/batch = 0.0527s\n",
            "61049/63080 (epoch 9.678), train_loss = 0.65037662, time/batch = 0.0527s\n",
            "61050/63080 (epoch 9.678), train_loss = 0.65295005, time/batch = 0.0528s\n",
            "61051/63080 (epoch 9.678), train_loss = 0.65289545, time/batch = 0.0523s\n",
            "61052/63080 (epoch 9.679), train_loss = 0.68099672, time/batch = 0.0538s\n",
            "61053/63080 (epoch 9.679), train_loss = 0.64315456, time/batch = 0.0526s\n",
            "61054/63080 (epoch 9.679), train_loss = 0.63482004, time/batch = 0.0527s\n",
            "61055/63080 (epoch 9.679), train_loss = 0.67180765, time/batch = 0.0525s\n",
            "61056/63080 (epoch 9.679), train_loss = 0.66709274, time/batch = 0.0527s\n",
            "61057/63080 (epoch 9.679), train_loss = 0.65845728, time/batch = 0.0531s\n",
            "61058/63080 (epoch 9.679), train_loss = 0.66845071, time/batch = 0.0524s\n",
            "61059/63080 (epoch 9.680), train_loss = 0.65285075, time/batch = 0.0537s\n",
            "61060/63080 (epoch 9.680), train_loss = 0.63442004, time/batch = 0.0525s\n",
            "61061/63080 (epoch 9.680), train_loss = 0.65464681, time/batch = 0.0522s\n",
            "61062/63080 (epoch 9.680), train_loss = 0.65316093, time/batch = 0.0524s\n",
            "61063/63080 (epoch 9.680), train_loss = 0.67752421, time/batch = 0.0528s\n",
            "61064/63080 (epoch 9.680), train_loss = 0.64601701, time/batch = 0.0528s\n",
            "61065/63080 (epoch 9.681), train_loss = 0.68055195, time/batch = 0.0528s\n",
            "61066/63080 (epoch 9.681), train_loss = 0.69240510, time/batch = 0.0527s\n",
            "61067/63080 (epoch 9.681), train_loss = 0.66434389, time/batch = 0.0525s\n",
            "61068/63080 (epoch 9.681), train_loss = 0.66550374, time/batch = 0.0526s\n",
            "61069/63080 (epoch 9.681), train_loss = 0.68966430, time/batch = 0.0527s\n",
            "61070/63080 (epoch 9.681), train_loss = 0.65072161, time/batch = 0.0528s\n",
            "61071/63080 (epoch 9.682), train_loss = 0.65631300, time/batch = 0.0526s\n",
            "61072/63080 (epoch 9.682), train_loss = 0.66905355, time/batch = 0.0524s\n",
            "61073/63080 (epoch 9.682), train_loss = 0.67333382, time/batch = 0.0528s\n",
            "61074/63080 (epoch 9.682), train_loss = 0.64478016, time/batch = 0.0524s\n",
            "61075/63080 (epoch 9.682), train_loss = 0.65463781, time/batch = 0.0539s\n",
            "61076/63080 (epoch 9.682), train_loss = 0.65319657, time/batch = 0.0531s\n",
            "61077/63080 (epoch 9.682), train_loss = 0.66576993, time/batch = 0.0524s\n",
            "61078/63080 (epoch 9.683), train_loss = 0.65241891, time/batch = 0.0528s\n",
            "61079/63080 (epoch 9.683), train_loss = 0.66717213, time/batch = 0.0520s\n",
            "61080/63080 (epoch 9.683), train_loss = 0.66878003, time/batch = 0.0527s\n",
            "61081/63080 (epoch 9.683), train_loss = 0.65677816, time/batch = 0.0532s\n",
            "61082/63080 (epoch 9.683), train_loss = 0.67688560, time/batch = 0.0524s\n",
            "61083/63080 (epoch 9.683), train_loss = 0.65081674, time/batch = 0.0523s\n",
            "61084/63080 (epoch 9.684), train_loss = 0.65422994, time/batch = 0.0525s\n",
            "61085/63080 (epoch 9.684), train_loss = 0.66444463, time/batch = 0.0526s\n",
            "61086/63080 (epoch 9.684), train_loss = 0.63854373, time/batch = 0.0531s\n",
            "61087/63080 (epoch 9.684), train_loss = 0.64417464, time/batch = 0.0530s\n",
            "61088/63080 (epoch 9.684), train_loss = 0.66363531, time/batch = 0.0533s\n",
            "61089/63080 (epoch 9.684), train_loss = 0.64946824, time/batch = 0.0524s\n",
            "61090/63080 (epoch 9.685), train_loss = 0.65599066, time/batch = 0.0530s\n",
            "61091/63080 (epoch 9.685), train_loss = 0.67229712, time/batch = 0.0533s\n",
            "61092/63080 (epoch 9.685), train_loss = 0.65348369, time/batch = 0.0530s\n",
            "61093/63080 (epoch 9.685), train_loss = 0.64246392, time/batch = 0.0533s\n",
            "61094/63080 (epoch 9.685), train_loss = 0.63117748, time/batch = 0.0525s\n",
            "61095/63080 (epoch 9.685), train_loss = 0.65980530, time/batch = 0.0528s\n",
            "61096/63080 (epoch 9.685), train_loss = 0.63353014, time/batch = 0.0531s\n",
            "61097/63080 (epoch 9.686), train_loss = 0.63419342, time/batch = 0.0526s\n",
            "61098/63080 (epoch 9.686), train_loss = 0.65318847, time/batch = 0.0526s\n",
            "61099/63080 (epoch 9.686), train_loss = 0.65749174, time/batch = 0.0522s\n",
            "61100/63080 (epoch 9.686), train_loss = 0.66053516, time/batch = 0.0534s\n",
            "61101/63080 (epoch 9.686), train_loss = 0.63291097, time/batch = 0.0521s\n",
            "61102/63080 (epoch 9.686), train_loss = 0.62964618, time/batch = 0.0525s\n",
            "61103/63080 (epoch 9.687), train_loss = 0.67377168, time/batch = 0.0532s\n",
            "61104/63080 (epoch 9.687), train_loss = 0.63329655, time/batch = 0.0525s\n",
            "61105/63080 (epoch 9.687), train_loss = 0.63205230, time/batch = 0.0526s\n",
            "61106/63080 (epoch 9.687), train_loss = 0.64414883, time/batch = 0.0524s\n",
            "61107/63080 (epoch 9.687), train_loss = 0.67967772, time/batch = 0.0545s\n",
            "61108/63080 (epoch 9.687), train_loss = 0.65828377, time/batch = 0.0525s\n",
            "61109/63080 (epoch 9.688), train_loss = 0.66351569, time/batch = 0.0525s\n",
            "61110/63080 (epoch 9.688), train_loss = 0.64756262, time/batch = 0.0528s\n",
            "61111/63080 (epoch 9.688), train_loss = 0.64170480, time/batch = 0.0524s\n",
            "61112/63080 (epoch 9.688), train_loss = 0.64803249, time/batch = 0.0525s\n",
            "61113/63080 (epoch 9.688), train_loss = 0.66410804, time/batch = 0.0524s\n",
            "61114/63080 (epoch 9.688), train_loss = 0.64216250, time/batch = 0.0530s\n",
            "61115/63080 (epoch 9.688), train_loss = 0.64815444, time/batch = 0.0540s\n",
            "61116/63080 (epoch 9.689), train_loss = 0.64904541, time/batch = 0.0524s\n",
            "61117/63080 (epoch 9.689), train_loss = 0.65392691, time/batch = 0.0527s\n",
            "61118/63080 (epoch 9.689), train_loss = 0.64174205, time/batch = 0.0525s\n",
            "61119/63080 (epoch 9.689), train_loss = 0.66863304, time/batch = 0.0526s\n",
            "61120/63080 (epoch 9.689), train_loss = 0.62979162, time/batch = 0.0529s\n",
            "61121/63080 (epoch 9.689), train_loss = 0.65054017, time/batch = 0.0526s\n",
            "61122/63080 (epoch 9.690), train_loss = 0.65090090, time/batch = 0.0524s\n",
            "61123/63080 (epoch 9.690), train_loss = 0.67182451, time/batch = 0.0528s\n",
            "61124/63080 (epoch 9.690), train_loss = 0.65280360, time/batch = 0.0538s\n",
            "61125/63080 (epoch 9.690), train_loss = 0.64828557, time/batch = 0.0537s\n",
            "61126/63080 (epoch 9.690), train_loss = 0.64865178, time/batch = 0.0533s\n",
            "61127/63080 (epoch 9.690), train_loss = 0.63986349, time/batch = 0.0528s\n",
            "61128/63080 (epoch 9.691), train_loss = 0.64372897, time/batch = 0.0524s\n",
            "61129/63080 (epoch 9.691), train_loss = 0.65205777, time/batch = 0.0526s\n",
            "61130/63080 (epoch 9.691), train_loss = 0.64771760, time/batch = 0.0525s\n",
            "61131/63080 (epoch 9.691), train_loss = 0.65444314, time/batch = 0.0533s\n",
            "61132/63080 (epoch 9.691), train_loss = 0.63074332, time/batch = 0.0533s\n",
            "61133/63080 (epoch 9.691), train_loss = 0.66281891, time/batch = 0.0524s\n",
            "61134/63080 (epoch 9.692), train_loss = 0.65274733, time/batch = 0.0529s\n",
            "61135/63080 (epoch 9.692), train_loss = 0.65110081, time/batch = 0.0522s\n",
            "61136/63080 (epoch 9.692), train_loss = 0.65066719, time/batch = 0.0524s\n",
            "61137/63080 (epoch 9.692), train_loss = 0.64622903, time/batch = 0.0533s\n",
            "61138/63080 (epoch 9.692), train_loss = 0.65690178, time/batch = 0.0527s\n",
            "61139/63080 (epoch 9.692), train_loss = 0.66595513, time/batch = 0.0526s\n",
            "61140/63080 (epoch 9.692), train_loss = 0.63243395, time/batch = 0.0527s\n",
            "61141/63080 (epoch 9.693), train_loss = 0.64129066, time/batch = 0.0525s\n",
            "61142/63080 (epoch 9.693), train_loss = 0.64605945, time/batch = 0.0527s\n",
            "61143/63080 (epoch 9.693), train_loss = 0.64092106, time/batch = 0.0535s\n",
            "61144/63080 (epoch 9.693), train_loss = 0.65689617, time/batch = 0.0529s\n",
            "61145/63080 (epoch 9.693), train_loss = 0.65284866, time/batch = 0.0523s\n",
            "61146/63080 (epoch 9.693), train_loss = 0.65396762, time/batch = 0.0536s\n",
            "61147/63080 (epoch 9.694), train_loss = 0.66600788, time/batch = 0.0529s\n",
            "61148/63080 (epoch 9.694), train_loss = 0.65030825, time/batch = 0.0525s\n",
            "61149/63080 (epoch 9.694), train_loss = 0.64635253, time/batch = 0.0531s\n",
            "61150/63080 (epoch 9.694), train_loss = 0.64912325, time/batch = 0.0528s\n",
            "61151/63080 (epoch 9.694), train_loss = 0.65264958, time/batch = 0.0525s\n",
            "61152/63080 (epoch 9.694), train_loss = 0.64123046, time/batch = 0.0525s\n",
            "61153/63080 (epoch 9.695), train_loss = 0.65434062, time/batch = 0.0526s\n",
            "61154/63080 (epoch 9.695), train_loss = 0.64383352, time/batch = 0.0524s\n",
            "61155/63080 (epoch 9.695), train_loss = 0.68497282, time/batch = 0.0535s\n",
            "61156/63080 (epoch 9.695), train_loss = 0.65914834, time/batch = 0.0527s\n",
            "61157/63080 (epoch 9.695), train_loss = 0.65482742, time/batch = 0.0523s\n",
            "61158/63080 (epoch 9.695), train_loss = 0.67581022, time/batch = 0.0527s\n",
            "61159/63080 (epoch 9.695), train_loss = 0.66751313, time/batch = 0.0529s\n",
            "61160/63080 (epoch 9.696), train_loss = 0.65914166, time/batch = 0.0531s\n",
            "61161/63080 (epoch 9.696), train_loss = 0.65582317, time/batch = 0.0523s\n",
            "61162/63080 (epoch 9.696), train_loss = 0.64011836, time/batch = 0.0523s\n",
            "61163/63080 (epoch 9.696), train_loss = 0.66611409, time/batch = 0.0532s\n",
            "61164/63080 (epoch 9.696), train_loss = 0.65448290, time/batch = 0.0526s\n",
            "61165/63080 (epoch 9.696), train_loss = 0.66097802, time/batch = 0.0529s\n",
            "61166/63080 (epoch 9.697), train_loss = 0.65726131, time/batch = 0.0531s\n",
            "61167/63080 (epoch 9.697), train_loss = 0.66495383, time/batch = 0.0525s\n",
            "61168/63080 (epoch 9.697), train_loss = 0.64263713, time/batch = 0.0527s\n",
            "61169/63080 (epoch 9.697), train_loss = 0.64992791, time/batch = 0.0522s\n",
            "61170/63080 (epoch 9.697), train_loss = 0.66034466, time/batch = 0.0524s\n",
            "61171/63080 (epoch 9.697), train_loss = 0.65335405, time/batch = 0.0530s\n",
            "61172/63080 (epoch 9.698), train_loss = 0.64304250, time/batch = 0.0523s\n",
            "61173/63080 (epoch 9.698), train_loss = 0.66629374, time/batch = 0.0524s\n",
            "61174/63080 (epoch 9.698), train_loss = 0.65029854, time/batch = 0.0533s\n",
            "61175/63080 (epoch 9.698), train_loss = 0.66917664, time/batch = 0.0523s\n",
            "61176/63080 (epoch 9.698), train_loss = 0.64688230, time/batch = 0.0529s\n",
            "61177/63080 (epoch 9.698), train_loss = 0.65345389, time/batch = 0.0527s\n",
            "61178/63080 (epoch 9.698), train_loss = 0.65050364, time/batch = 0.0525s\n",
            "61179/63080 (epoch 9.699), train_loss = 0.64792114, time/batch = 0.0525s\n",
            "61180/63080 (epoch 9.699), train_loss = 0.64361572, time/batch = 0.0529s\n",
            "61181/63080 (epoch 9.699), train_loss = 0.64490080, time/batch = 0.0526s\n",
            "61182/63080 (epoch 9.699), train_loss = 0.67794812, time/batch = 0.0527s\n",
            "61183/63080 (epoch 9.699), train_loss = 0.63615203, time/batch = 0.0531s\n",
            "61184/63080 (epoch 9.699), train_loss = 0.63688761, time/batch = 0.0528s\n",
            "61185/63080 (epoch 9.700), train_loss = 0.66306657, time/batch = 0.0529s\n",
            "61186/63080 (epoch 9.700), train_loss = 0.66305655, time/batch = 0.0523s\n",
            "61187/63080 (epoch 9.700), train_loss = 0.66284436, time/batch = 0.0527s\n",
            "61188/63080 (epoch 9.700), train_loss = 0.64213747, time/batch = 0.0540s\n",
            "61189/63080 (epoch 9.700), train_loss = 0.64041954, time/batch = 0.0531s\n",
            "61190/63080 (epoch 9.700), train_loss = 0.65233564, time/batch = 0.0531s\n",
            "61191/63080 (epoch 9.701), train_loss = 0.66018903, time/batch = 0.0522s\n",
            "61192/63080 (epoch 9.701), train_loss = 0.65775907, time/batch = 0.0525s\n",
            "61193/63080 (epoch 9.701), train_loss = 0.65104979, time/batch = 0.0536s\n",
            "61194/63080 (epoch 9.701), train_loss = 0.66209048, time/batch = 0.0527s\n",
            "61195/63080 (epoch 9.701), train_loss = 0.63543326, time/batch = 0.0529s\n",
            "61196/63080 (epoch 9.701), train_loss = 0.64576238, time/batch = 0.0529s\n",
            "61197/63080 (epoch 9.701), train_loss = 0.62470317, time/batch = 0.0525s\n",
            "61198/63080 (epoch 9.702), train_loss = 0.67976594, time/batch = 0.0525s\n",
            "61199/63080 (epoch 9.702), train_loss = 0.65813309, time/batch = 0.0526s\n",
            "61200/63080 (epoch 9.702), train_loss = 0.65235156, time/batch = 0.0528s\n",
            "61201/63080 (epoch 9.702), train_loss = 0.65963542, time/batch = 0.0522s\n",
            "61202/63080 (epoch 9.702), train_loss = 0.65163720, time/batch = 0.0529s\n",
            "61203/63080 (epoch 9.702), train_loss = 0.65362126, time/batch = 0.0526s\n",
            "61204/63080 (epoch 9.703), train_loss = 0.64533514, time/batch = 0.0525s\n",
            "61205/63080 (epoch 9.703), train_loss = 0.63676882, time/batch = 0.0536s\n",
            "61206/63080 (epoch 9.703), train_loss = 0.63206816, time/batch = 0.0523s\n",
            "61207/63080 (epoch 9.703), train_loss = 0.66728145, time/batch = 0.0529s\n",
            "61208/63080 (epoch 9.703), train_loss = 0.63340706, time/batch = 0.0530s\n",
            "61209/63080 (epoch 9.703), train_loss = 0.62772644, time/batch = 0.0523s\n",
            "61210/63080 (epoch 9.704), train_loss = 0.62671971, time/batch = 0.0528s\n",
            "61211/63080 (epoch 9.704), train_loss = 0.63276076, time/batch = 0.0531s\n",
            "61212/63080 (epoch 9.704), train_loss = 0.66498625, time/batch = 0.0525s\n",
            "61213/63080 (epoch 9.704), train_loss = 0.63928628, time/batch = 0.0524s\n",
            "61214/63080 (epoch 9.704), train_loss = 0.65411025, time/batch = 0.0527s\n",
            "61215/63080 (epoch 9.704), train_loss = 0.63426733, time/batch = 0.0529s\n",
            "61216/63080 (epoch 9.705), train_loss = 0.66391838, time/batch = 0.0530s\n",
            "61217/63080 (epoch 9.705), train_loss = 0.64801753, time/batch = 0.0527s\n",
            "61218/63080 (epoch 9.705), train_loss = 0.66542828, time/batch = 0.0529s\n",
            "61219/63080 (epoch 9.705), train_loss = 0.64545810, time/batch = 0.0524s\n",
            "61220/63080 (epoch 9.705), train_loss = 0.65850186, time/batch = 0.0530s\n",
            "61221/63080 (epoch 9.705), train_loss = 0.66014922, time/batch = 0.0520s\n",
            "61222/63080 (epoch 9.705), train_loss = 0.64288229, time/batch = 0.0528s\n",
            "61223/63080 (epoch 9.706), train_loss = 0.65083987, time/batch = 0.0533s\n",
            "61224/63080 (epoch 9.706), train_loss = 0.64054757, time/batch = 0.0534s\n",
            "61225/63080 (epoch 9.706), train_loss = 0.65568179, time/batch = 0.0526s\n",
            "61226/63080 (epoch 9.706), train_loss = 0.63747537, time/batch = 0.0528s\n",
            "61227/63080 (epoch 9.706), train_loss = 0.65951222, time/batch = 0.0526s\n",
            "61228/63080 (epoch 9.706), train_loss = 0.65285563, time/batch = 0.0533s\n",
            "61229/63080 (epoch 9.707), train_loss = 0.65590829, time/batch = 0.0529s\n",
            "61230/63080 (epoch 9.707), train_loss = 0.61811274, time/batch = 0.0525s\n",
            "61231/63080 (epoch 9.707), train_loss = 0.65966189, time/batch = 0.0522s\n",
            "61232/63080 (epoch 9.707), train_loss = 0.63120937, time/batch = 0.0528s\n",
            "61233/63080 (epoch 9.707), train_loss = 0.67021728, time/batch = 0.0524s\n",
            "61234/63080 (epoch 9.707), train_loss = 0.65310693, time/batch = 0.0530s\n",
            "61235/63080 (epoch 9.708), train_loss = 0.64823210, time/batch = 0.0524s\n",
            "61236/63080 (epoch 9.708), train_loss = 0.67377704, time/batch = 0.0528s\n",
            "61237/63080 (epoch 9.708), train_loss = 0.67144185, time/batch = 0.0520s\n",
            "61238/63080 (epoch 9.708), train_loss = 0.63948828, time/batch = 0.0526s\n",
            "61239/63080 (epoch 9.708), train_loss = 0.65618926, time/batch = 0.0529s\n",
            "61240/63080 (epoch 9.708), train_loss = 0.63749021, time/batch = 0.0514s\n",
            "61241/63080 (epoch 9.708), train_loss = 0.65698397, time/batch = 0.0524s\n",
            "61242/63080 (epoch 9.709), train_loss = 0.65500873, time/batch = 0.0526s\n",
            "61243/63080 (epoch 9.709), train_loss = 0.68279761, time/batch = 0.0533s\n",
            "61244/63080 (epoch 9.709), train_loss = 0.66756690, time/batch = 0.0524s\n",
            "61245/63080 (epoch 9.709), train_loss = 0.67093545, time/batch = 0.0526s\n",
            "61246/63080 (epoch 9.709), train_loss = 0.66171306, time/batch = 0.0532s\n",
            "61247/63080 (epoch 9.709), train_loss = 0.67001235, time/batch = 0.0523s\n",
            "61248/63080 (epoch 9.710), train_loss = 0.67258656, time/batch = 0.0521s\n",
            "61249/63080 (epoch 9.710), train_loss = 0.63283616, time/batch = 0.0524s\n",
            "61250/63080 (epoch 9.710), train_loss = 0.66752046, time/batch = 0.0541s\n",
            "61251/63080 (epoch 9.710), train_loss = 0.66459322, time/batch = 0.0524s\n",
            "61252/63080 (epoch 9.710), train_loss = 0.65437692, time/batch = 0.0524s\n",
            "61253/63080 (epoch 9.710), train_loss = 0.66013485, time/batch = 0.0526s\n",
            "61254/63080 (epoch 9.711), train_loss = 0.68635726, time/batch = 0.0527s\n",
            "61255/63080 (epoch 9.711), train_loss = 0.67081583, time/batch = 0.0532s\n",
            "61256/63080 (epoch 9.711), train_loss = 0.64246100, time/batch = 0.0524s\n",
            "61257/63080 (epoch 9.711), train_loss = 0.66347724, time/batch = 0.0536s\n",
            "61258/63080 (epoch 9.711), train_loss = 0.65045536, time/batch = 0.0528s\n",
            "61259/63080 (epoch 9.711), train_loss = 0.66649693, time/batch = 0.0529s\n",
            "61260/63080 (epoch 9.711), train_loss = 0.65683842, time/batch = 0.0528s\n",
            "61261/63080 (epoch 9.712), train_loss = 0.64317495, time/batch = 0.0522s\n",
            "61262/63080 (epoch 9.712), train_loss = 0.66426295, time/batch = 0.0525s\n",
            "61263/63080 (epoch 9.712), train_loss = 0.67285633, time/batch = 0.0529s\n",
            "61264/63080 (epoch 9.712), train_loss = 0.66509116, time/batch = 0.0529s\n",
            "61265/63080 (epoch 9.712), train_loss = 0.70737863, time/batch = 0.0525s\n",
            "61266/63080 (epoch 9.712), train_loss = 0.67558497, time/batch = 0.0545s\n",
            "61267/63080 (epoch 9.713), train_loss = 0.69253045, time/batch = 0.0525s\n",
            "61268/63080 (epoch 9.713), train_loss = 0.66102594, time/batch = 0.0536s\n",
            "61269/63080 (epoch 9.713), train_loss = 0.65390021, time/batch = 0.0520s\n",
            "61270/63080 (epoch 9.713), train_loss = 0.67847258, time/batch = 0.0526s\n",
            "61271/63080 (epoch 9.713), train_loss = 0.65572298, time/batch = 0.0522s\n",
            "61272/63080 (epoch 9.713), train_loss = 0.65100759, time/batch = 0.0532s\n",
            "61273/63080 (epoch 9.714), train_loss = 0.66430396, time/batch = 0.0525s\n",
            "61274/63080 (epoch 9.714), train_loss = 0.65133691, time/batch = 0.0526s\n",
            "61275/63080 (epoch 9.714), train_loss = 0.66621906, time/batch = 0.0531s\n",
            "61276/63080 (epoch 9.714), train_loss = 0.67863941, time/batch = 0.0529s\n",
            "61277/63080 (epoch 9.714), train_loss = 0.64256597, time/batch = 0.0523s\n",
            "61278/63080 (epoch 9.714), train_loss = 0.63970363, time/batch = 0.0531s\n",
            "61279/63080 (epoch 9.714), train_loss = 0.66981095, time/batch = 0.0527s\n",
            "61280/63080 (epoch 9.715), train_loss = 0.66670305, time/batch = 0.0530s\n",
            "61281/63080 (epoch 9.715), train_loss = 0.67550766, time/batch = 0.0524s\n",
            "61282/63080 (epoch 9.715), train_loss = 0.66510540, time/batch = 0.0515s\n",
            "61283/63080 (epoch 9.715), train_loss = 0.65720344, time/batch = 0.0528s\n",
            "61284/63080 (epoch 9.715), train_loss = 0.65686786, time/batch = 0.0529s\n",
            "61285/63080 (epoch 9.715), train_loss = 0.66812366, time/batch = 0.0525s\n",
            "61286/63080 (epoch 9.716), train_loss = 0.67321950, time/batch = 0.0527s\n",
            "61287/63080 (epoch 9.716), train_loss = 0.64801598, time/batch = 0.0526s\n",
            "61288/63080 (epoch 9.716), train_loss = 0.69037473, time/batch = 0.0527s\n",
            "61289/63080 (epoch 9.716), train_loss = 0.67606086, time/batch = 0.0526s\n",
            "61290/63080 (epoch 9.716), train_loss = 0.66545916, time/batch = 0.0524s\n",
            "61291/63080 (epoch 9.716), train_loss = 0.66264510, time/batch = 0.0530s\n",
            "61292/63080 (epoch 9.717), train_loss = 0.67343414, time/batch = 0.0526s\n",
            "61293/63080 (epoch 9.717), train_loss = 0.66726696, time/batch = 0.0526s\n",
            "61294/63080 (epoch 9.717), train_loss = 0.65749532, time/batch = 0.0530s\n",
            "61295/63080 (epoch 9.717), train_loss = 0.67374539, time/batch = 0.0527s\n",
            "61296/63080 (epoch 9.717), train_loss = 0.68024504, time/batch = 0.0527s\n",
            "61297/63080 (epoch 9.717), train_loss = 0.64382476, time/batch = 0.0523s\n",
            "61298/63080 (epoch 9.718), train_loss = 0.66476983, time/batch = 0.0527s\n",
            "61299/63080 (epoch 9.718), train_loss = 0.65313548, time/batch = 0.0525s\n",
            "61300/63080 (epoch 9.718), train_loss = 0.66250205, time/batch = 0.0526s\n",
            "61301/63080 (epoch 9.718), train_loss = 0.65465403, time/batch = 0.0527s\n",
            "61302/63080 (epoch 9.718), train_loss = 0.66004211, time/batch = 0.0527s\n",
            "61303/63080 (epoch 9.718), train_loss = 0.66876358, time/batch = 0.0526s\n",
            "61304/63080 (epoch 9.718), train_loss = 0.66493201, time/batch = 0.0524s\n",
            "61305/63080 (epoch 9.719), train_loss = 0.65299898, time/batch = 0.0525s\n",
            "61306/63080 (epoch 9.719), train_loss = 0.66622895, time/batch = 0.0526s\n",
            "61307/63080 (epoch 9.719), train_loss = 0.64663780, time/batch = 0.0528s\n",
            "61308/63080 (epoch 9.719), train_loss = 0.68198854, time/batch = 0.0526s\n",
            "61309/63080 (epoch 9.719), train_loss = 0.66612208, time/batch = 0.0524s\n",
            "61310/63080 (epoch 9.719), train_loss = 0.66077852, time/batch = 0.0526s\n",
            "61311/63080 (epoch 9.720), train_loss = 0.64843565, time/batch = 0.0524s\n",
            "61312/63080 (epoch 9.720), train_loss = 0.67169964, time/batch = 0.0528s\n",
            "61313/63080 (epoch 9.720), train_loss = 0.66710716, time/batch = 0.0527s\n",
            "61314/63080 (epoch 9.720), train_loss = 0.66257805, time/batch = 0.0527s\n",
            "61315/63080 (epoch 9.720), train_loss = 0.67300874, time/batch = 0.0535s\n",
            "61316/63080 (epoch 9.720), train_loss = 0.67813724, time/batch = 0.0529s\n",
            "61317/63080 (epoch 9.721), train_loss = 0.69576228, time/batch = 0.0528s\n",
            "61318/63080 (epoch 9.721), train_loss = 0.68807858, time/batch = 0.0524s\n",
            "61319/63080 (epoch 9.721), train_loss = 0.66854733, time/batch = 0.0524s\n",
            "61320/63080 (epoch 9.721), train_loss = 0.67047793, time/batch = 0.0526s\n",
            "61321/63080 (epoch 9.721), train_loss = 0.65116566, time/batch = 0.0518s\n",
            "61322/63080 (epoch 9.721), train_loss = 0.67937785, time/batch = 0.0525s\n",
            "61323/63080 (epoch 9.721), train_loss = 0.67769092, time/batch = 0.0533s\n",
            "61324/63080 (epoch 9.722), train_loss = 0.64672178, time/batch = 0.0526s\n",
            "61325/63080 (epoch 9.722), train_loss = 0.65658748, time/batch = 0.0525s\n",
            "61326/63080 (epoch 9.722), train_loss = 0.63718110, time/batch = 0.0526s\n",
            "61327/63080 (epoch 9.722), train_loss = 0.68585944, time/batch = 0.0531s\n",
            "61328/63080 (epoch 9.722), train_loss = 0.68473560, time/batch = 0.0525s\n",
            "61329/63080 (epoch 9.722), train_loss = 0.66618186, time/batch = 0.0524s\n",
            "61330/63080 (epoch 9.723), train_loss = 0.69629729, time/batch = 0.0529s\n",
            "61331/63080 (epoch 9.723), train_loss = 0.66505092, time/batch = 0.0521s\n",
            "61332/63080 (epoch 9.723), train_loss = 0.66889489, time/batch = 0.0527s\n",
            "61333/63080 (epoch 9.723), train_loss = 0.66486716, time/batch = 0.0523s\n",
            "61334/63080 (epoch 9.723), train_loss = 0.66997319, time/batch = 0.0530s\n",
            "61335/63080 (epoch 9.723), train_loss = 0.66446197, time/batch = 0.0544s\n",
            "61336/63080 (epoch 9.724), train_loss = 0.67406279, time/batch = 0.0525s\n",
            "61337/63080 (epoch 9.724), train_loss = 0.66138989, time/batch = 0.0525s\n",
            "61338/63080 (epoch 9.724), train_loss = 0.68472302, time/batch = 0.0523s\n",
            "61339/63080 (epoch 9.724), train_loss = 0.67097235, time/batch = 0.0535s\n",
            "61340/63080 (epoch 9.724), train_loss = 0.67224073, time/batch = 0.0524s\n",
            "61341/63080 (epoch 9.724), train_loss = 0.65980536, time/batch = 0.0523s\n",
            "61342/63080 (epoch 9.724), train_loss = 0.65454662, time/batch = 0.0524s\n",
            "61343/63080 (epoch 9.725), train_loss = 0.66763157, time/batch = 0.0523s\n",
            "61344/63080 (epoch 9.725), train_loss = 0.65770358, time/batch = 0.0528s\n",
            "61345/63080 (epoch 9.725), train_loss = 0.65895110, time/batch = 0.0524s\n",
            "61346/63080 (epoch 9.725), train_loss = 0.66351962, time/batch = 0.0533s\n",
            "61347/63080 (epoch 9.725), train_loss = 0.66633576, time/batch = 0.0525s\n",
            "61348/63080 (epoch 9.725), train_loss = 0.68020701, time/batch = 0.0526s\n",
            "61349/63080 (epoch 9.726), train_loss = 0.65539688, time/batch = 0.0526s\n",
            "61350/63080 (epoch 9.726), train_loss = 0.63740873, time/batch = 0.0532s\n",
            "61351/63080 (epoch 9.726), train_loss = 0.66302949, time/batch = 0.0526s\n",
            "61352/63080 (epoch 9.726), train_loss = 0.68285143, time/batch = 0.0630s\n",
            "61353/63080 (epoch 9.726), train_loss = 0.66022694, time/batch = 0.0524s\n",
            "61354/63080 (epoch 9.726), train_loss = 0.65155053, time/batch = 0.0535s\n",
            "61355/63080 (epoch 9.727), train_loss = 0.63309270, time/batch = 0.0523s\n",
            "61356/63080 (epoch 9.727), train_loss = 0.65700430, time/batch = 0.0525s\n",
            "61357/63080 (epoch 9.727), train_loss = 0.65918177, time/batch = 0.0525s\n",
            "61358/63080 (epoch 9.727), train_loss = 0.64087319, time/batch = 0.0533s\n",
            "61359/63080 (epoch 9.727), train_loss = 0.66896510, time/batch = 0.0521s\n",
            "61360/63080 (epoch 9.727), train_loss = 0.67504770, time/batch = 0.0523s\n",
            "61361/63080 (epoch 9.727), train_loss = 0.64470923, time/batch = 0.0521s\n",
            "61362/63080 (epoch 9.728), train_loss = 0.64363343, time/batch = 0.0523s\n",
            "61363/63080 (epoch 9.728), train_loss = 0.64319152, time/batch = 0.0526s\n",
            "61364/63080 (epoch 9.728), train_loss = 0.66924965, time/batch = 0.0534s\n",
            "61365/63080 (epoch 9.728), train_loss = 0.66190237, time/batch = 0.0526s\n",
            "61366/63080 (epoch 9.728), train_loss = 0.66110075, time/batch = 0.0528s\n",
            "61367/63080 (epoch 9.728), train_loss = 0.66113877, time/batch = 0.0525s\n",
            "61368/63080 (epoch 9.729), train_loss = 0.67206097, time/batch = 0.0527s\n",
            "61369/63080 (epoch 9.729), train_loss = 0.66389936, time/batch = 0.0523s\n",
            "61370/63080 (epoch 9.729), train_loss = 0.66105926, time/batch = 0.0530s\n",
            "61371/63080 (epoch 9.729), train_loss = 0.63856757, time/batch = 0.0517s\n",
            "61372/63080 (epoch 9.729), train_loss = 0.65408927, time/batch = 0.0526s\n",
            "61373/63080 (epoch 9.729), train_loss = 0.67299521, time/batch = 0.0530s\n",
            "61374/63080 (epoch 9.730), train_loss = 0.66519427, time/batch = 0.0525s\n",
            "61375/63080 (epoch 9.730), train_loss = 0.63987434, time/batch = 0.0523s\n",
            "61376/63080 (epoch 9.730), train_loss = 0.67262125, time/batch = 0.0526s\n",
            "61377/63080 (epoch 9.730), train_loss = 0.65750915, time/batch = 0.0527s\n",
            "61378/63080 (epoch 9.730), train_loss = 0.64928353, time/batch = 0.0526s\n",
            "61379/63080 (epoch 9.730), train_loss = 0.65985811, time/batch = 0.0527s\n",
            "61380/63080 (epoch 9.731), train_loss = 0.65868884, time/batch = 0.0531s\n",
            "61381/63080 (epoch 9.731), train_loss = 0.67438108, time/batch = 0.0521s\n",
            "61382/63080 (epoch 9.731), train_loss = 0.66143596, time/batch = 0.0527s\n",
            "61383/63080 (epoch 9.731), train_loss = 0.66784322, time/batch = 0.0522s\n",
            "61384/63080 (epoch 9.731), train_loss = 0.66622609, time/batch = 0.0529s\n",
            "61385/63080 (epoch 9.731), train_loss = 0.65359473, time/batch = 0.0528s\n",
            "61386/63080 (epoch 9.731), train_loss = 0.66182435, time/batch = 0.0526s\n",
            "61387/63080 (epoch 9.732), train_loss = 0.66219699, time/batch = 0.0526s\n",
            "61388/63080 (epoch 9.732), train_loss = 0.65809768, time/batch = 0.0526s\n",
            "61389/63080 (epoch 9.732), train_loss = 0.63928187, time/batch = 0.0528s\n",
            "61390/63080 (epoch 9.732), train_loss = 0.67864478, time/batch = 0.0523s\n",
            "61391/63080 (epoch 9.732), train_loss = 0.62166727, time/batch = 0.0527s\n",
            "61392/63080 (epoch 9.732), train_loss = 0.65171170, time/batch = 0.0526s\n",
            "61393/63080 (epoch 9.733), train_loss = 0.65142941, time/batch = 0.0522s\n",
            "61394/63080 (epoch 9.733), train_loss = 0.63498968, time/batch = 0.0527s\n",
            "61395/63080 (epoch 9.733), train_loss = 0.63243991, time/batch = 0.0526s\n",
            "61396/63080 (epoch 9.733), train_loss = 0.64210135, time/batch = 0.0525s\n",
            "61397/63080 (epoch 9.733), train_loss = 0.64537966, time/batch = 0.0524s\n",
            "61398/63080 (epoch 9.733), train_loss = 0.62785572, time/batch = 0.0525s\n",
            "61399/63080 (epoch 9.734), train_loss = 0.66063720, time/batch = 0.0524s\n",
            "61400/63080 (epoch 9.734), train_loss = 0.62426114, time/batch = 0.0525s\n",
            "61401/63080 (epoch 9.734), train_loss = 0.63993084, time/batch = 0.0524s\n",
            "61402/63080 (epoch 9.734), train_loss = 0.61072570, time/batch = 0.0521s\n",
            "61403/63080 (epoch 9.734), train_loss = 0.66905326, time/batch = 0.0527s\n",
            "61404/63080 (epoch 9.734), train_loss = 0.64874053, time/batch = 0.0532s\n",
            "61405/63080 (epoch 9.734), train_loss = 0.64336276, time/batch = 0.0526s\n",
            "61406/63080 (epoch 9.735), train_loss = 0.64310616, time/batch = 0.0531s\n",
            "61407/63080 (epoch 9.735), train_loss = 0.65660894, time/batch = 0.0521s\n",
            "61408/63080 (epoch 9.735), train_loss = 0.65974277, time/batch = 0.0528s\n",
            "61409/63080 (epoch 9.735), train_loss = 0.65685236, time/batch = 0.0524s\n",
            "61410/63080 (epoch 9.735), train_loss = 0.64772189, time/batch = 0.0525s\n",
            "61411/63080 (epoch 9.735), train_loss = 0.66053307, time/batch = 0.0522s\n",
            "61412/63080 (epoch 9.736), train_loss = 0.65568388, time/batch = 0.0525s\n",
            "61413/63080 (epoch 9.736), train_loss = 0.65437502, time/batch = 0.0523s\n",
            "61414/63080 (epoch 9.736), train_loss = 0.67088246, time/batch = 0.0524s\n",
            "61415/63080 (epoch 9.736), train_loss = 0.67561412, time/batch = 0.0519s\n",
            "61416/63080 (epoch 9.736), train_loss = 0.63984370, time/batch = 0.0524s\n",
            "61417/63080 (epoch 9.736), train_loss = 0.64345121, time/batch = 0.0523s\n",
            "61418/63080 (epoch 9.737), train_loss = 0.65860939, time/batch = 0.0525s\n",
            "61419/63080 (epoch 9.737), train_loss = 0.63675827, time/batch = 0.0526s\n",
            "61420/63080 (epoch 9.737), train_loss = 0.66667295, time/batch = 0.0534s\n",
            "61421/63080 (epoch 9.737), train_loss = 0.65877622, time/batch = 0.0524s\n",
            "61422/63080 (epoch 9.737), train_loss = 0.65296692, time/batch = 0.0527s\n",
            "61423/63080 (epoch 9.737), train_loss = 0.66286260, time/batch = 0.0524s\n",
            "61424/63080 (epoch 9.737), train_loss = 0.66846347, time/batch = 0.0525s\n",
            "61425/63080 (epoch 9.738), train_loss = 0.64330447, time/batch = 0.0525s\n",
            "61426/63080 (epoch 9.738), train_loss = 0.65713716, time/batch = 0.0520s\n",
            "61427/63080 (epoch 9.738), train_loss = 0.65038997, time/batch = 0.0525s\n",
            "61428/63080 (epoch 9.738), train_loss = 0.66061085, time/batch = 0.0531s\n",
            "61429/63080 (epoch 9.738), train_loss = 0.65767628, time/batch = 0.0525s\n",
            "61430/63080 (epoch 9.738), train_loss = 0.66586071, time/batch = 0.0535s\n",
            "61431/63080 (epoch 9.739), train_loss = 0.64943874, time/batch = 0.0525s\n",
            "61432/63080 (epoch 9.739), train_loss = 0.66603625, time/batch = 0.0525s\n",
            "61433/63080 (epoch 9.739), train_loss = 0.65059167, time/batch = 0.0526s\n",
            "61434/63080 (epoch 9.739), train_loss = 0.66480184, time/batch = 0.0536s\n",
            "61435/63080 (epoch 9.739), train_loss = 0.65798903, time/batch = 0.0526s\n",
            "61436/63080 (epoch 9.739), train_loss = 0.66165191, time/batch = 0.0527s\n",
            "61437/63080 (epoch 9.740), train_loss = 0.65482843, time/batch = 0.0516s\n",
            "61438/63080 (epoch 9.740), train_loss = 0.65395725, time/batch = 0.0523s\n",
            "61439/63080 (epoch 9.740), train_loss = 0.66230655, time/batch = 0.0522s\n",
            "61440/63080 (epoch 9.740), train_loss = 0.67336124, time/batch = 0.0531s\n",
            "61441/63080 (epoch 9.740), train_loss = 0.68140632, time/batch = 0.0528s\n",
            "61442/63080 (epoch 9.740), train_loss = 0.66832483, time/batch = 0.0525s\n",
            "61443/63080 (epoch 9.740), train_loss = 0.65198821, time/batch = 0.0527s\n",
            "61444/63080 (epoch 9.741), train_loss = 0.66352940, time/batch = 0.0524s\n",
            "61445/63080 (epoch 9.741), train_loss = 0.65459663, time/batch = 0.0522s\n",
            "61446/63080 (epoch 9.741), train_loss = 0.63224530, time/batch = 0.0530s\n",
            "61447/63080 (epoch 9.741), train_loss = 0.66103798, time/batch = 0.0524s\n",
            "61448/63080 (epoch 9.741), train_loss = 0.64577121, time/batch = 0.0530s\n",
            "61449/63080 (epoch 9.741), train_loss = 0.66953379, time/batch = 0.0525s\n",
            "61450/63080 (epoch 9.742), train_loss = 0.64731151, time/batch = 0.0526s\n",
            "61451/63080 (epoch 9.742), train_loss = 0.65640539, time/batch = 0.0523s\n",
            "61452/63080 (epoch 9.742), train_loss = 0.62173831, time/batch = 0.0523s\n",
            "61453/63080 (epoch 9.742), train_loss = 0.67670292, time/batch = 0.0532s\n",
            "61454/63080 (epoch 9.742), train_loss = 0.63145393, time/batch = 0.0524s\n",
            "61455/63080 (epoch 9.742), train_loss = 0.67197537, time/batch = 0.0527s\n",
            "61456/63080 (epoch 9.743), train_loss = 0.65160578, time/batch = 0.0531s\n",
            "61457/63080 (epoch 9.743), train_loss = 0.65340513, time/batch = 0.0528s\n",
            "61458/63080 (epoch 9.743), train_loss = 0.65418750, time/batch = 0.0540s\n",
            "61459/63080 (epoch 9.743), train_loss = 0.65198851, time/batch = 0.0522s\n",
            "61460/63080 (epoch 9.743), train_loss = 0.65506679, time/batch = 0.0521s\n",
            "61461/63080 (epoch 9.743), train_loss = 0.62961531, time/batch = 0.0528s\n",
            "61462/63080 (epoch 9.744), train_loss = 0.63295877, time/batch = 0.0523s\n",
            "61463/63080 (epoch 9.744), train_loss = 0.64401454, time/batch = 0.0527s\n",
            "61464/63080 (epoch 9.744), train_loss = 0.65077913, time/batch = 0.0527s\n",
            "61465/63080 (epoch 9.744), train_loss = 0.64873749, time/batch = 0.0529s\n",
            "61466/63080 (epoch 9.744), train_loss = 0.64080554, time/batch = 0.0522s\n",
            "61467/63080 (epoch 9.744), train_loss = 0.64706773, time/batch = 0.0531s\n",
            "61468/63080 (epoch 9.744), train_loss = 0.65132147, time/batch = 0.0530s\n",
            "61469/63080 (epoch 9.745), train_loss = 0.62112969, time/batch = 0.0524s\n",
            "61470/63080 (epoch 9.745), train_loss = 0.65326476, time/batch = 0.0534s\n",
            "61471/63080 (epoch 9.745), train_loss = 0.65953666, time/batch = 0.0523s\n",
            "61472/63080 (epoch 9.745), train_loss = 0.62457371, time/batch = 0.0523s\n",
            "61473/63080 (epoch 9.745), train_loss = 0.64506811, time/batch = 0.0527s\n",
            "61474/63080 (epoch 9.745), train_loss = 0.65843302, time/batch = 0.0526s\n",
            "61475/63080 (epoch 9.746), train_loss = 0.64804250, time/batch = 0.0527s\n",
            "61476/63080 (epoch 9.746), train_loss = 0.64705199, time/batch = 0.0541s\n",
            "61477/63080 (epoch 9.746), train_loss = 0.64128703, time/batch = 0.0529s\n",
            "61478/63080 (epoch 9.746), train_loss = 0.64660043, time/batch = 0.0525s\n",
            "61479/63080 (epoch 9.746), train_loss = 0.65139365, time/batch = 0.0525s\n",
            "61480/63080 (epoch 9.746), train_loss = 0.66691744, time/batch = 0.0526s\n",
            "61481/63080 (epoch 9.747), train_loss = 0.67236823, time/batch = 0.0521s\n",
            "61482/63080 (epoch 9.747), train_loss = 0.66621751, time/batch = 0.0529s\n",
            "61483/63080 (epoch 9.747), train_loss = 0.67217982, time/batch = 0.0524s\n",
            "61484/63080 (epoch 9.747), train_loss = 0.66190839, time/batch = 0.0528s\n",
            "61485/63080 (epoch 9.747), train_loss = 0.67346597, time/batch = 0.0525s\n",
            "61486/63080 (epoch 9.747), train_loss = 0.67032254, time/batch = 0.0531s\n",
            "61487/63080 (epoch 9.747), train_loss = 0.66635478, time/batch = 0.0526s\n",
            "61488/63080 (epoch 9.748), train_loss = 0.65613794, time/batch = 0.0528s\n",
            "61489/63080 (epoch 9.748), train_loss = 0.66002274, time/batch = 0.0523s\n",
            "61490/63080 (epoch 9.748), train_loss = 0.64709496, time/batch = 0.0525s\n",
            "61491/63080 (epoch 9.748), train_loss = 0.65778410, time/batch = 0.0530s\n",
            "61492/63080 (epoch 9.748), train_loss = 0.64787537, time/batch = 0.0521s\n",
            "61493/63080 (epoch 9.748), train_loss = 0.66468638, time/batch = 0.0520s\n",
            "61494/63080 (epoch 9.749), train_loss = 0.65131480, time/batch = 0.0527s\n",
            "61495/63080 (epoch 9.749), train_loss = 0.65340734, time/batch = 0.0529s\n",
            "61496/63080 (epoch 9.749), train_loss = 0.63504684, time/batch = 0.0523s\n",
            "61497/63080 (epoch 9.749), train_loss = 0.68330407, time/batch = 0.0530s\n",
            "61498/63080 (epoch 9.749), train_loss = 0.65338480, time/batch = 0.0528s\n",
            "61499/63080 (epoch 9.749), train_loss = 0.65730512, time/batch = 0.0523s\n",
            "61500/63080 (epoch 9.750), train_loss = 0.66991448, time/batch = 0.0535s\n",
            "61501/63080 (epoch 9.750), train_loss = 0.65169030, time/batch = 0.0523s\n",
            "61502/63080 (epoch 9.750), train_loss = 0.62635702, time/batch = 0.0526s\n",
            "61503/63080 (epoch 9.750), train_loss = 0.70027304, time/batch = 0.0533s\n",
            "61504/63080 (epoch 9.750), train_loss = 0.67104298, time/batch = 0.0529s\n",
            "61505/63080 (epoch 9.750), train_loss = 0.68417364, time/batch = 0.0527s\n",
            "61506/63080 (epoch 9.750), train_loss = 0.64783639, time/batch = 0.0525s\n",
            "61507/63080 (epoch 9.751), train_loss = 0.65860176, time/batch = 0.0523s\n",
            "61508/63080 (epoch 9.751), train_loss = 0.65146458, time/batch = 0.0524s\n",
            "61509/63080 (epoch 9.751), train_loss = 0.65738541, time/batch = 0.0524s\n",
            "61510/63080 (epoch 9.751), train_loss = 0.64285272, time/batch = 0.0532s\n",
            "61511/63080 (epoch 9.751), train_loss = 0.64050186, time/batch = 0.0524s\n",
            "61512/63080 (epoch 9.751), train_loss = 0.63770282, time/batch = 0.0524s\n",
            "61513/63080 (epoch 9.752), train_loss = 0.65942442, time/batch = 0.0524s\n",
            "61514/63080 (epoch 9.752), train_loss = 0.65249699, time/batch = 0.0527s\n",
            "61515/63080 (epoch 9.752), train_loss = 0.66315621, time/batch = 0.0524s\n",
            "61516/63080 (epoch 9.752), train_loss = 0.64409816, time/batch = 0.0525s\n",
            "61517/63080 (epoch 9.752), train_loss = 0.65674686, time/batch = 0.0526s\n",
            "61518/63080 (epoch 9.752), train_loss = 0.65943104, time/batch = 0.0524s\n",
            "61519/63080 (epoch 9.753), train_loss = 0.65870821, time/batch = 0.0539s\n",
            "61520/63080 (epoch 9.753), train_loss = 0.67247212, time/batch = 0.0526s\n",
            "61521/63080 (epoch 9.753), train_loss = 0.66137999, time/batch = 0.0520s\n",
            "61522/63080 (epoch 9.753), train_loss = 0.66741329, time/batch = 0.0525s\n",
            "61523/63080 (epoch 9.753), train_loss = 0.66795725, time/batch = 0.0528s\n",
            "61524/63080 (epoch 9.753), train_loss = 0.68143219, time/batch = 0.0524s\n",
            "61525/63080 (epoch 9.753), train_loss = 0.65796524, time/batch = 0.0527s\n",
            "61526/63080 (epoch 9.754), train_loss = 0.66777587, time/batch = 0.0525s\n",
            "61527/63080 (epoch 9.754), train_loss = 0.66202545, time/batch = 0.0528s\n",
            "61528/63080 (epoch 9.754), train_loss = 0.65913135, time/batch = 0.0528s\n",
            "61529/63080 (epoch 9.754), train_loss = 0.64681894, time/batch = 0.0525s\n",
            "61530/63080 (epoch 9.754), train_loss = 0.66374141, time/batch = 0.0531s\n",
            "61531/63080 (epoch 9.754), train_loss = 0.63578624, time/batch = 0.0522s\n",
            "61532/63080 (epoch 9.755), train_loss = 0.68081176, time/batch = 0.0524s\n",
            "61533/63080 (epoch 9.755), train_loss = 0.68991739, time/batch = 0.0525s\n",
            "61534/63080 (epoch 9.755), train_loss = 0.67919886, time/batch = 0.0524s\n",
            "61535/63080 (epoch 9.755), train_loss = 0.70024574, time/batch = 0.0531s\n",
            "61536/63080 (epoch 9.755), train_loss = 0.68784261, time/batch = 0.0523s\n",
            "61537/63080 (epoch 9.755), train_loss = 0.67570001, time/batch = 0.0515s\n",
            "61538/63080 (epoch 9.756), train_loss = 0.65592819, time/batch = 0.0531s\n",
            "61539/63080 (epoch 9.756), train_loss = 0.67007989, time/batch = 0.0524s\n",
            "61540/63080 (epoch 9.756), train_loss = 0.64121491, time/batch = 0.0525s\n",
            "61541/63080 (epoch 9.756), train_loss = 0.63366598, time/batch = 0.0522s\n",
            "61542/63080 (epoch 9.756), train_loss = 0.65900809, time/batch = 0.0529s\n",
            "61543/63080 (epoch 9.756), train_loss = 0.65520567, time/batch = 0.0522s\n",
            "61544/63080 (epoch 9.756), train_loss = 0.64880234, time/batch = 0.0529s\n",
            "61545/63080 (epoch 9.757), train_loss = 0.68114078, time/batch = 0.0529s\n",
            "61546/63080 (epoch 9.757), train_loss = 0.65256262, time/batch = 0.0528s\n",
            "61547/63080 (epoch 9.757), train_loss = 0.66082001, time/batch = 0.0526s\n",
            "61548/63080 (epoch 9.757), train_loss = 0.67966753, time/batch = 0.0519s\n",
            "61549/63080 (epoch 9.757), train_loss = 0.62615168, time/batch = 0.0526s\n",
            "61550/63080 (epoch 9.757), train_loss = 0.66337425, time/batch = 0.0526s\n",
            "61551/63080 (epoch 9.758), train_loss = 0.64860088, time/batch = 0.0521s\n",
            "61552/63080 (epoch 9.758), train_loss = 0.65099847, time/batch = 0.0530s\n",
            "61553/63080 (epoch 9.758), train_loss = 0.67185032, time/batch = 0.0527s\n",
            "61554/63080 (epoch 9.758), train_loss = 0.65632015, time/batch = 0.0526s\n",
            "61555/63080 (epoch 9.758), train_loss = 0.66431707, time/batch = 0.0524s\n",
            "61556/63080 (epoch 9.758), train_loss = 0.65184700, time/batch = 0.0527s\n",
            "61557/63080 (epoch 9.759), train_loss = 0.66272366, time/batch = 0.0531s\n",
            "61558/63080 (epoch 9.759), train_loss = 0.63817221, time/batch = 0.0532s\n",
            "61559/63080 (epoch 9.759), train_loss = 0.64779669, time/batch = 0.0527s\n",
            "61560/63080 (epoch 9.759), train_loss = 0.63707358, time/batch = 0.0520s\n",
            "61561/63080 (epoch 9.759), train_loss = 0.68433410, time/batch = 0.0524s\n",
            "61562/63080 (epoch 9.759), train_loss = 0.65639490, time/batch = 0.0524s\n",
            "61563/63080 (epoch 9.760), train_loss = 0.65551758, time/batch = 0.0522s\n",
            "61564/63080 (epoch 9.760), train_loss = 0.66384763, time/batch = 0.0527s\n",
            "61565/63080 (epoch 9.760), train_loss = 0.64124167, time/batch = 0.0535s\n",
            "61566/63080 (epoch 9.760), train_loss = 0.66452086, time/batch = 0.0525s\n",
            "61567/63080 (epoch 9.760), train_loss = 0.66008168, time/batch = 0.0522s\n",
            "61568/63080 (epoch 9.760), train_loss = 0.68351960, time/batch = 0.0528s\n",
            "61569/63080 (epoch 9.760), train_loss = 0.65753049, time/batch = 0.0527s\n",
            "61570/63080 (epoch 9.761), train_loss = 0.65558153, time/batch = 0.0524s\n",
            "61571/63080 (epoch 9.761), train_loss = 0.68676931, time/batch = 0.0517s\n",
            "61572/63080 (epoch 9.761), train_loss = 0.66759712, time/batch = 0.0525s\n",
            "61573/63080 (epoch 9.761), train_loss = 0.65921718, time/batch = 0.0524s\n",
            "61574/63080 (epoch 9.761), train_loss = 0.64948338, time/batch = 0.0526s\n",
            "61575/63080 (epoch 9.761), train_loss = 0.67680329, time/batch = 0.0526s\n",
            "61576/63080 (epoch 9.762), train_loss = 0.68242431, time/batch = 0.0529s\n",
            "61577/63080 (epoch 9.762), train_loss = 0.67346972, time/batch = 0.0524s\n",
            "61578/63080 (epoch 9.762), train_loss = 0.69263709, time/batch = 0.0528s\n",
            "61579/63080 (epoch 9.762), train_loss = 0.67379493, time/batch = 0.0526s\n",
            "61580/63080 (epoch 9.762), train_loss = 0.67440659, time/batch = 0.0527s\n",
            "61581/63080 (epoch 9.762), train_loss = 0.66468841, time/batch = 0.0522s\n",
            "61582/63080 (epoch 9.763), train_loss = 0.65919775, time/batch = 0.0521s\n",
            "61583/63080 (epoch 9.763), train_loss = 0.66484922, time/batch = 0.0524s\n",
            "61584/63080 (epoch 9.763), train_loss = 0.65582448, time/batch = 0.0530s\n",
            "61585/63080 (epoch 9.763), train_loss = 0.64748526, time/batch = 0.0530s\n",
            "61586/63080 (epoch 9.763), train_loss = 0.66870755, time/batch = 0.0528s\n",
            "61587/63080 (epoch 9.763), train_loss = 0.66354066, time/batch = 0.0541s\n",
            "61588/63080 (epoch 9.763), train_loss = 0.66582716, time/batch = 0.0524s\n",
            "61589/63080 (epoch 9.764), train_loss = 0.67656118, time/batch = 0.0526s\n",
            "61590/63080 (epoch 9.764), train_loss = 0.67401648, time/batch = 0.0528s\n",
            "61591/63080 (epoch 9.764), train_loss = 0.68327349, time/batch = 0.0524s\n",
            "61592/63080 (epoch 9.764), train_loss = 0.64322013, time/batch = 0.0523s\n",
            "61593/63080 (epoch 9.764), train_loss = 0.66652173, time/batch = 0.0522s\n",
            "61594/63080 (epoch 9.764), train_loss = 0.67439222, time/batch = 0.0525s\n",
            "61595/63080 (epoch 9.765), train_loss = 0.67432743, time/batch = 0.0526s\n",
            "61596/63080 (epoch 9.765), train_loss = 0.67009664, time/batch = 0.0534s\n",
            "61597/63080 (epoch 9.765), train_loss = 0.66415924, time/batch = 0.0522s\n",
            "61598/63080 (epoch 9.765), train_loss = 0.67464805, time/batch = 0.0524s\n",
            "61599/63080 (epoch 9.765), train_loss = 0.66524416, time/batch = 0.0530s\n",
            "61600/63080 (epoch 9.765), train_loss = 0.66890121, time/batch = 0.0529s\n",
            "61601/63080 (epoch 9.766), train_loss = 0.64074147, time/batch = 0.0522s\n",
            "61602/63080 (epoch 9.766), train_loss = 0.66411686, time/batch = 0.0524s\n",
            "61603/63080 (epoch 9.766), train_loss = 0.67181784, time/batch = 0.0523s\n",
            "61604/63080 (epoch 9.766), train_loss = 0.65606004, time/batch = 0.0528s\n",
            "61605/63080 (epoch 9.766), train_loss = 0.66574776, time/batch = 0.0523s\n",
            "61606/63080 (epoch 9.766), train_loss = 0.67566985, time/batch = 0.0527s\n",
            "61607/63080 (epoch 9.766), train_loss = 0.66446662, time/batch = 0.0522s\n",
            "61608/63080 (epoch 9.767), train_loss = 0.67042124, time/batch = 0.0526s\n",
            "61609/63080 (epoch 9.767), train_loss = 0.65198022, time/batch = 0.0520s\n",
            "61610/63080 (epoch 9.767), train_loss = 0.68228519, time/batch = 0.0539s\n",
            "61611/63080 (epoch 9.767), train_loss = 0.66878211, time/batch = 0.0531s\n",
            "61612/63080 (epoch 9.767), train_loss = 0.69072312, time/batch = 0.0525s\n",
            "61613/63080 (epoch 9.767), train_loss = 0.67907232, time/batch = 0.0521s\n",
            "61614/63080 (epoch 9.768), train_loss = 0.67365700, time/batch = 0.0525s\n",
            "61615/63080 (epoch 9.768), train_loss = 0.68668228, time/batch = 0.0534s\n",
            "61616/63080 (epoch 9.768), train_loss = 0.66973990, time/batch = 0.0520s\n",
            "61617/63080 (epoch 9.768), train_loss = 0.69318348, time/batch = 0.0524s\n",
            "61618/63080 (epoch 9.768), train_loss = 0.66957223, time/batch = 0.0531s\n",
            "61619/63080 (epoch 9.768), train_loss = 0.67498267, time/batch = 0.0523s\n",
            "61620/63080 (epoch 9.769), train_loss = 0.67732781, time/batch = 0.0528s\n",
            "61621/63080 (epoch 9.769), train_loss = 0.67960179, time/batch = 0.0525s\n",
            "61622/63080 (epoch 9.769), train_loss = 0.68201166, time/batch = 0.0523s\n",
            "61623/63080 (epoch 9.769), train_loss = 0.67380667, time/batch = 0.0522s\n",
            "61624/63080 (epoch 9.769), train_loss = 0.67135286, time/batch = 0.0528s\n",
            "61625/63080 (epoch 9.769), train_loss = 0.66839248, time/batch = 0.0529s\n",
            "61626/63080 (epoch 9.769), train_loss = 0.67997366, time/batch = 0.0525s\n",
            "61627/63080 (epoch 9.770), train_loss = 0.65648001, time/batch = 0.0520s\n",
            "61628/63080 (epoch 9.770), train_loss = 0.65971357, time/batch = 0.0527s\n",
            "61629/63080 (epoch 9.770), train_loss = 0.67694819, time/batch = 0.0522s\n",
            "61630/63080 (epoch 9.770), train_loss = 0.67882121, time/batch = 0.0523s\n",
            "61631/63080 (epoch 9.770), train_loss = 0.66501164, time/batch = 0.0530s\n",
            "61632/63080 (epoch 9.770), train_loss = 0.68008757, time/batch = 0.0524s\n",
            "61633/63080 (epoch 9.771), train_loss = 0.67463493, time/batch = 0.0523s\n",
            "61634/63080 (epoch 9.771), train_loss = 0.67669225, time/batch = 0.0531s\n",
            "61635/63080 (epoch 9.771), train_loss = 0.68399513, time/batch = 0.0525s\n",
            "61636/63080 (epoch 9.771), train_loss = 0.68536037, time/batch = 0.0529s\n",
            "61637/63080 (epoch 9.771), train_loss = 0.64960796, time/batch = 0.0522s\n",
            "61638/63080 (epoch 9.771), train_loss = 0.65930182, time/batch = 0.0513s\n",
            "61639/63080 (epoch 9.772), train_loss = 0.65034050, time/batch = 0.0524s\n",
            "61640/63080 (epoch 9.772), train_loss = 0.65138453, time/batch = 0.0522s\n",
            "61641/63080 (epoch 9.772), train_loss = 0.67582095, time/batch = 0.0523s\n",
            "61642/63080 (epoch 9.772), train_loss = 0.67505944, time/batch = 0.0525s\n",
            "61643/63080 (epoch 9.772), train_loss = 0.66605759, time/batch = 0.0527s\n",
            "61644/63080 (epoch 9.772), train_loss = 0.65441519, time/batch = 0.0534s\n",
            "61645/63080 (epoch 9.773), train_loss = 0.66795343, time/batch = 0.0536s\n",
            "61646/63080 (epoch 9.773), train_loss = 0.68051386, time/batch = 0.0524s\n",
            "61647/63080 (epoch 9.773), train_loss = 0.67103243, time/batch = 0.0526s\n",
            "61648/63080 (epoch 9.773), train_loss = 0.66191465, time/batch = 0.0523s\n",
            "61649/63080 (epoch 9.773), train_loss = 0.66345400, time/batch = 0.0518s\n",
            "61650/63080 (epoch 9.773), train_loss = 0.67869145, time/batch = 0.0528s\n",
            "61651/63080 (epoch 9.773), train_loss = 0.64882290, time/batch = 0.0524s\n",
            "61652/63080 (epoch 9.774), train_loss = 0.68604499, time/batch = 0.0524s\n",
            "61653/63080 (epoch 9.774), train_loss = 0.63994241, time/batch = 0.0533s\n",
            "61654/63080 (epoch 9.774), train_loss = 0.66058785, time/batch = 0.0533s\n",
            "61655/63080 (epoch 9.774), train_loss = 0.66210788, time/batch = 0.0525s\n",
            "61656/63080 (epoch 9.774), train_loss = 0.66658902, time/batch = 0.0525s\n",
            "61657/63080 (epoch 9.774), train_loss = 0.67082375, time/batch = 0.0528s\n",
            "61658/63080 (epoch 9.775), train_loss = 0.65437907, time/batch = 0.0523s\n",
            "61659/63080 (epoch 9.775), train_loss = 0.67646080, time/batch = 0.0519s\n",
            "61660/63080 (epoch 9.775), train_loss = 0.67580712, time/batch = 0.0530s\n",
            "61661/63080 (epoch 9.775), train_loss = 0.67196584, time/batch = 0.0530s\n",
            "61662/63080 (epoch 9.775), train_loss = 0.66857576, time/batch = 0.0523s\n",
            "61663/63080 (epoch 9.775), train_loss = 0.66243112, time/batch = 0.0526s\n",
            "61664/63080 (epoch 9.776), train_loss = 0.66960377, time/batch = 0.0530s\n",
            "61665/63080 (epoch 9.776), train_loss = 0.66072118, time/batch = 0.0524s\n",
            "61666/63080 (epoch 9.776), train_loss = 0.67627937, time/batch = 0.0529s\n",
            "61667/63080 (epoch 9.776), train_loss = 0.66793543, time/batch = 0.0524s\n",
            "61668/63080 (epoch 9.776), train_loss = 0.65704441, time/batch = 0.0526s\n",
            "61669/63080 (epoch 9.776), train_loss = 0.69556034, time/batch = 0.0527s\n",
            "61670/63080 (epoch 9.776), train_loss = 0.65375054, time/batch = 0.0524s\n",
            "61671/63080 (epoch 9.777), train_loss = 0.66760546, time/batch = 0.0523s\n",
            "61672/63080 (epoch 9.777), train_loss = 0.67895126, time/batch = 0.0526s\n",
            "61673/63080 (epoch 9.777), train_loss = 0.69023842, time/batch = 0.0529s\n",
            "61674/63080 (epoch 9.777), train_loss = 0.68179065, time/batch = 0.0527s\n",
            "61675/63080 (epoch 9.777), train_loss = 0.67510146, time/batch = 0.0530s\n",
            "61676/63080 (epoch 9.777), train_loss = 0.66956949, time/batch = 0.0531s\n",
            "61677/63080 (epoch 9.778), train_loss = 0.67645580, time/batch = 0.0524s\n",
            "61678/63080 (epoch 9.778), train_loss = 0.66851199, time/batch = 0.0525s\n",
            "61679/63080 (epoch 9.778), train_loss = 0.66935515, time/batch = 0.0526s\n",
            "61680/63080 (epoch 9.778), train_loss = 0.66611093, time/batch = 0.0528s\n",
            "61681/63080 (epoch 9.778), train_loss = 0.67270792, time/batch = 0.0544s\n",
            "61682/63080 (epoch 9.778), train_loss = 0.69828552, time/batch = 0.0524s\n",
            "61683/63080 (epoch 9.779), train_loss = 0.66993457, time/batch = 0.0530s\n",
            "61684/63080 (epoch 9.779), train_loss = 0.70772153, time/batch = 0.0527s\n",
            "61685/63080 (epoch 9.779), train_loss = 0.65450144, time/batch = 0.0523s\n",
            "61686/63080 (epoch 9.779), train_loss = 0.67936343, time/batch = 0.0524s\n",
            "61687/63080 (epoch 9.779), train_loss = 0.67471683, time/batch = 0.0537s\n",
            "61688/63080 (epoch 9.779), train_loss = 0.67808807, time/batch = 0.0524s\n",
            "61689/63080 (epoch 9.779), train_loss = 0.66175050, time/batch = 0.0526s\n",
            "61690/63080 (epoch 9.780), train_loss = 0.68278676, time/batch = 0.0528s\n",
            "61691/63080 (epoch 9.780), train_loss = 0.66396970, time/batch = 0.0521s\n",
            "61692/63080 (epoch 9.780), train_loss = 0.65387726, time/batch = 0.0524s\n",
            "61693/63080 (epoch 9.780), train_loss = 0.68118203, time/batch = 0.0523s\n",
            "61694/63080 (epoch 9.780), train_loss = 0.68824452, time/batch = 0.0530s\n",
            "61695/63080 (epoch 9.780), train_loss = 0.67371029, time/batch = 0.0523s\n",
            "61696/63080 (epoch 9.781), train_loss = 0.68428940, time/batch = 0.0524s\n",
            "61697/63080 (epoch 9.781), train_loss = 0.66829425, time/batch = 0.0526s\n",
            "61698/63080 (epoch 9.781), train_loss = 0.66644472, time/batch = 0.0553s\n",
            "61699/63080 (epoch 9.781), train_loss = 0.64442039, time/batch = 0.0527s\n",
            "61700/63080 (epoch 9.781), train_loss = 0.67210162, time/batch = 0.0526s\n",
            "61701/63080 (epoch 9.781), train_loss = 0.67572069, time/batch = 0.0530s\n",
            "61702/63080 (epoch 9.782), train_loss = 0.68916684, time/batch = 0.0523s\n",
            "61703/63080 (epoch 9.782), train_loss = 0.66707009, time/batch = 0.0523s\n",
            "61704/63080 (epoch 9.782), train_loss = 0.67371756, time/batch = 0.0530s\n",
            "61705/63080 (epoch 9.782), train_loss = 0.67767698, time/batch = 0.0521s\n",
            "61706/63080 (epoch 9.782), train_loss = 0.67262971, time/batch = 0.0528s\n",
            "61707/63080 (epoch 9.782), train_loss = 0.66681397, time/batch = 0.0523s\n",
            "61708/63080 (epoch 9.782), train_loss = 0.68389100, time/batch = 0.0527s\n",
            "61709/63080 (epoch 9.783), train_loss = 0.67387706, time/batch = 0.0526s\n",
            "61710/63080 (epoch 9.783), train_loss = 0.67517006, time/batch = 0.0528s\n",
            "61711/63080 (epoch 9.783), train_loss = 0.65674061, time/batch = 0.0519s\n",
            "61712/63080 (epoch 9.783), train_loss = 0.69619012, time/batch = 0.0524s\n",
            "61713/63080 (epoch 9.783), train_loss = 0.69463730, time/batch = 0.0535s\n",
            "61714/63080 (epoch 9.783), train_loss = 0.69654840, time/batch = 0.0525s\n",
            "61715/63080 (epoch 9.784), train_loss = 0.66431385, time/batch = 0.0529s\n",
            "61716/63080 (epoch 9.784), train_loss = 0.67767048, time/batch = 0.0522s\n",
            "61717/63080 (epoch 9.784), train_loss = 0.64994407, time/batch = 0.0533s\n",
            "61718/63080 (epoch 9.784), train_loss = 0.68363875, time/batch = 0.0523s\n",
            "61719/63080 (epoch 9.784), train_loss = 0.68803298, time/batch = 0.0526s\n",
            "61720/63080 (epoch 9.784), train_loss = 0.65871251, time/batch = 0.0538s\n",
            "61721/63080 (epoch 9.785), train_loss = 0.66438949, time/batch = 0.0527s\n",
            "61722/63080 (epoch 9.785), train_loss = 0.69394749, time/batch = 0.0522s\n",
            "61723/63080 (epoch 9.785), train_loss = 0.66855019, time/batch = 0.0522s\n",
            "61724/63080 (epoch 9.785), train_loss = 0.68547088, time/batch = 0.0525s\n",
            "61725/63080 (epoch 9.785), train_loss = 0.67575234, time/batch = 0.0526s\n",
            "61726/63080 (epoch 9.785), train_loss = 0.66760957, time/batch = 0.0529s\n",
            "61727/63080 (epoch 9.786), train_loss = 0.65989900, time/batch = 0.0515s\n",
            "61728/63080 (epoch 9.786), train_loss = 0.66329962, time/batch = 0.0524s\n",
            "61729/63080 (epoch 9.786), train_loss = 0.66968119, time/batch = 0.0526s\n",
            "61730/63080 (epoch 9.786), train_loss = 0.67431855, time/batch = 0.0528s\n",
            "61731/63080 (epoch 9.786), train_loss = 0.66971970, time/batch = 0.0524s\n",
            "61732/63080 (epoch 9.786), train_loss = 0.69831294, time/batch = 0.0523s\n",
            "61733/63080 (epoch 9.786), train_loss = 0.67319095, time/batch = 0.0528s\n",
            "61734/63080 (epoch 9.787), train_loss = 0.69859183, time/batch = 0.0523s\n",
            "61735/63080 (epoch 9.787), train_loss = 0.68393749, time/batch = 0.0537s\n",
            "61736/63080 (epoch 9.787), train_loss = 0.69868422, time/batch = 0.0532s\n",
            "61737/63080 (epoch 9.787), train_loss = 0.67446160, time/batch = 0.0522s\n",
            "61738/63080 (epoch 9.787), train_loss = 0.67655224, time/batch = 0.0528s\n",
            "61739/63080 (epoch 9.787), train_loss = 0.68531853, time/batch = 0.0523s\n",
            "61740/63080 (epoch 9.788), train_loss = 0.67503011, time/batch = 0.0527s\n",
            "61741/63080 (epoch 9.788), train_loss = 0.66646630, time/batch = 0.0521s\n",
            "61742/63080 (epoch 9.788), train_loss = 0.67382747, time/batch = 0.0526s\n",
            "61743/63080 (epoch 9.788), train_loss = 0.67676657, time/batch = 0.0525s\n",
            "61744/63080 (epoch 9.788), train_loss = 0.65783179, time/batch = 0.0530s\n",
            "61745/63080 (epoch 9.788), train_loss = 0.65147525, time/batch = 0.0525s\n",
            "61746/63080 (epoch 9.789), train_loss = 0.63189709, time/batch = 0.0523s\n",
            "61747/63080 (epoch 9.789), train_loss = 0.64776111, time/batch = 0.0545s\n",
            "61748/63080 (epoch 9.789), train_loss = 0.66604841, time/batch = 0.0532s\n",
            "61749/63080 (epoch 9.789), train_loss = 0.63658065, time/batch = 0.0524s\n",
            "61750/63080 (epoch 9.789), train_loss = 0.66693479, time/batch = 0.0523s\n",
            "61751/63080 (epoch 9.789), train_loss = 0.67043209, time/batch = 0.0527s\n",
            "61752/63080 (epoch 9.789), train_loss = 0.68590277, time/batch = 0.0525s\n",
            "61753/63080 (epoch 9.790), train_loss = 0.66405219, time/batch = 0.0529s\n",
            "61754/63080 (epoch 9.790), train_loss = 0.67474216, time/batch = 0.0526s\n",
            "61755/63080 (epoch 9.790), train_loss = 0.67770827, time/batch = 0.0530s\n",
            "61756/63080 (epoch 9.790), train_loss = 0.67659962, time/batch = 0.0523s\n",
            "61757/63080 (epoch 9.790), train_loss = 0.69155371, time/batch = 0.0522s\n",
            "61758/63080 (epoch 9.790), train_loss = 0.68798310, time/batch = 0.0528s\n",
            "61759/63080 (epoch 9.791), train_loss = 0.67433101, time/batch = 0.0530s\n",
            "61760/63080 (epoch 9.791), train_loss = 0.67352450, time/batch = 0.0527s\n",
            "61761/63080 (epoch 9.791), train_loss = 0.67616123, time/batch = 0.0525s\n",
            "61762/63080 (epoch 9.791), train_loss = 0.65136951, time/batch = 0.0530s\n",
            "61763/63080 (epoch 9.791), train_loss = 0.66641271, time/batch = 0.0525s\n",
            "61764/63080 (epoch 9.791), train_loss = 0.66056800, time/batch = 0.0526s\n",
            "61765/63080 (epoch 9.792), train_loss = 0.66336924, time/batch = 0.0529s\n",
            "61766/63080 (epoch 9.792), train_loss = 0.66807377, time/batch = 0.0522s\n",
            "61767/63080 (epoch 9.792), train_loss = 0.69992000, time/batch = 0.0525s\n",
            "61768/63080 (epoch 9.792), train_loss = 0.67556220, time/batch = 0.0522s\n",
            "61769/63080 (epoch 9.792), train_loss = 0.69911027, time/batch = 0.0527s\n",
            "61770/63080 (epoch 9.792), train_loss = 0.66899079, time/batch = 0.0528s\n",
            "61771/63080 (epoch 9.792), train_loss = 0.67114776, time/batch = 0.0514s\n",
            "61772/63080 (epoch 9.793), train_loss = 0.67750317, time/batch = 0.0524s\n",
            "61773/63080 (epoch 9.793), train_loss = 0.69809783, time/batch = 0.0526s\n",
            "61774/63080 (epoch 9.793), train_loss = 0.65412390, time/batch = 0.0528s\n",
            "61775/63080 (epoch 9.793), train_loss = 0.65096623, time/batch = 0.0531s\n",
            "61776/63080 (epoch 9.793), train_loss = 0.66745168, time/batch = 0.0533s\n",
            "61777/63080 (epoch 9.793), train_loss = 0.68572116, time/batch = 0.0522s\n",
            "61778/63080 (epoch 9.794), train_loss = 0.65578187, time/batch = 0.0523s\n",
            "61779/63080 (epoch 9.794), train_loss = 0.67876136, time/batch = 0.0528s\n",
            "61780/63080 (epoch 9.794), train_loss = 0.68252957, time/batch = 0.0529s\n",
            "61781/63080 (epoch 9.794), train_loss = 0.66626656, time/batch = 0.0518s\n",
            "61782/63080 (epoch 9.794), train_loss = 0.64850795, time/batch = 0.0526s\n",
            "61783/63080 (epoch 9.794), train_loss = 0.67137879, time/batch = 0.0529s\n",
            "61784/63080 (epoch 9.795), train_loss = 0.68533456, time/batch = 0.0525s\n",
            "61785/63080 (epoch 9.795), train_loss = 0.65092182, time/batch = 0.0529s\n",
            "61786/63080 (epoch 9.795), train_loss = 0.65440279, time/batch = 0.0529s\n",
            "61787/63080 (epoch 9.795), train_loss = 0.63473976, time/batch = 0.0522s\n",
            "61788/63080 (epoch 9.795), train_loss = 0.63674736, time/batch = 0.0526s\n",
            "61789/63080 (epoch 9.795), train_loss = 0.63937837, time/batch = 0.0523s\n",
            "61790/63080 (epoch 9.795), train_loss = 0.67735487, time/batch = 0.0525s\n",
            "61791/63080 (epoch 9.796), train_loss = 0.66685998, time/batch = 0.0527s\n",
            "61792/63080 (epoch 9.796), train_loss = 0.65932077, time/batch = 0.0527s\n",
            "61793/63080 (epoch 9.796), train_loss = 0.65939361, time/batch = 0.0524s\n",
            "61794/63080 (epoch 9.796), train_loss = 0.67989779, time/batch = 0.0526s\n",
            "61795/63080 (epoch 9.796), train_loss = 0.67097187, time/batch = 0.0525s\n",
            "61796/63080 (epoch 9.796), train_loss = 0.66685569, time/batch = 0.0526s\n",
            "61797/63080 (epoch 9.797), train_loss = 0.66705781, time/batch = 0.0524s\n",
            "61798/63080 (epoch 9.797), train_loss = 0.67387044, time/batch = 0.0537s\n",
            "61799/63080 (epoch 9.797), train_loss = 0.67093593, time/batch = 0.0523s\n",
            "61800/63080 (epoch 9.797), train_loss = 0.67776924, time/batch = 0.0527s\n",
            "61801/63080 (epoch 9.797), train_loss = 0.66337281, time/batch = 0.0520s\n",
            "61802/63080 (epoch 9.797), train_loss = 0.64644539, time/batch = 0.0524s\n",
            "61803/63080 (epoch 9.798), train_loss = 0.66763902, time/batch = 0.0525s\n",
            "61804/63080 (epoch 9.798), train_loss = 0.67569464, time/batch = 0.0521s\n",
            "61805/63080 (epoch 9.798), train_loss = 0.66065955, time/batch = 0.0525s\n",
            "61806/63080 (epoch 9.798), train_loss = 0.66455013, time/batch = 0.0526s\n",
            "61807/63080 (epoch 9.798), train_loss = 0.64608735, time/batch = 0.0527s\n",
            "61808/63080 (epoch 9.798), train_loss = 0.67307794, time/batch = 0.0527s\n",
            "61809/63080 (epoch 9.799), train_loss = 0.67962760, time/batch = 0.0531s\n",
            "61810/63080 (epoch 9.799), train_loss = 0.68099761, time/batch = 0.0522s\n",
            "61811/63080 (epoch 9.799), train_loss = 0.66869277, time/batch = 0.0521s\n",
            "61812/63080 (epoch 9.799), train_loss = 0.67627114, time/batch = 0.0526s\n",
            "61813/63080 (epoch 9.799), train_loss = 0.67941779, time/batch = 0.0527s\n",
            "61814/63080 (epoch 9.799), train_loss = 0.70574969, time/batch = 0.0525s\n",
            "61815/63080 (epoch 9.799), train_loss = 0.68207026, time/batch = 0.0528s\n",
            "61816/63080 (epoch 9.800), train_loss = 0.66643590, time/batch = 0.0531s\n",
            "61817/63080 (epoch 9.800), train_loss = 0.67809516, time/batch = 0.0524s\n",
            "61818/63080 (epoch 9.800), train_loss = 0.67970878, time/batch = 0.0525s\n",
            "61819/63080 (epoch 9.800), train_loss = 0.66696715, time/batch = 0.0529s\n",
            "61820/63080 (epoch 9.800), train_loss = 0.66667253, time/batch = 0.0526s\n",
            "61821/63080 (epoch 9.800), train_loss = 0.65403026, time/batch = 0.0522s\n",
            "61822/63080 (epoch 9.801), train_loss = 0.66018057, time/batch = 0.0524s\n",
            "61823/63080 (epoch 9.801), train_loss = 0.68328881, time/batch = 0.0527s\n",
            "61824/63080 (epoch 9.801), train_loss = 0.66645026, time/batch = 0.0535s\n",
            "61825/63080 (epoch 9.801), train_loss = 0.67960048, time/batch = 0.0530s\n",
            "61826/63080 (epoch 9.801), train_loss = 0.66967928, time/batch = 0.0522s\n",
            "61827/63080 (epoch 9.801), train_loss = 0.67429054, time/batch = 0.0523s\n",
            "61828/63080 (epoch 9.802), train_loss = 0.68157339, time/batch = 0.0530s\n",
            "61829/63080 (epoch 9.802), train_loss = 0.65769112, time/batch = 0.0532s\n",
            "61830/63080 (epoch 9.802), train_loss = 0.67628622, time/batch = 0.0523s\n",
            "61831/63080 (epoch 9.802), train_loss = 0.66909307, time/batch = 0.0532s\n",
            "61832/63080 (epoch 9.802), train_loss = 0.68467432, time/batch = 0.0526s\n",
            "61833/63080 (epoch 9.802), train_loss = 0.67347187, time/batch = 0.0526s\n",
            "61834/63080 (epoch 9.802), train_loss = 0.67133528, time/batch = 0.0526s\n",
            "61835/63080 (epoch 9.803), train_loss = 0.64806807, time/batch = 0.0527s\n",
            "61836/63080 (epoch 9.803), train_loss = 0.66239750, time/batch = 0.0531s\n",
            "61837/63080 (epoch 9.803), train_loss = 0.67720550, time/batch = 0.0525s\n",
            "61838/63080 (epoch 9.803), train_loss = 0.67202812, time/batch = 0.0525s\n",
            "61839/63080 (epoch 9.803), train_loss = 0.68070829, time/batch = 0.0524s\n",
            "61840/63080 (epoch 9.803), train_loss = 0.69130963, time/batch = 0.0537s\n",
            "61841/63080 (epoch 9.804), train_loss = 0.64762270, time/batch = 0.0524s\n",
            "61842/63080 (epoch 9.804), train_loss = 0.68139231, time/batch = 0.0525s\n",
            "61843/63080 (epoch 9.804), train_loss = 0.66229808, time/batch = 0.0532s\n",
            "61844/63080 (epoch 9.804), train_loss = 0.65868121, time/batch = 0.0527s\n",
            "61845/63080 (epoch 9.804), train_loss = 0.65780598, time/batch = 0.0527s\n",
            "61846/63080 (epoch 9.804), train_loss = 0.67109346, time/batch = 0.0526s\n",
            "61847/63080 (epoch 9.805), train_loss = 0.66077822, time/batch = 0.0529s\n",
            "61848/63080 (epoch 9.805), train_loss = 0.67515355, time/batch = 0.0532s\n",
            "61849/63080 (epoch 9.805), train_loss = 0.63758296, time/batch = 0.0522s\n",
            "61850/63080 (epoch 9.805), train_loss = 0.67309314, time/batch = 0.0529s\n",
            "61851/63080 (epoch 9.805), train_loss = 0.65462494, time/batch = 0.0521s\n",
            "61852/63080 (epoch 9.805), train_loss = 0.63090646, time/batch = 0.0529s\n",
            "61853/63080 (epoch 9.805), train_loss = 0.67063558, time/batch = 0.0525s\n",
            "61854/63080 (epoch 9.806), train_loss = 0.66844916, time/batch = 0.0525s\n",
            "61855/63080 (epoch 9.806), train_loss = 0.65671706, time/batch = 0.0525s\n",
            "61856/63080 (epoch 9.806), train_loss = 0.64034003, time/batch = 0.0525s\n",
            "61857/63080 (epoch 9.806), train_loss = 0.65863127, time/batch = 0.0525s\n",
            "61858/63080 (epoch 9.806), train_loss = 0.63300759, time/batch = 0.0528s\n",
            "61859/63080 (epoch 9.806), train_loss = 0.65645045, time/batch = 0.0538s\n",
            "61860/63080 (epoch 9.807), train_loss = 0.66368920, time/batch = 0.0529s\n",
            "61861/63080 (epoch 9.807), train_loss = 0.65813237, time/batch = 0.0524s\n",
            "61862/63080 (epoch 9.807), train_loss = 0.64376843, time/batch = 0.0524s\n",
            "61863/63080 (epoch 9.807), train_loss = 0.63484448, time/batch = 0.0523s\n",
            "61864/63080 (epoch 9.807), train_loss = 0.65160298, time/batch = 0.0528s\n",
            "61865/63080 (epoch 9.807), train_loss = 0.64369768, time/batch = 0.0528s\n",
            "61866/63080 (epoch 9.808), train_loss = 0.66705567, time/batch = 0.0525s\n",
            "61867/63080 (epoch 9.808), train_loss = 0.64087367, time/batch = 0.0525s\n",
            "61868/63080 (epoch 9.808), train_loss = 0.62289143, time/batch = 0.0527s\n",
            "61869/63080 (epoch 9.808), train_loss = 0.65562665, time/batch = 0.0530s\n",
            "61870/63080 (epoch 9.808), train_loss = 0.64293677, time/batch = 0.0549s\n",
            "61871/63080 (epoch 9.808), train_loss = 0.63074529, time/batch = 0.0515s\n",
            "61872/63080 (epoch 9.808), train_loss = 0.64355314, time/batch = 0.0527s\n",
            "61873/63080 (epoch 9.809), train_loss = 0.65432686, time/batch = 0.0523s\n",
            "61874/63080 (epoch 9.809), train_loss = 0.66530550, time/batch = 0.0526s\n",
            "61875/63080 (epoch 9.809), train_loss = 0.63483119, time/batch = 0.0524s\n",
            "61876/63080 (epoch 9.809), train_loss = 0.63508838, time/batch = 0.0525s\n",
            "61877/63080 (epoch 9.809), train_loss = 0.66265357, time/batch = 0.0526s\n",
            "61878/63080 (epoch 9.809), train_loss = 0.64141518, time/batch = 0.0524s\n",
            "61879/63080 (epoch 9.810), train_loss = 0.62033218, time/batch = 0.0524s\n",
            "61880/63080 (epoch 9.810), train_loss = 0.63533479, time/batch = 0.0534s\n",
            "61881/63080 (epoch 9.810), train_loss = 0.65688765, time/batch = 0.0525s\n",
            "61882/63080 (epoch 9.810), train_loss = 0.63820994, time/batch = 0.0524s\n",
            "61883/63080 (epoch 9.810), train_loss = 0.63078880, time/batch = 0.0523s\n",
            "61884/63080 (epoch 9.810), train_loss = 0.65012252, time/batch = 0.0527s\n",
            "61885/63080 (epoch 9.811), train_loss = 0.64577276, time/batch = 0.0524s\n",
            "61886/63080 (epoch 9.811), train_loss = 0.64132988, time/batch = 0.0534s\n",
            "61887/63080 (epoch 9.811), train_loss = 0.64715290, time/batch = 0.0526s\n",
            "61888/63080 (epoch 9.811), train_loss = 0.65887946, time/batch = 0.0528s\n",
            "61889/63080 (epoch 9.811), train_loss = 0.64396244, time/batch = 0.0524s\n",
            "61890/63080 (epoch 9.811), train_loss = 0.67308038, time/batch = 0.0525s\n",
            "61891/63080 (epoch 9.812), train_loss = 0.64636070, time/batch = 0.0527s\n",
            "61892/63080 (epoch 9.812), train_loss = 0.63789713, time/batch = 0.0530s\n",
            "61893/63080 (epoch 9.812), train_loss = 0.65606040, time/batch = 0.0530s\n",
            "61894/63080 (epoch 9.812), train_loss = 0.62194228, time/batch = 0.0526s\n",
            "61895/63080 (epoch 9.812), train_loss = 0.64131862, time/batch = 0.0525s\n",
            "61896/63080 (epoch 9.812), train_loss = 0.64007962, time/batch = 0.0528s\n",
            "61897/63080 (epoch 9.812), train_loss = 0.63356549, time/batch = 0.0534s\n",
            "61898/63080 (epoch 9.813), train_loss = 0.64633632, time/batch = 0.0523s\n",
            "61899/63080 (epoch 9.813), train_loss = 0.64407873, time/batch = 0.0522s\n",
            "61900/63080 (epoch 9.813), train_loss = 0.65807545, time/batch = 0.0526s\n",
            "61901/63080 (epoch 9.813), train_loss = 0.65167367, time/batch = 0.0533s\n",
            "61902/63080 (epoch 9.813), train_loss = 0.64427978, time/batch = 0.0521s\n",
            "61903/63080 (epoch 9.813), train_loss = 0.66109985, time/batch = 0.0508s\n",
            "61904/63080 (epoch 9.814), train_loss = 0.65761375, time/batch = 0.0528s\n",
            "61905/63080 (epoch 9.814), train_loss = 0.65889990, time/batch = 0.0533s\n",
            "61906/63080 (epoch 9.814), train_loss = 0.65940070, time/batch = 0.0527s\n",
            "61907/63080 (epoch 9.814), train_loss = 0.65657908, time/batch = 0.0526s\n",
            "61908/63080 (epoch 9.814), train_loss = 0.65835714, time/batch = 0.0529s\n",
            "61909/63080 (epoch 9.814), train_loss = 0.64769626, time/batch = 0.0524s\n",
            "61910/63080 (epoch 9.815), train_loss = 0.64928108, time/batch = 0.0528s\n",
            "61911/63080 (epoch 9.815), train_loss = 0.64819294, time/batch = 0.0524s\n",
            "61912/63080 (epoch 9.815), train_loss = 0.62675589, time/batch = 0.0531s\n",
            "61913/63080 (epoch 9.815), train_loss = 0.63914067, time/batch = 0.0523s\n",
            "61914/63080 (epoch 9.815), train_loss = 0.66060477, time/batch = 0.0527s\n",
            "61915/63080 (epoch 9.815), train_loss = 0.63197351, time/batch = 0.0525s\n",
            "61916/63080 (epoch 9.815), train_loss = 0.63451016, time/batch = 0.0523s\n",
            "61917/63080 (epoch 9.816), train_loss = 0.65961826, time/batch = 0.0531s\n",
            "61918/63080 (epoch 9.816), train_loss = 0.64896584, time/batch = 0.0522s\n",
            "61919/63080 (epoch 9.816), train_loss = 0.66311127, time/batch = 0.0534s\n",
            "61920/63080 (epoch 9.816), train_loss = 0.65512788, time/batch = 0.0538s\n",
            "61921/63080 (epoch 9.816), train_loss = 0.62689382, time/batch = 0.0523s\n",
            "61922/63080 (epoch 9.816), train_loss = 0.61386186, time/batch = 0.0526s\n",
            "61923/63080 (epoch 9.817), train_loss = 0.59737444, time/batch = 0.0523s\n",
            "61924/63080 (epoch 9.817), train_loss = 0.65196484, time/batch = 0.0528s\n",
            "61925/63080 (epoch 9.817), train_loss = 0.65740162, time/batch = 0.0536s\n",
            "61926/63080 (epoch 9.817), train_loss = 0.66636765, time/batch = 0.0523s\n",
            "61927/63080 (epoch 9.817), train_loss = 0.65694988, time/batch = 0.0525s\n",
            "61928/63080 (epoch 9.817), train_loss = 0.63982838, time/batch = 0.0528s\n",
            "61929/63080 (epoch 9.818), train_loss = 0.63746589, time/batch = 0.0527s\n",
            "61930/63080 (epoch 9.818), train_loss = 0.65407294, time/batch = 0.0529s\n",
            "61931/63080 (epoch 9.818), train_loss = 0.64532059, time/batch = 0.0522s\n",
            "61932/63080 (epoch 9.818), train_loss = 0.63894939, time/batch = 0.0526s\n",
            "61933/63080 (epoch 9.818), train_loss = 0.65555578, time/batch = 0.0526s\n",
            "61934/63080 (epoch 9.818), train_loss = 0.64679533, time/batch = 0.0527s\n",
            "61935/63080 (epoch 9.818), train_loss = 0.64969218, time/batch = 0.0523s\n",
            "61936/63080 (epoch 9.819), train_loss = 0.67566192, time/batch = 0.0524s\n",
            "61937/63080 (epoch 9.819), train_loss = 0.67655045, time/batch = 0.0523s\n",
            "61938/63080 (epoch 9.819), train_loss = 0.64226288, time/batch = 0.0524s\n",
            "61939/63080 (epoch 9.819), train_loss = 0.67672253, time/batch = 0.0522s\n",
            "61940/63080 (epoch 9.819), train_loss = 0.65633631, time/batch = 0.0524s\n",
            "61941/63080 (epoch 9.819), train_loss = 0.64147198, time/batch = 0.0543s\n",
            "61942/63080 (epoch 9.820), train_loss = 0.65382749, time/batch = 0.0524s\n",
            "61943/63080 (epoch 9.820), train_loss = 0.64921796, time/batch = 0.0531s\n",
            "61944/63080 (epoch 9.820), train_loss = 0.62086242, time/batch = 0.0530s\n",
            "61945/63080 (epoch 9.820), train_loss = 0.63246894, time/batch = 0.0525s\n",
            "61946/63080 (epoch 9.820), train_loss = 0.64950120, time/batch = 0.0528s\n",
            "61947/63080 (epoch 9.820), train_loss = 0.63301718, time/batch = 0.0525s\n",
            "61948/63080 (epoch 9.821), train_loss = 0.64515519, time/batch = 0.0523s\n",
            "61949/63080 (epoch 9.821), train_loss = 0.63295001, time/batch = 0.0520s\n",
            "61950/63080 (epoch 9.821), train_loss = 0.62815851, time/batch = 0.0528s\n",
            "61951/63080 (epoch 9.821), train_loss = 0.66056049, time/batch = 0.0525s\n",
            "61952/63080 (epoch 9.821), train_loss = 0.64805323, time/batch = 0.0529s\n",
            "61953/63080 (epoch 9.821), train_loss = 0.63235521, time/batch = 0.0522s\n",
            "61954/63080 (epoch 9.821), train_loss = 0.62083495, time/batch = 0.0524s\n",
            "61955/63080 (epoch 9.822), train_loss = 0.64511931, time/batch = 0.0524s\n",
            "61956/63080 (epoch 9.822), train_loss = 0.64609677, time/batch = 0.0526s\n",
            "61957/63080 (epoch 9.822), train_loss = 0.66582131, time/batch = 0.0530s\n",
            "61958/63080 (epoch 9.822), train_loss = 0.63618284, time/batch = 0.0518s\n",
            "61959/63080 (epoch 9.822), train_loss = 0.66828084, time/batch = 0.0524s\n",
            "61960/63080 (epoch 9.822), train_loss = 0.67984772, time/batch = 0.0525s\n",
            "61961/63080 (epoch 9.823), train_loss = 0.65681750, time/batch = 0.0520s\n",
            "61962/63080 (epoch 9.823), train_loss = 0.65969479, time/batch = 0.0525s\n",
            "61963/63080 (epoch 9.823), train_loss = 0.63485682, time/batch = 0.0526s\n",
            "61964/63080 (epoch 9.823), train_loss = 0.64370173, time/batch = 0.0523s\n",
            "61965/63080 (epoch 9.823), train_loss = 0.67052972, time/batch = 0.0523s\n",
            "61966/63080 (epoch 9.823), train_loss = 0.64744925, time/batch = 0.0524s\n",
            "61967/63080 (epoch 9.824), train_loss = 0.64624459, time/batch = 0.0526s\n",
            "61968/63080 (epoch 9.824), train_loss = 0.64398491, time/batch = 0.0526s\n",
            "61969/63080 (epoch 9.824), train_loss = 0.63240391, time/batch = 0.0517s\n",
            "61970/63080 (epoch 9.824), train_loss = 0.65036052, time/batch = 0.0527s\n",
            "61971/63080 (epoch 9.824), train_loss = 0.63602227, time/batch = 0.0527s\n",
            "61972/63080 (epoch 9.824), train_loss = 0.66376644, time/batch = 0.0521s\n",
            "61973/63080 (epoch 9.825), train_loss = 0.67242324, time/batch = 0.0527s\n",
            "61974/63080 (epoch 9.825), train_loss = 0.63133472, time/batch = 0.0530s\n",
            "61975/63080 (epoch 9.825), train_loss = 0.66192079, time/batch = 0.0526s\n",
            "61976/63080 (epoch 9.825), train_loss = 0.66198945, time/batch = 0.0526s\n",
            "61977/63080 (epoch 9.825), train_loss = 0.64426839, time/batch = 0.0524s\n",
            "61978/63080 (epoch 9.825), train_loss = 0.66787857, time/batch = 0.0525s\n",
            "61979/63080 (epoch 9.825), train_loss = 0.66833472, time/batch = 0.0533s\n",
            "61980/63080 (epoch 9.826), train_loss = 0.66365546, time/batch = 0.0533s\n",
            "61981/63080 (epoch 9.826), train_loss = 0.65496647, time/batch = 0.0523s\n",
            "61982/63080 (epoch 9.826), train_loss = 0.65101546, time/batch = 0.0522s\n",
            "61983/63080 (epoch 9.826), train_loss = 0.64900541, time/batch = 0.0524s\n",
            "61984/63080 (epoch 9.826), train_loss = 0.67080909, time/batch = 0.0522s\n",
            "61985/63080 (epoch 9.826), train_loss = 0.64129502, time/batch = 0.0524s\n",
            "61986/63080 (epoch 9.827), train_loss = 0.65613270, time/batch = 0.0528s\n",
            "61987/63080 (epoch 9.827), train_loss = 0.63092160, time/batch = 0.0527s\n",
            "61988/63080 (epoch 9.827), train_loss = 0.62719518, time/batch = 0.0529s\n",
            "61989/63080 (epoch 9.827), train_loss = 0.66355205, time/batch = 0.0523s\n",
            "61990/63080 (epoch 9.827), train_loss = 0.63727450, time/batch = 0.0536s\n",
            "61991/63080 (epoch 9.827), train_loss = 0.61855584, time/batch = 0.0527s\n",
            "61992/63080 (epoch 9.828), train_loss = 0.65916473, time/batch = 0.0522s\n",
            "61993/63080 (epoch 9.828), train_loss = 0.64504510, time/batch = 0.0528s\n",
            "61994/63080 (epoch 9.828), train_loss = 0.65122026, time/batch = 0.0526s\n",
            "61995/63080 (epoch 9.828), train_loss = 0.66854107, time/batch = 0.0534s\n",
            "61996/63080 (epoch 9.828), train_loss = 0.64872342, time/batch = 0.0525s\n",
            "61997/63080 (epoch 9.828), train_loss = 0.65695173, time/batch = 0.0523s\n",
            "61998/63080 (epoch 9.828), train_loss = 0.66427529, time/batch = 0.0527s\n",
            "61999/63080 (epoch 9.829), train_loss = 0.67753404, time/batch = 0.0527s\n",
            "evaluating loss over split index 1\n",
            "1/333...\n",
            "2/333...\n",
            "3/333...\n",
            "4/333...\n",
            "5/333...\n",
            "6/333...\n",
            "7/333...\n",
            "8/333...\n",
            "9/333...\n",
            "10/333...\n",
            "11/333...\n",
            "12/333...\n",
            "13/333...\n",
            "14/333...\n",
            "15/333...\n",
            "16/333...\n",
            "17/333...\n",
            "18/333...\n",
            "19/333...\n",
            "20/333...\n",
            "21/333...\n",
            "22/333...\n",
            "23/333...\n",
            "24/333...\n",
            "25/333...\n",
            "26/333...\n",
            "27/333...\n",
            "28/333...\n",
            "29/333...\n",
            "30/333...\n",
            "31/333...\n",
            "32/333...\n",
            "33/333...\n",
            "34/333...\n",
            "35/333...\n",
            "36/333...\n",
            "37/333...\n",
            "38/333...\n",
            "39/333...\n",
            "40/333...\n",
            "41/333...\n",
            "42/333...\n",
            "43/333...\n",
            "44/333...\n",
            "45/333...\n",
            "46/333...\n",
            "47/333...\n",
            "48/333...\n",
            "49/333...\n",
            "50/333...\n",
            "51/333...\n",
            "52/333...\n",
            "53/333...\n",
            "54/333...\n",
            "55/333...\n",
            "56/333...\n",
            "57/333...\n",
            "58/333...\n",
            "59/333...\n",
            "60/333...\n",
            "61/333...\n",
            "62/333...\n",
            "63/333...\n",
            "64/333...\n",
            "65/333...\n",
            "66/333...\n",
            "67/333...\n",
            "68/333...\n",
            "69/333...\n",
            "70/333...\n",
            "71/333...\n",
            "72/333...\n",
            "73/333...\n",
            "74/333...\n",
            "75/333...\n",
            "76/333...\n",
            "77/333...\n",
            "78/333...\n",
            "79/333...\n",
            "80/333...\n",
            "81/333...\n",
            "82/333...\n",
            "83/333...\n",
            "84/333...\n",
            "85/333...\n",
            "86/333...\n",
            "87/333...\n",
            "88/333...\n",
            "89/333...\n",
            "90/333...\n",
            "91/333...\n",
            "92/333...\n",
            "93/333...\n",
            "94/333...\n",
            "95/333...\n",
            "96/333...\n",
            "97/333...\n",
            "98/333...\n",
            "99/333...\n",
            "100/333...\n",
            "101/333...\n",
            "102/333...\n",
            "103/333...\n",
            "104/333...\n",
            "105/333...\n",
            "106/333...\n",
            "107/333...\n",
            "108/333...\n",
            "109/333...\n",
            "110/333...\n",
            "111/333...\n",
            "112/333...\n",
            "113/333...\n",
            "114/333...\n",
            "115/333...\n",
            "116/333...\n",
            "117/333...\n",
            "118/333...\n",
            "119/333...\n",
            "120/333...\n",
            "121/333...\n",
            "122/333...\n",
            "123/333...\n",
            "124/333...\n",
            "125/333...\n",
            "126/333...\n",
            "127/333...\n",
            "128/333...\n",
            "129/333...\n",
            "130/333...\n",
            "131/333...\n",
            "132/333...\n",
            "133/333...\n",
            "134/333...\n",
            "135/333...\n",
            "136/333...\n",
            "137/333...\n",
            "138/333...\n",
            "139/333...\n",
            "140/333...\n",
            "141/333...\n",
            "142/333...\n",
            "143/333...\n",
            "144/333...\n",
            "145/333...\n",
            "146/333...\n",
            "147/333...\n",
            "148/333...\n",
            "149/333...\n",
            "150/333...\n",
            "151/333...\n",
            "152/333...\n",
            "153/333...\n",
            "154/333...\n",
            "155/333...\n",
            "156/333...\n",
            "157/333...\n",
            "158/333...\n",
            "159/333...\n",
            "160/333...\n",
            "161/333...\n",
            "162/333...\n",
            "163/333...\n",
            "164/333...\n",
            "165/333...\n",
            "166/333...\n",
            "167/333...\n",
            "168/333...\n",
            "169/333...\n",
            "170/333...\n",
            "171/333...\n",
            "172/333...\n",
            "173/333...\n",
            "174/333...\n",
            "175/333...\n",
            "176/333...\n",
            "177/333...\n",
            "178/333...\n",
            "179/333...\n",
            "180/333...\n",
            "181/333...\n",
            "182/333...\n",
            "183/333...\n",
            "184/333...\n",
            "185/333...\n",
            "186/333...\n",
            "187/333...\n",
            "188/333...\n",
            "189/333...\n",
            "190/333...\n",
            "191/333...\n",
            "192/333...\n",
            "193/333...\n",
            "194/333...\n",
            "195/333...\n",
            "196/333...\n",
            "197/333...\n",
            "198/333...\n",
            "199/333...\n",
            "200/333...\n",
            "201/333...\n",
            "202/333...\n",
            "203/333...\n",
            "204/333...\n",
            "205/333...\n",
            "206/333...\n",
            "207/333...\n",
            "208/333...\n",
            "209/333...\n",
            "210/333...\n",
            "211/333...\n",
            "212/333...\n",
            "213/333...\n",
            "214/333...\n",
            "215/333...\n",
            "216/333...\n",
            "217/333...\n",
            "218/333...\n",
            "219/333...\n",
            "220/333...\n",
            "221/333...\n",
            "222/333...\n",
            "223/333...\n",
            "224/333...\n",
            "225/333...\n",
            "226/333...\n",
            "227/333...\n",
            "228/333...\n",
            "229/333...\n",
            "230/333...\n",
            "231/333...\n",
            "232/333...\n",
            "233/333...\n",
            "234/333...\n",
            "235/333...\n",
            "236/333...\n",
            "237/333...\n",
            "238/333...\n",
            "239/333...\n",
            "240/333...\n",
            "241/333...\n",
            "242/333...\n",
            "243/333...\n",
            "244/333...\n",
            "245/333...\n",
            "246/333...\n",
            "247/333...\n",
            "248/333...\n",
            "249/333...\n",
            "250/333...\n",
            "251/333...\n",
            "252/333...\n",
            "253/333...\n",
            "254/333...\n",
            "255/333...\n",
            "256/333...\n",
            "257/333...\n",
            "258/333...\n",
            "259/333...\n",
            "260/333...\n",
            "261/333...\n",
            "262/333...\n",
            "263/333...\n",
            "264/333...\n",
            "265/333...\n",
            "266/333...\n",
            "267/333...\n",
            "268/333...\n",
            "269/333...\n",
            "270/333...\n",
            "271/333...\n",
            "272/333...\n",
            "273/333...\n",
            "274/333...\n",
            "275/333...\n",
            "276/333...\n",
            "277/333...\n",
            "278/333...\n",
            "279/333...\n",
            "280/333...\n",
            "281/333...\n",
            "282/333...\n",
            "283/333...\n",
            "284/333...\n",
            "285/333...\n",
            "286/333...\n",
            "287/333...\n",
            "288/333...\n",
            "289/333...\n",
            "290/333...\n",
            "291/333...\n",
            "292/333...\n",
            "293/333...\n",
            "294/333...\n",
            "295/333...\n",
            "296/333...\n",
            "297/333...\n",
            "298/333...\n",
            "299/333...\n",
            "300/333...\n",
            "301/333...\n",
            "302/333...\n",
            "303/333...\n",
            "304/333...\n",
            "305/333...\n",
            "306/333...\n",
            "307/333...\n",
            "308/333...\n",
            "309/333...\n",
            "310/333...\n",
            "311/333...\n",
            "312/333...\n",
            "313/333...\n",
            "314/333...\n",
            "315/333...\n",
            "316/333...\n",
            "317/333...\n",
            "318/333...\n",
            "319/333...\n",
            "320/333...\n",
            "321/333...\n",
            "322/333...\n",
            "323/333...\n",
            "324/333...\n",
            "325/333...\n",
            "326/333...\n",
            "327/333...\n",
            "328/333...\n",
            "329/333...\n",
            "330/333...\n",
            "331/333...\n",
            "332/333...\n",
            "333/333...\n",
            "saving checkpoint to /content/drive/MyDrive/Kontur_task/check/lm_lstm_epoch9.83_0.6093.pt\n",
            "62000/63080 (epoch 9.829), train_loss = 0.66347718, time/batch = 0.0528s\n",
            "62001/63080 (epoch 9.829), train_loss = 0.66062981, time/batch = 0.0594s\n",
            "62002/63080 (epoch 9.829), train_loss = 0.67227435, time/batch = 0.0583s\n",
            "62003/63080 (epoch 9.829), train_loss = 0.65688330, time/batch = 0.0573s\n",
            "62004/63080 (epoch 9.829), train_loss = 0.64398897, time/batch = 0.0542s\n",
            "62005/63080 (epoch 9.830), train_loss = 0.66487217, time/batch = 0.0536s\n",
            "62006/63080 (epoch 9.830), train_loss = 0.65914333, time/batch = 0.0526s\n",
            "62007/63080 (epoch 9.830), train_loss = 0.65099883, time/batch = 0.0519s\n",
            "62008/63080 (epoch 9.830), train_loss = 0.67794311, time/batch = 0.0526s\n",
            "62009/63080 (epoch 9.830), train_loss = 0.66911203, time/batch = 0.0524s\n",
            "62010/63080 (epoch 9.830), train_loss = 0.67678815, time/batch = 0.0526s\n",
            "62011/63080 (epoch 9.831), train_loss = 0.66651213, time/batch = 0.0524s\n",
            "62012/63080 (epoch 9.831), train_loss = 0.66741562, time/batch = 0.0522s\n",
            "62013/63080 (epoch 9.831), train_loss = 0.65109915, time/batch = 0.0530s\n",
            "62014/63080 (epoch 9.831), train_loss = 0.65216458, time/batch = 0.0520s\n",
            "62015/63080 (epoch 9.831), train_loss = 0.64011598, time/batch = 0.0541s\n",
            "62016/63080 (epoch 9.831), train_loss = 0.65743977, time/batch = 0.0518s\n",
            "62017/63080 (epoch 9.831), train_loss = 0.63632661, time/batch = 0.0520s\n",
            "62018/63080 (epoch 9.832), train_loss = 0.65468347, time/batch = 0.0521s\n",
            "62019/63080 (epoch 9.832), train_loss = 0.65313715, time/batch = 0.0524s\n",
            "62020/63080 (epoch 9.832), train_loss = 0.66516566, time/batch = 0.0519s\n",
            "62021/63080 (epoch 9.832), train_loss = 0.64468199, time/batch = 0.0526s\n",
            "62022/63080 (epoch 9.832), train_loss = 0.65607810, time/batch = 0.0518s\n",
            "62023/63080 (epoch 9.832), train_loss = 0.64024478, time/batch = 0.0521s\n",
            "62024/63080 (epoch 9.833), train_loss = 0.65157044, time/batch = 0.0512s\n",
            "62025/63080 (epoch 9.833), train_loss = 0.66683817, time/batch = 0.0519s\n",
            "62026/63080 (epoch 9.833), train_loss = 0.65760905, time/batch = 0.0521s\n",
            "62027/63080 (epoch 9.833), train_loss = 0.65632915, time/batch = 0.0523s\n",
            "62028/63080 (epoch 9.833), train_loss = 0.67183119, time/batch = 0.0517s\n",
            "62029/63080 (epoch 9.833), train_loss = 0.66401035, time/batch = 0.0524s\n",
            "62030/63080 (epoch 9.834), train_loss = 0.66916507, time/batch = 0.0514s\n",
            "62031/63080 (epoch 9.834), train_loss = 0.66747975, time/batch = 0.0525s\n",
            "62032/63080 (epoch 9.834), train_loss = 0.63964236, time/batch = 0.0520s\n",
            "62033/63080 (epoch 9.834), train_loss = 0.64874816, time/batch = 0.0520s\n",
            "62034/63080 (epoch 9.834), train_loss = 0.61774474, time/batch = 0.0518s\n",
            "62035/63080 (epoch 9.834), train_loss = 0.64662045, time/batch = 0.0522s\n",
            "62036/63080 (epoch 9.834), train_loss = 0.64825588, time/batch = 0.0519s\n",
            "62037/63080 (epoch 9.835), train_loss = 0.63485295, time/batch = 0.0522s\n",
            "62038/63080 (epoch 9.835), train_loss = 0.63494015, time/batch = 0.0526s\n",
            "62039/63080 (epoch 9.835), train_loss = 0.66891557, time/batch = 0.0521s\n",
            "62040/63080 (epoch 9.835), train_loss = 0.64343566, time/batch = 0.0521s\n",
            "62041/63080 (epoch 9.835), train_loss = 0.63832223, time/batch = 0.0523s\n",
            "62042/63080 (epoch 9.835), train_loss = 0.66340142, time/batch = 0.0520s\n",
            "62043/63080 (epoch 9.836), train_loss = 0.62419373, time/batch = 0.0525s\n",
            "62044/63080 (epoch 9.836), train_loss = 0.64124751, time/batch = 0.0524s\n",
            "62045/63080 (epoch 9.836), train_loss = 0.65115130, time/batch = 0.0517s\n",
            "62046/63080 (epoch 9.836), train_loss = 0.66377908, time/batch = 0.0521s\n",
            "62047/63080 (epoch 9.836), train_loss = 0.67532778, time/batch = 0.0519s\n",
            "62048/63080 (epoch 9.836), train_loss = 0.66483939, time/batch = 0.0522s\n",
            "62049/63080 (epoch 9.837), train_loss = 0.67085111, time/batch = 0.0521s\n",
            "62050/63080 (epoch 9.837), train_loss = 0.66618562, time/batch = 0.0521s\n",
            "62051/63080 (epoch 9.837), train_loss = 0.65664446, time/batch = 0.0517s\n",
            "62052/63080 (epoch 9.837), train_loss = 0.65245193, time/batch = 0.0521s\n",
            "62053/63080 (epoch 9.837), train_loss = 0.66245532, time/batch = 0.0525s\n",
            "62054/63080 (epoch 9.837), train_loss = 0.66586357, time/batch = 0.0521s\n",
            "62055/63080 (epoch 9.838), train_loss = 0.64774930, time/batch = 0.0522s\n",
            "62056/63080 (epoch 9.838), train_loss = 0.66664469, time/batch = 0.0520s\n",
            "62057/63080 (epoch 9.838), train_loss = 0.66591847, time/batch = 0.0520s\n",
            "62058/63080 (epoch 9.838), train_loss = 0.66254085, time/batch = 0.0529s\n",
            "62059/63080 (epoch 9.838), train_loss = 0.64698935, time/batch = 0.0523s\n",
            "62060/63080 (epoch 9.838), train_loss = 0.63333780, time/batch = 0.0518s\n",
            "62061/63080 (epoch 9.838), train_loss = 0.66458118, time/batch = 0.0522s\n",
            "62062/63080 (epoch 9.839), train_loss = 0.64517283, time/batch = 0.0523s\n",
            "62063/63080 (epoch 9.839), train_loss = 0.65440488, time/batch = 0.0525s\n",
            "62064/63080 (epoch 9.839), train_loss = 0.64929438, time/batch = 0.0521s\n",
            "62065/63080 (epoch 9.839), train_loss = 0.66561872, time/batch = 0.0519s\n",
            "62066/63080 (epoch 9.839), train_loss = 0.67948669, time/batch = 0.0518s\n",
            "62067/63080 (epoch 9.839), train_loss = 0.67202127, time/batch = 0.0521s\n",
            "62068/63080 (epoch 9.840), train_loss = 0.66772270, time/batch = 0.0524s\n",
            "62069/63080 (epoch 9.840), train_loss = 0.67146873, time/batch = 0.0520s\n",
            "62070/63080 (epoch 9.840), train_loss = 0.67321217, time/batch = 0.0522s\n",
            "62071/63080 (epoch 9.840), train_loss = 0.67642981, time/batch = 0.0519s\n",
            "62072/63080 (epoch 9.840), train_loss = 0.66414970, time/batch = 0.0519s\n",
            "62073/63080 (epoch 9.840), train_loss = 0.67289221, time/batch = 0.0519s\n",
            "62074/63080 (epoch 9.841), train_loss = 0.70495051, time/batch = 0.0527s\n",
            "62075/63080 (epoch 9.841), train_loss = 0.67266864, time/batch = 0.0518s\n",
            "62076/63080 (epoch 9.841), train_loss = 0.66040611, time/batch = 0.0522s\n",
            "62077/63080 (epoch 9.841), train_loss = 0.64916050, time/batch = 0.0525s\n",
            "62078/63080 (epoch 9.841), train_loss = 0.65191257, time/batch = 0.0520s\n",
            "62079/63080 (epoch 9.841), train_loss = 0.66129518, time/batch = 0.0542s\n",
            "62080/63080 (epoch 9.841), train_loss = 0.65598214, time/batch = 0.0517s\n",
            "62081/63080 (epoch 9.842), train_loss = 0.63328725, time/batch = 0.0526s\n",
            "62082/63080 (epoch 9.842), train_loss = 0.68081695, time/batch = 0.0519s\n",
            "62083/63080 (epoch 9.842), train_loss = 0.67287558, time/batch = 0.0524s\n",
            "62084/63080 (epoch 9.842), train_loss = 0.65956688, time/batch = 0.0520s\n",
            "62085/63080 (epoch 9.842), train_loss = 0.66340435, time/batch = 0.0525s\n",
            "62086/63080 (epoch 9.842), train_loss = 0.65577036, time/batch = 0.0523s\n",
            "62087/63080 (epoch 9.843), train_loss = 0.66108268, time/batch = 0.0520s\n",
            "62088/63080 (epoch 9.843), train_loss = 0.66205907, time/batch = 0.0520s\n",
            "62089/63080 (epoch 9.843), train_loss = 0.66070312, time/batch = 0.0519s\n",
            "62090/63080 (epoch 9.843), train_loss = 0.63878220, time/batch = 0.0515s\n",
            "62091/63080 (epoch 9.843), train_loss = 0.64589530, time/batch = 0.0509s\n",
            "62092/63080 (epoch 9.843), train_loss = 0.64272928, time/batch = 0.0520s\n",
            "62093/63080 (epoch 9.844), train_loss = 0.64978552, time/batch = 0.0521s\n",
            "62094/63080 (epoch 9.844), train_loss = 0.66031283, time/batch = 0.0521s\n",
            "62095/63080 (epoch 9.844), train_loss = 0.65467238, time/batch = 0.0523s\n",
            "62096/63080 (epoch 9.844), train_loss = 0.64075661, time/batch = 0.0522s\n",
            "62097/63080 (epoch 9.844), train_loss = 0.65579528, time/batch = 0.0523s\n",
            "62098/63080 (epoch 9.844), train_loss = 0.65654200, time/batch = 0.0522s\n",
            "62099/63080 (epoch 9.844), train_loss = 0.62852073, time/batch = 0.0521s\n",
            "62100/63080 (epoch 9.845), train_loss = 0.63546365, time/batch = 0.0523s\n",
            "62101/63080 (epoch 9.845), train_loss = 0.65105116, time/batch = 0.0526s\n",
            "62102/63080 (epoch 9.845), train_loss = 0.62494379, time/batch = 0.0520s\n",
            "62103/63080 (epoch 9.845), train_loss = 0.63727200, time/batch = 0.0521s\n",
            "62104/63080 (epoch 9.845), train_loss = 0.64412081, time/batch = 0.0548s\n",
            "62105/63080 (epoch 9.845), train_loss = 0.64356893, time/batch = 0.0525s\n",
            "62106/63080 (epoch 9.846), train_loss = 0.66248333, time/batch = 0.0526s\n",
            "62107/63080 (epoch 9.846), train_loss = 0.65513039, time/batch = 0.0522s\n",
            "62108/63080 (epoch 9.846), train_loss = 0.66649950, time/batch = 0.0521s\n",
            "62109/63080 (epoch 9.846), train_loss = 0.67561406, time/batch = 0.0526s\n",
            "62110/63080 (epoch 9.846), train_loss = 0.64634657, time/batch = 0.0519s\n",
            "62111/63080 (epoch 9.846), train_loss = 0.65463257, time/batch = 0.0514s\n",
            "62112/63080 (epoch 9.847), train_loss = 0.66610432, time/batch = 0.0525s\n",
            "62113/63080 (epoch 9.847), train_loss = 0.66468370, time/batch = 0.0524s\n",
            "62114/63080 (epoch 9.847), train_loss = 0.66846776, time/batch = 0.0530s\n",
            "62115/63080 (epoch 9.847), train_loss = 0.67369533, time/batch = 0.0515s\n",
            "62116/63080 (epoch 9.847), train_loss = 0.64239311, time/batch = 0.0518s\n",
            "62117/63080 (epoch 9.847), train_loss = 0.62726676, time/batch = 0.0522s\n",
            "62118/63080 (epoch 9.847), train_loss = 0.65435416, time/batch = 0.0520s\n",
            "62119/63080 (epoch 9.848), train_loss = 0.67394006, time/batch = 0.0521s\n",
            "62120/63080 (epoch 9.848), train_loss = 0.67356360, time/batch = 0.0519s\n",
            "62121/63080 (epoch 9.848), train_loss = 0.64814723, time/batch = 0.0522s\n",
            "62122/63080 (epoch 9.848), train_loss = 0.66705805, time/batch = 0.0520s\n",
            "62123/63080 (epoch 9.848), train_loss = 0.65178543, time/batch = 0.0519s\n",
            "62124/63080 (epoch 9.848), train_loss = 0.65870869, time/batch = 0.0520s\n",
            "62125/63080 (epoch 9.849), train_loss = 0.65109867, time/batch = 0.0529s\n",
            "62126/63080 (epoch 9.849), train_loss = 0.64766806, time/batch = 0.0521s\n",
            "62127/63080 (epoch 9.849), train_loss = 0.65837061, time/batch = 0.0520s\n",
            "62128/63080 (epoch 9.849), train_loss = 0.64324445, time/batch = 0.0522s\n",
            "62129/63080 (epoch 9.849), train_loss = 0.66749656, time/batch = 0.0525s\n",
            "62130/63080 (epoch 9.849), train_loss = 0.65496147, time/batch = 0.0519s\n",
            "62131/63080 (epoch 9.850), train_loss = 0.65116709, time/batch = 0.0518s\n",
            "62132/63080 (epoch 9.850), train_loss = 0.67572635, time/batch = 0.0519s\n",
            "62133/63080 (epoch 9.850), train_loss = 0.65296203, time/batch = 0.0522s\n",
            "62134/63080 (epoch 9.850), train_loss = 0.66293001, time/batch = 0.0519s\n",
            "62135/63080 (epoch 9.850), train_loss = 0.66445071, time/batch = 0.0524s\n",
            "62136/63080 (epoch 9.850), train_loss = 0.68599772, time/batch = 0.0519s\n",
            "62137/63080 (epoch 9.851), train_loss = 0.68427527, time/batch = 0.0518s\n",
            "62138/63080 (epoch 9.851), train_loss = 0.67206979, time/batch = 0.0522s\n",
            "62139/63080 (epoch 9.851), train_loss = 0.68028116, time/batch = 0.0520s\n",
            "62140/63080 (epoch 9.851), train_loss = 0.66249359, time/batch = 0.0519s\n",
            "62141/63080 (epoch 9.851), train_loss = 0.64648521, time/batch = 0.0515s\n",
            "62142/63080 (epoch 9.851), train_loss = 0.66075629, time/batch = 0.0526s\n",
            "62143/63080 (epoch 9.851), train_loss = 0.68157566, time/batch = 0.0522s\n",
            "62144/63080 (epoch 9.852), train_loss = 0.67115241, time/batch = 0.0524s\n",
            "62145/63080 (epoch 9.852), train_loss = 0.65609539, time/batch = 0.0521s\n",
            "62146/63080 (epoch 9.852), train_loss = 0.64286280, time/batch = 0.0526s\n",
            "62147/63080 (epoch 9.852), train_loss = 0.65397596, time/batch = 0.0519s\n",
            "62148/63080 (epoch 9.852), train_loss = 0.62370831, time/batch = 0.0525s\n",
            "62149/63080 (epoch 9.852), train_loss = 0.65547878, time/batch = 0.0517s\n",
            "62150/63080 (epoch 9.853), train_loss = 0.65238613, time/batch = 0.0530s\n",
            "62151/63080 (epoch 9.853), train_loss = 0.64669687, time/batch = 0.0525s\n",
            "62152/63080 (epoch 9.853), train_loss = 0.64539433, time/batch = 0.0519s\n",
            "62153/63080 (epoch 9.853), train_loss = 0.65588850, time/batch = 0.0523s\n",
            "62154/63080 (epoch 9.853), train_loss = 0.66738164, time/batch = 0.0525s\n",
            "62155/63080 (epoch 9.853), train_loss = 0.66272360, time/batch = 0.0530s\n",
            "62156/63080 (epoch 9.854), train_loss = 0.64560556, time/batch = 0.0520s\n",
            "62157/63080 (epoch 9.854), train_loss = 0.63822061, time/batch = 0.0522s\n",
            "62158/63080 (epoch 9.854), train_loss = 0.65804154, time/batch = 0.0517s\n",
            "62159/63080 (epoch 9.854), train_loss = 0.65625161, time/batch = 0.0521s\n",
            "62160/63080 (epoch 9.854), train_loss = 0.65122199, time/batch = 0.0519s\n",
            "62161/63080 (epoch 9.854), train_loss = 0.66733891, time/batch = 0.0523s\n",
            "62162/63080 (epoch 9.854), train_loss = 0.62191391, time/batch = 0.0520s\n",
            "62163/63080 (epoch 9.855), train_loss = 0.67340422, time/batch = 0.0522s\n",
            "62164/63080 (epoch 9.855), train_loss = 0.67492360, time/batch = 0.0522s\n",
            "62165/63080 (epoch 9.855), train_loss = 0.67309004, time/batch = 0.0522s\n",
            "62166/63080 (epoch 9.855), train_loss = 0.66329521, time/batch = 0.0524s\n",
            "62167/63080 (epoch 9.855), train_loss = 0.65186787, time/batch = 0.0517s\n",
            "62168/63080 (epoch 9.855), train_loss = 0.69635934, time/batch = 0.0519s\n",
            "62169/63080 (epoch 9.856), train_loss = 0.67034692, time/batch = 0.0524s\n",
            "62170/63080 (epoch 9.856), train_loss = 0.66068113, time/batch = 0.0520s\n",
            "62171/63080 (epoch 9.856), train_loss = 0.67046648, time/batch = 0.0519s\n",
            "62172/63080 (epoch 9.856), train_loss = 0.69736439, time/batch = 0.0519s\n",
            "62173/63080 (epoch 9.856), train_loss = 0.64301670, time/batch = 0.0521s\n",
            "62174/63080 (epoch 9.856), train_loss = 0.68308967, time/batch = 0.0523s\n",
            "62175/63080 (epoch 9.857), train_loss = 0.65386719, time/batch = 0.0530s\n",
            "62176/63080 (epoch 9.857), train_loss = 0.64940041, time/batch = 0.0521s\n",
            "62177/63080 (epoch 9.857), train_loss = 0.66471171, time/batch = 0.0523s\n",
            "62178/63080 (epoch 9.857), train_loss = 0.66490501, time/batch = 0.0526s\n",
            "62179/63080 (epoch 9.857), train_loss = 0.65508467, time/batch = 0.0521s\n",
            "62180/63080 (epoch 9.857), train_loss = 0.67335778, time/batch = 0.0522s\n",
            "62181/63080 (epoch 9.857), train_loss = 0.65872276, time/batch = 0.0519s\n",
            "62182/63080 (epoch 9.858), train_loss = 0.66418880, time/batch = 0.0520s\n",
            "62183/63080 (epoch 9.858), train_loss = 0.66683275, time/batch = 0.0519s\n",
            "62184/63080 (epoch 9.858), train_loss = 0.65738094, time/batch = 0.0548s\n",
            "62185/63080 (epoch 9.858), train_loss = 0.64999104, time/batch = 0.0525s\n",
            "62186/63080 (epoch 9.858), train_loss = 0.63094950, time/batch = 0.0520s\n",
            "62187/63080 (epoch 9.858), train_loss = 0.64716858, time/batch = 0.0521s\n",
            "62188/63080 (epoch 9.859), train_loss = 0.63885480, time/batch = 0.0521s\n",
            "62189/63080 (epoch 9.859), train_loss = 0.65214145, time/batch = 0.0520s\n",
            "62190/63080 (epoch 9.859), train_loss = 0.64201194, time/batch = 0.0514s\n",
            "62191/63080 (epoch 9.859), train_loss = 0.64091492, time/batch = 0.0518s\n",
            "62192/63080 (epoch 9.859), train_loss = 0.64968050, time/batch = 0.0520s\n",
            "62193/63080 (epoch 9.859), train_loss = 0.65427166, time/batch = 0.0520s\n",
            "62194/63080 (epoch 9.860), train_loss = 0.67879152, time/batch = 0.0523s\n",
            "62195/63080 (epoch 9.860), train_loss = 0.67039114, time/batch = 0.0523s\n",
            "62196/63080 (epoch 9.860), train_loss = 0.65827215, time/batch = 0.0521s\n",
            "62197/63080 (epoch 9.860), train_loss = 0.65970182, time/batch = 0.0520s\n",
            "62198/63080 (epoch 9.860), train_loss = 0.62590456, time/batch = 0.0518s\n",
            "62199/63080 (epoch 9.860), train_loss = 0.65708852, time/batch = 0.0529s\n",
            "62200/63080 (epoch 9.860), train_loss = 0.64525968, time/batch = 0.0521s\n",
            "62201/63080 (epoch 9.861), train_loss = 0.66439497, time/batch = 0.0524s\n",
            "62202/63080 (epoch 9.861), train_loss = 0.66549987, time/batch = 0.0521s\n",
            "62203/63080 (epoch 9.861), train_loss = 0.64657074, time/batch = 0.0521s\n",
            "62204/63080 (epoch 9.861), train_loss = 0.67993188, time/batch = 0.0526s\n",
            "62205/63080 (epoch 9.861), train_loss = 0.66161400, time/batch = 0.0526s\n",
            "62206/63080 (epoch 9.861), train_loss = 0.64438748, time/batch = 0.0519s\n",
            "62207/63080 (epoch 9.862), train_loss = 0.64716518, time/batch = 0.0521s\n",
            "62208/63080 (epoch 9.862), train_loss = 0.65203714, time/batch = 0.0523s\n",
            "62209/63080 (epoch 9.862), train_loss = 0.65095091, time/batch = 0.0524s\n",
            "62210/63080 (epoch 9.862), train_loss = 0.66836494, time/batch = 0.0524s\n",
            "62211/63080 (epoch 9.862), train_loss = 0.66048104, time/batch = 0.0522s\n",
            "62212/63080 (epoch 9.862), train_loss = 0.70967495, time/batch = 0.0525s\n",
            "62213/63080 (epoch 9.863), train_loss = 0.67353517, time/batch = 0.0526s\n",
            "62214/63080 (epoch 9.863), train_loss = 0.67275262, time/batch = 0.0512s\n",
            "62215/63080 (epoch 9.863), train_loss = 0.66093689, time/batch = 0.0520s\n",
            "62216/63080 (epoch 9.863), train_loss = 0.67959219, time/batch = 0.0523s\n",
            "62217/63080 (epoch 9.863), train_loss = 0.67077571, time/batch = 0.0516s\n",
            "62218/63080 (epoch 9.863), train_loss = 0.66179526, time/batch = 0.0520s\n",
            "62219/63080 (epoch 9.864), train_loss = 0.67261952, time/batch = 0.0515s\n",
            "62220/63080 (epoch 9.864), train_loss = 0.65501398, time/batch = 0.0519s\n",
            "62221/63080 (epoch 9.864), train_loss = 0.65855163, time/batch = 0.0520s\n",
            "62222/63080 (epoch 9.864), train_loss = 0.66176480, time/batch = 0.0526s\n",
            "62223/63080 (epoch 9.864), train_loss = 0.65016878, time/batch = 0.0520s\n",
            "62224/63080 (epoch 9.864), train_loss = 0.64362371, time/batch = 0.0523s\n",
            "62225/63080 (epoch 9.864), train_loss = 0.64626741, time/batch = 0.0525s\n",
            "62226/63080 (epoch 9.865), train_loss = 0.67412144, time/batch = 0.0520s\n",
            "62227/63080 (epoch 9.865), train_loss = 0.67143631, time/batch = 0.0514s\n",
            "62228/63080 (epoch 9.865), train_loss = 0.64231765, time/batch = 0.0518s\n",
            "62229/63080 (epoch 9.865), train_loss = 0.65300316, time/batch = 0.0521s\n",
            "62230/63080 (epoch 9.865), train_loss = 0.64658487, time/batch = 0.0524s\n",
            "62231/63080 (epoch 9.865), train_loss = 0.67252314, time/batch = 0.0518s\n",
            "62232/63080 (epoch 9.866), train_loss = 0.66388834, time/batch = 0.0523s\n",
            "62233/63080 (epoch 9.866), train_loss = 0.66671097, time/batch = 0.0518s\n",
            "62234/63080 (epoch 9.866), train_loss = 0.66726786, time/batch = 0.0524s\n",
            "62235/63080 (epoch 9.866), train_loss = 0.66333938, time/batch = 0.0517s\n",
            "62236/63080 (epoch 9.866), train_loss = 0.66314185, time/batch = 0.0529s\n",
            "62237/63080 (epoch 9.866), train_loss = 0.68621653, time/batch = 0.0527s\n",
            "62238/63080 (epoch 9.867), train_loss = 0.66705894, time/batch = 0.0520s\n",
            "62239/63080 (epoch 9.867), train_loss = 0.66702026, time/batch = 0.0525s\n",
            "62240/63080 (epoch 9.867), train_loss = 0.66270006, time/batch = 0.0520s\n",
            "62241/63080 (epoch 9.867), train_loss = 0.66296244, time/batch = 0.0519s\n",
            "62242/63080 (epoch 9.867), train_loss = 0.65158564, time/batch = 0.0533s\n",
            "62243/63080 (epoch 9.867), train_loss = 0.66667241, time/batch = 0.0522s\n",
            "62244/63080 (epoch 9.867), train_loss = 0.65925765, time/batch = 0.0521s\n",
            "62245/63080 (epoch 9.868), train_loss = 0.65356863, time/batch = 0.0524s\n",
            "62246/63080 (epoch 9.868), train_loss = 0.65869153, time/batch = 0.0520s\n",
            "62247/63080 (epoch 9.868), train_loss = 0.64061534, time/batch = 0.0521s\n",
            "62248/63080 (epoch 9.868), train_loss = 0.64670068, time/batch = 0.0515s\n",
            "62249/63080 (epoch 9.868), train_loss = 0.62873560, time/batch = 0.0521s\n",
            "62250/63080 (epoch 9.868), train_loss = 0.62408799, time/batch = 0.0519s\n",
            "62251/63080 (epoch 9.869), train_loss = 0.66300315, time/batch = 0.0527s\n",
            "62252/63080 (epoch 9.869), train_loss = 0.62770116, time/batch = 0.0517s\n",
            "62253/63080 (epoch 9.869), train_loss = 0.65056980, time/batch = 0.0524s\n",
            "62254/63080 (epoch 9.869), train_loss = 0.64288217, time/batch = 0.0521s\n",
            "62255/63080 (epoch 9.869), train_loss = 0.63924772, time/batch = 0.0525s\n",
            "62256/63080 (epoch 9.869), train_loss = 0.65447396, time/batch = 0.0528s\n",
            "62257/63080 (epoch 9.870), train_loss = 0.66788709, time/batch = 0.0524s\n",
            "62258/63080 (epoch 9.870), train_loss = 0.65087140, time/batch = 0.0520s\n",
            "62259/63080 (epoch 9.870), train_loss = 0.67377764, time/batch = 0.0522s\n",
            "62260/63080 (epoch 9.870), train_loss = 0.69148660, time/batch = 0.0517s\n",
            "62261/63080 (epoch 9.870), train_loss = 0.66414946, time/batch = 0.0521s\n",
            "62262/63080 (epoch 9.870), train_loss = 0.65851474, time/batch = 0.0523s\n",
            "62263/63080 (epoch 9.870), train_loss = 0.65778017, time/batch = 0.0528s\n",
            "62264/63080 (epoch 9.871), train_loss = 0.66042244, time/batch = 0.0521s\n",
            "62265/63080 (epoch 9.871), train_loss = 0.66311699, time/batch = 0.0522s\n",
            "62266/63080 (epoch 9.871), train_loss = 0.67980742, time/batch = 0.0527s\n",
            "62267/63080 (epoch 9.871), train_loss = 0.66646034, time/batch = 0.0521s\n",
            "62268/63080 (epoch 9.871), train_loss = 0.64496231, time/batch = 0.0511s\n",
            "62269/63080 (epoch 9.871), train_loss = 0.64789748, time/batch = 0.0520s\n",
            "62270/63080 (epoch 9.872), train_loss = 0.64793372, time/batch = 0.0530s\n",
            "62271/63080 (epoch 9.872), train_loss = 0.64455801, time/batch = 0.0519s\n",
            "62272/63080 (epoch 9.872), train_loss = 0.67856073, time/batch = 0.0521s\n",
            "62273/63080 (epoch 9.872), train_loss = 0.64282370, time/batch = 0.0525s\n",
            "62274/63080 (epoch 9.872), train_loss = 0.64748228, time/batch = 0.0520s\n",
            "62275/63080 (epoch 9.872), train_loss = 0.64381564, time/batch = 0.0526s\n",
            "62276/63080 (epoch 9.873), train_loss = 0.67020166, time/batch = 0.0521s\n",
            "62277/63080 (epoch 9.873), train_loss = 0.68045199, time/batch = 0.0522s\n",
            "62278/63080 (epoch 9.873), train_loss = 0.65074813, time/batch = 0.0518s\n",
            "62279/63080 (epoch 9.873), train_loss = 0.66838282, time/batch = 0.0522s\n",
            "62280/63080 (epoch 9.873), train_loss = 0.65878153, time/batch = 0.0520s\n",
            "62281/63080 (epoch 9.873), train_loss = 0.64803743, time/batch = 0.0518s\n",
            "62282/63080 (epoch 9.873), train_loss = 0.64274848, time/batch = 0.0522s\n",
            "62283/63080 (epoch 9.874), train_loss = 0.64569116, time/batch = 0.0519s\n",
            "62284/63080 (epoch 9.874), train_loss = 0.64681065, time/batch = 0.0521s\n",
            "62285/63080 (epoch 9.874), train_loss = 0.66521156, time/batch = 0.0520s\n",
            "62286/63080 (epoch 9.874), train_loss = 0.66853929, time/batch = 0.0521s\n",
            "62287/63080 (epoch 9.874), train_loss = 0.68790644, time/batch = 0.0543s\n",
            "62288/63080 (epoch 9.874), train_loss = 0.66498005, time/batch = 0.0518s\n",
            "62289/63080 (epoch 9.875), train_loss = 0.64353502, time/batch = 0.0527s\n",
            "62290/63080 (epoch 9.875), train_loss = 0.66637200, time/batch = 0.0518s\n",
            "62291/63080 (epoch 9.875), train_loss = 0.66622120, time/batch = 0.0518s\n",
            "62292/63080 (epoch 9.875), train_loss = 0.68463951, time/batch = 0.0519s\n",
            "62293/63080 (epoch 9.875), train_loss = 0.69684660, time/batch = 0.0522s\n",
            "62294/63080 (epoch 9.875), train_loss = 0.69223446, time/batch = 0.0520s\n",
            "62295/63080 (epoch 9.876), train_loss = 0.68180591, time/batch = 0.0523s\n",
            "62296/63080 (epoch 9.876), train_loss = 0.66167843, time/batch = 0.0522s\n",
            "62297/63080 (epoch 9.876), train_loss = 0.64594656, time/batch = 0.0524s\n",
            "62298/63080 (epoch 9.876), train_loss = 0.66405177, time/batch = 0.0518s\n",
            "62299/63080 (epoch 9.876), train_loss = 0.65833610, time/batch = 0.0519s\n",
            "62300/63080 (epoch 9.876), train_loss = 0.65641761, time/batch = 0.0520s\n",
            "62301/63080 (epoch 9.877), train_loss = 0.65306127, time/batch = 0.0516s\n",
            "62302/63080 (epoch 9.877), train_loss = 0.66187429, time/batch = 0.0527s\n",
            "62303/63080 (epoch 9.877), train_loss = 0.66466689, time/batch = 0.0522s\n",
            "62304/63080 (epoch 9.877), train_loss = 0.66620475, time/batch = 0.0520s\n",
            "62305/63080 (epoch 9.877), train_loss = 0.68500650, time/batch = 0.0518s\n",
            "62306/63080 (epoch 9.877), train_loss = 0.65138268, time/batch = 0.0524s\n",
            "62307/63080 (epoch 9.877), train_loss = 0.64720887, time/batch = 0.0520s\n",
            "62308/63080 (epoch 9.878), train_loss = 0.63982993, time/batch = 0.0521s\n",
            "62309/63080 (epoch 9.878), train_loss = 0.64516830, time/batch = 0.0521s\n",
            "62310/63080 (epoch 9.878), train_loss = 0.64270502, time/batch = 0.0521s\n",
            "62311/63080 (epoch 9.878), train_loss = 0.63497192, time/batch = 0.0521s\n",
            "62312/63080 (epoch 9.878), train_loss = 0.65112120, time/batch = 0.0521s\n",
            "62313/63080 (epoch 9.878), train_loss = 0.66682440, time/batch = 0.0522s\n",
            "62314/63080 (epoch 9.879), train_loss = 0.67868525, time/batch = 0.0522s\n",
            "62315/63080 (epoch 9.879), train_loss = 0.66845399, time/batch = 0.0519s\n",
            "62316/63080 (epoch 9.879), train_loss = 0.64557177, time/batch = 0.0522s\n",
            "62317/63080 (epoch 9.879), train_loss = 0.65367925, time/batch = 0.0523s\n",
            "62318/63080 (epoch 9.879), train_loss = 0.63066077, time/batch = 0.0523s\n",
            "62319/63080 (epoch 9.879), train_loss = 0.63378310, time/batch = 0.0520s\n",
            "62320/63080 (epoch 9.880), train_loss = 0.65658277, time/batch = 0.0521s\n",
            "62321/63080 (epoch 9.880), train_loss = 0.65227801, time/batch = 0.0521s\n",
            "62322/63080 (epoch 9.880), train_loss = 0.65964311, time/batch = 0.0524s\n",
            "62323/63080 (epoch 9.880), train_loss = 0.65969449, time/batch = 0.0521s\n",
            "62324/63080 (epoch 9.880), train_loss = 0.66204780, time/batch = 0.0526s\n",
            "62325/63080 (epoch 9.880), train_loss = 0.64779621, time/batch = 0.0521s\n",
            "62326/63080 (epoch 9.880), train_loss = 0.63377255, time/batch = 0.0519s\n",
            "62327/63080 (epoch 9.881), train_loss = 0.67067963, time/batch = 0.0518s\n",
            "62328/63080 (epoch 9.881), train_loss = 0.66098315, time/batch = 0.0521s\n",
            "62329/63080 (epoch 9.881), train_loss = 0.66859192, time/batch = 0.0521s\n",
            "62330/63080 (epoch 9.881), train_loss = 0.67192668, time/batch = 0.0523s\n",
            "62331/63080 (epoch 9.881), train_loss = 0.65436023, time/batch = 0.0520s\n",
            "62332/63080 (epoch 9.881), train_loss = 0.64834821, time/batch = 0.0521s\n",
            "62333/63080 (epoch 9.882), train_loss = 0.67502028, time/batch = 0.0524s\n",
            "62334/63080 (epoch 9.882), train_loss = 0.63896066, time/batch = 0.0524s\n",
            "62335/63080 (epoch 9.882), train_loss = 0.63989806, time/batch = 0.0539s\n",
            "62336/63080 (epoch 9.882), train_loss = 0.66240799, time/batch = 0.0520s\n",
            "62337/63080 (epoch 9.882), train_loss = 0.68567896, time/batch = 0.0529s\n",
            "62338/63080 (epoch 9.882), train_loss = 0.67710686, time/batch = 0.0521s\n",
            "62339/63080 (epoch 9.883), train_loss = 0.67736721, time/batch = 0.0521s\n",
            "62340/63080 (epoch 9.883), train_loss = 0.66833496, time/batch = 0.0525s\n",
            "62341/63080 (epoch 9.883), train_loss = 0.67419559, time/batch = 0.0528s\n",
            "62342/63080 (epoch 9.883), train_loss = 0.68856627, time/batch = 0.0520s\n",
            "62343/63080 (epoch 9.883), train_loss = 0.70885020, time/batch = 0.0519s\n",
            "62344/63080 (epoch 9.883), train_loss = 0.64482462, time/batch = 0.0526s\n",
            "62345/63080 (epoch 9.883), train_loss = 0.67501098, time/batch = 0.0524s\n",
            "62346/63080 (epoch 9.884), train_loss = 0.68208891, time/batch = 0.0533s\n",
            "62347/63080 (epoch 9.884), train_loss = 0.66244930, time/batch = 0.0515s\n",
            "62348/63080 (epoch 9.884), train_loss = 0.66812575, time/batch = 0.0519s\n",
            "62349/63080 (epoch 9.884), train_loss = 0.65446389, time/batch = 0.0519s\n",
            "62350/63080 (epoch 9.884), train_loss = 0.65091664, time/batch = 0.0520s\n",
            "62351/63080 (epoch 9.884), train_loss = 0.67313278, time/batch = 0.0521s\n",
            "62352/63080 (epoch 9.885), train_loss = 0.66495538, time/batch = 0.0521s\n",
            "62353/63080 (epoch 9.885), train_loss = 0.67009866, time/batch = 0.0520s\n",
            "62354/63080 (epoch 9.885), train_loss = 0.64541739, time/batch = 0.0522s\n",
            "62355/63080 (epoch 9.885), train_loss = 0.67402428, time/batch = 0.0522s\n",
            "62356/63080 (epoch 9.885), train_loss = 0.65141010, time/batch = 0.0529s\n",
            "62357/63080 (epoch 9.885), train_loss = 0.66968369, time/batch = 0.0520s\n",
            "62358/63080 (epoch 9.886), train_loss = 0.65932506, time/batch = 0.0524s\n",
            "62359/63080 (epoch 9.886), train_loss = 0.67165142, time/batch = 0.0521s\n",
            "62360/63080 (epoch 9.886), train_loss = 0.65157449, time/batch = 0.0521s\n",
            "62361/63080 (epoch 9.886), train_loss = 0.67382729, time/batch = 0.0537s\n",
            "62362/63080 (epoch 9.886), train_loss = 0.66790634, time/batch = 0.0520s\n",
            "62363/63080 (epoch 9.886), train_loss = 0.65449291, time/batch = 0.0518s\n",
            "62364/63080 (epoch 9.886), train_loss = 0.65598840, time/batch = 0.0521s\n",
            "62365/63080 (epoch 9.887), train_loss = 0.66721189, time/batch = 0.0524s\n",
            "62366/63080 (epoch 9.887), train_loss = 0.66936553, time/batch = 0.0521s\n",
            "62367/63080 (epoch 9.887), train_loss = 0.65618742, time/batch = 0.0519s\n",
            "62368/63080 (epoch 9.887), train_loss = 0.66017348, time/batch = 0.0523s\n",
            "62369/63080 (epoch 9.887), train_loss = 0.65554035, time/batch = 0.0521s\n",
            "62370/63080 (epoch 9.887), train_loss = 0.67942154, time/batch = 0.0521s\n",
            "62371/63080 (epoch 9.888), train_loss = 0.65859818, time/batch = 0.0524s\n",
            "62372/63080 (epoch 9.888), train_loss = 0.65540266, time/batch = 0.0524s\n",
            "62373/63080 (epoch 9.888), train_loss = 0.66358829, time/batch = 0.0518s\n",
            "62374/63080 (epoch 9.888), train_loss = 0.64147586, time/batch = 0.0523s\n",
            "62375/63080 (epoch 9.888), train_loss = 0.68664593, time/batch = 0.0521s\n",
            "62376/63080 (epoch 9.888), train_loss = 0.66068369, time/batch = 0.0524s\n",
            "62377/63080 (epoch 9.889), train_loss = 0.63643646, time/batch = 0.0518s\n",
            "62378/63080 (epoch 9.889), train_loss = 0.65947276, time/batch = 0.0518s\n",
            "62379/63080 (epoch 9.889), train_loss = 0.62489414, time/batch = 0.0517s\n",
            "62380/63080 (epoch 9.889), train_loss = 0.66936201, time/batch = 0.0536s\n",
            "62381/63080 (epoch 9.889), train_loss = 0.64446551, time/batch = 0.0520s\n",
            "62382/63080 (epoch 9.889), train_loss = 0.64653361, time/batch = 0.0520s\n",
            "62383/63080 (epoch 9.890), train_loss = 0.61337018, time/batch = 0.0524s\n",
            "62384/63080 (epoch 9.890), train_loss = 0.64866418, time/batch = 0.0521s\n",
            "62385/63080 (epoch 9.890), train_loss = 0.64634979, time/batch = 0.0521s\n",
            "62386/63080 (epoch 9.890), train_loss = 0.64834225, time/batch = 0.0508s\n",
            "62387/63080 (epoch 9.890), train_loss = 0.64113051, time/batch = 0.0522s\n",
            "62388/63080 (epoch 9.890), train_loss = 0.65386772, time/batch = 0.0522s\n",
            "62389/63080 (epoch 9.890), train_loss = 0.65222299, time/batch = 0.0519s\n",
            "62390/63080 (epoch 9.891), train_loss = 0.66629261, time/batch = 0.0520s\n",
            "62391/63080 (epoch 9.891), train_loss = 0.63510495, time/batch = 0.0520s\n",
            "62392/63080 (epoch 9.891), train_loss = 0.66182566, time/batch = 0.0518s\n",
            "62393/63080 (epoch 9.891), train_loss = 0.66629708, time/batch = 0.0522s\n",
            "62394/63080 (epoch 9.891), train_loss = 0.65246987, time/batch = 0.0522s\n",
            "62395/63080 (epoch 9.891), train_loss = 0.65326571, time/batch = 0.0525s\n",
            "62396/63080 (epoch 9.892), train_loss = 0.67574537, time/batch = 0.0520s\n",
            "62397/63080 (epoch 9.892), train_loss = 0.63650948, time/batch = 0.0524s\n",
            "62398/63080 (epoch 9.892), train_loss = 0.66557038, time/batch = 0.0518s\n",
            "62399/63080 (epoch 9.892), train_loss = 0.67092580, time/batch = 0.0520s\n",
            "62400/63080 (epoch 9.892), train_loss = 0.66907382, time/batch = 0.0523s\n",
            "62401/63080 (epoch 9.892), train_loss = 0.66463369, time/batch = 0.0523s\n",
            "62402/63080 (epoch 9.893), train_loss = 0.66962689, time/batch = 0.0531s\n",
            "62403/63080 (epoch 9.893), train_loss = 0.64915746, time/batch = 0.0521s\n",
            "62404/63080 (epoch 9.893), train_loss = 0.66127187, time/batch = 0.0519s\n",
            "62405/63080 (epoch 9.893), train_loss = 0.65416211, time/batch = 0.0525s\n",
            "62406/63080 (epoch 9.893), train_loss = 0.64375001, time/batch = 0.0533s\n",
            "62407/63080 (epoch 9.893), train_loss = 0.66369539, time/batch = 0.0520s\n",
            "62408/63080 (epoch 9.893), train_loss = 0.66435981, time/batch = 0.0520s\n",
            "62409/63080 (epoch 9.894), train_loss = 0.66079140, time/batch = 0.0521s\n",
            "62410/63080 (epoch 9.894), train_loss = 0.66634530, time/batch = 0.0518s\n",
            "62411/63080 (epoch 9.894), train_loss = 0.67493707, time/batch = 0.0517s\n",
            "62412/63080 (epoch 9.894), train_loss = 0.65436339, time/batch = 0.0521s\n",
            "62413/63080 (epoch 9.894), train_loss = 0.64557868, time/batch = 0.0523s\n",
            "62414/63080 (epoch 9.894), train_loss = 0.64805984, time/batch = 0.0522s\n",
            "62415/63080 (epoch 9.895), train_loss = 0.68211955, time/batch = 0.0519s\n",
            "62416/63080 (epoch 9.895), train_loss = 0.68681705, time/batch = 0.0524s\n",
            "62417/63080 (epoch 9.895), train_loss = 0.65280914, time/batch = 0.0523s\n",
            "62418/63080 (epoch 9.895), train_loss = 0.65118480, time/batch = 0.0518s\n",
            "62419/63080 (epoch 9.895), train_loss = 0.64758664, time/batch = 0.0520s\n",
            "62420/63080 (epoch 9.895), train_loss = 0.68027943, time/batch = 0.0519s\n",
            "62421/63080 (epoch 9.896), train_loss = 0.67429501, time/batch = 0.0524s\n",
            "62422/63080 (epoch 9.896), train_loss = 0.65884674, time/batch = 0.0516s\n",
            "62423/63080 (epoch 9.896), train_loss = 0.66201514, time/batch = 0.0524s\n",
            "62424/63080 (epoch 9.896), train_loss = 0.66049796, time/batch = 0.0523s\n",
            "62425/63080 (epoch 9.896), train_loss = 0.65958112, time/batch = 0.0525s\n",
            "62426/63080 (epoch 9.896), train_loss = 0.66946113, time/batch = 0.0536s\n",
            "62427/63080 (epoch 9.896), train_loss = 0.67278546, time/batch = 0.0523s\n",
            "62428/63080 (epoch 9.897), train_loss = 0.67266268, time/batch = 0.0522s\n",
            "62429/63080 (epoch 9.897), train_loss = 0.67720437, time/batch = 0.0522s\n",
            "62430/63080 (epoch 9.897), train_loss = 0.67983621, time/batch = 0.0522s\n",
            "62431/63080 (epoch 9.897), train_loss = 0.66973579, time/batch = 0.0520s\n",
            "62432/63080 (epoch 9.897), train_loss = 0.64419669, time/batch = 0.0520s\n",
            "62433/63080 (epoch 9.897), train_loss = 0.65871441, time/batch = 0.0519s\n",
            "62434/63080 (epoch 9.898), train_loss = 0.67079204, time/batch = 0.0522s\n",
            "62435/63080 (epoch 9.898), train_loss = 0.68535322, time/batch = 0.0520s\n",
            "62436/63080 (epoch 9.898), train_loss = 0.65368962, time/batch = 0.0527s\n",
            "62437/63080 (epoch 9.898), train_loss = 0.65885305, time/batch = 0.0522s\n",
            "62438/63080 (epoch 9.898), train_loss = 0.68798834, time/batch = 0.0524s\n",
            "62439/63080 (epoch 9.898), train_loss = 0.67197156, time/batch = 0.0520s\n",
            "62440/63080 (epoch 9.899), train_loss = 0.64624691, time/batch = 0.0519s\n",
            "62441/63080 (epoch 9.899), train_loss = 0.66321838, time/batch = 0.0530s\n",
            "62442/63080 (epoch 9.899), train_loss = 0.66558504, time/batch = 0.0520s\n",
            "62443/63080 (epoch 9.899), train_loss = 0.64981395, time/batch = 0.0519s\n",
            "62444/63080 (epoch 9.899), train_loss = 0.64163345, time/batch = 0.0519s\n",
            "62445/63080 (epoch 9.899), train_loss = 0.63953710, time/batch = 0.0525s\n",
            "62446/63080 (epoch 9.899), train_loss = 0.63819456, time/batch = 0.0516s\n",
            "62447/63080 (epoch 9.900), train_loss = 0.65341300, time/batch = 0.0521s\n",
            "62448/63080 (epoch 9.900), train_loss = 0.63954806, time/batch = 0.0521s\n",
            "62449/63080 (epoch 9.900), train_loss = 0.66433817, time/batch = 0.0521s\n",
            "62450/63080 (epoch 9.900), train_loss = 0.64044708, time/batch = 0.0519s\n",
            "62451/63080 (epoch 9.900), train_loss = 0.64723957, time/batch = 0.0519s\n",
            "62452/63080 (epoch 9.900), train_loss = 0.64864922, time/batch = 0.0519s\n",
            "62453/63080 (epoch 9.901), train_loss = 0.66829574, time/batch = 0.0526s\n",
            "62454/63080 (epoch 9.901), train_loss = 0.66892469, time/batch = 0.0519s\n",
            "62455/63080 (epoch 9.901), train_loss = 0.65826350, time/batch = 0.0517s\n",
            "62456/63080 (epoch 9.901), train_loss = 0.65856504, time/batch = 0.0518s\n",
            "62457/63080 (epoch 9.901), train_loss = 0.65887094, time/batch = 0.0519s\n",
            "62458/63080 (epoch 9.901), train_loss = 0.67170459, time/batch = 0.0519s\n",
            "62459/63080 (epoch 9.902), train_loss = 0.64908010, time/batch = 0.0519s\n",
            "62460/63080 (epoch 9.902), train_loss = 0.65753698, time/batch = 0.0522s\n",
            "62461/63080 (epoch 9.902), train_loss = 0.65086037, time/batch = 0.0522s\n",
            "62462/63080 (epoch 9.902), train_loss = 0.65073788, time/batch = 0.0525s\n",
            "62463/63080 (epoch 9.902), train_loss = 0.65872365, time/batch = 0.0524s\n",
            "62464/63080 (epoch 9.902), train_loss = 0.64291990, time/batch = 0.0523s\n",
            "62465/63080 (epoch 9.903), train_loss = 0.65363461, time/batch = 0.0521s\n",
            "62466/63080 (epoch 9.903), train_loss = 0.66820163, time/batch = 0.0518s\n",
            "62467/63080 (epoch 9.903), train_loss = 0.63511801, time/batch = 0.0523s\n",
            "62468/63080 (epoch 9.903), train_loss = 0.64589959, time/batch = 0.0520s\n",
            "62469/63080 (epoch 9.903), train_loss = 0.63496912, time/batch = 0.0533s\n",
            "62470/63080 (epoch 9.903), train_loss = 0.64136618, time/batch = 0.0522s\n",
            "62471/63080 (epoch 9.903), train_loss = 0.64598447, time/batch = 0.0525s\n",
            "62472/63080 (epoch 9.904), train_loss = 0.63999248, time/batch = 0.0521s\n",
            "62473/63080 (epoch 9.904), train_loss = 0.64586818, time/batch = 0.0520s\n",
            "62474/63080 (epoch 9.904), train_loss = 0.64496720, time/batch = 0.0520s\n",
            "62475/63080 (epoch 9.904), train_loss = 0.62459117, time/batch = 0.0517s\n",
            "62476/63080 (epoch 9.904), train_loss = 0.65401947, time/batch = 0.0517s\n",
            "62477/63080 (epoch 9.904), train_loss = 0.65047532, time/batch = 0.0521s\n",
            "62478/63080 (epoch 9.905), train_loss = 0.61090463, time/batch = 0.0519s\n",
            "62479/63080 (epoch 9.905), train_loss = 0.65954667, time/batch = 0.0524s\n",
            "62480/63080 (epoch 9.905), train_loss = 0.65923452, time/batch = 0.0518s\n",
            "62481/63080 (epoch 9.905), train_loss = 0.63280475, time/batch = 0.0518s\n",
            "62482/63080 (epoch 9.905), train_loss = 0.64909506, time/batch = 0.0511s\n",
            "62483/63080 (epoch 9.905), train_loss = 0.64575726, time/batch = 0.0520s\n",
            "62484/63080 (epoch 9.906), train_loss = 0.67128664, time/batch = 0.0531s\n",
            "62485/63080 (epoch 9.906), train_loss = 0.62557983, time/batch = 0.0525s\n",
            "62486/63080 (epoch 9.906), train_loss = 0.65399671, time/batch = 0.0521s\n",
            "62487/63080 (epoch 9.906), train_loss = 0.63816667, time/batch = 0.0520s\n",
            "62488/63080 (epoch 9.906), train_loss = 0.62450534, time/batch = 0.0523s\n",
            "62489/63080 (epoch 9.906), train_loss = 0.63994932, time/batch = 0.0525s\n",
            "62490/63080 (epoch 9.906), train_loss = 0.63068509, time/batch = 0.0531s\n",
            "62491/63080 (epoch 9.907), train_loss = 0.63881165, time/batch = 0.0519s\n",
            "62492/63080 (epoch 9.907), train_loss = 0.65181530, time/batch = 0.0521s\n",
            "62493/63080 (epoch 9.907), train_loss = 0.65043205, time/batch = 0.0518s\n",
            "62494/63080 (epoch 9.907), train_loss = 0.63592964, time/batch = 0.0523s\n",
            "62495/63080 (epoch 9.907), train_loss = 0.64132524, time/batch = 0.0513s\n",
            "62496/63080 (epoch 9.907), train_loss = 0.63794756, time/batch = 0.0523s\n",
            "62497/63080 (epoch 9.908), train_loss = 0.66777736, time/batch = 0.0519s\n",
            "62498/63080 (epoch 9.908), train_loss = 0.65761018, time/batch = 0.0521s\n",
            "62499/63080 (epoch 9.908), train_loss = 0.65462494, time/batch = 0.0517s\n",
            "62500/63080 (epoch 9.908), train_loss = 0.64293814, time/batch = 0.0520s\n",
            "62501/63080 (epoch 9.908), train_loss = 0.66705418, time/batch = 0.0523s\n",
            "62502/63080 (epoch 9.908), train_loss = 0.64033484, time/batch = 0.0519s\n",
            "62503/63080 (epoch 9.909), train_loss = 0.67612809, time/batch = 0.0520s\n",
            "62504/63080 (epoch 9.909), train_loss = 0.67343473, time/batch = 0.0533s\n",
            "62505/63080 (epoch 9.909), train_loss = 0.66520613, time/batch = 0.0522s\n",
            "62506/63080 (epoch 9.909), train_loss = 0.66798687, time/batch = 0.0520s\n",
            "62507/63080 (epoch 9.909), train_loss = 0.66533673, time/batch = 0.0521s\n",
            "62508/63080 (epoch 9.909), train_loss = 0.66592377, time/batch = 0.0521s\n",
            "62509/63080 (epoch 9.909), train_loss = 0.67479885, time/batch = 0.0523s\n",
            "62510/63080 (epoch 9.910), train_loss = 0.66108823, time/batch = 0.0519s\n",
            "62511/63080 (epoch 9.910), train_loss = 0.66973722, time/batch = 0.0525s\n",
            "62512/63080 (epoch 9.910), train_loss = 0.65126401, time/batch = 0.0520s\n",
            "62513/63080 (epoch 9.910), train_loss = 0.63676041, time/batch = 0.0522s\n",
            "62514/63080 (epoch 9.910), train_loss = 0.63417107, time/batch = 0.0519s\n",
            "62515/63080 (epoch 9.910), train_loss = 0.67448920, time/batch = 0.0520s\n",
            "62516/63080 (epoch 9.911), train_loss = 0.65644580, time/batch = 0.0521s\n",
            "62517/63080 (epoch 9.911), train_loss = 0.65782672, time/batch = 0.0521s\n",
            "62518/63080 (epoch 9.911), train_loss = 0.64598298, time/batch = 0.0524s\n",
            "62519/63080 (epoch 9.911), train_loss = 0.64635867, time/batch = 0.0521s\n",
            "62520/63080 (epoch 9.911), train_loss = 0.63649923, time/batch = 0.0518s\n",
            "62521/63080 (epoch 9.911), train_loss = 0.66079926, time/batch = 0.0527s\n",
            "62522/63080 (epoch 9.912), train_loss = 0.67477608, time/batch = 0.0518s\n",
            "62523/63080 (epoch 9.912), train_loss = 0.63835120, time/batch = 0.0524s\n",
            "62524/63080 (epoch 9.912), train_loss = 0.65324658, time/batch = 0.0520s\n",
            "62525/63080 (epoch 9.912), train_loss = 0.63599056, time/batch = 0.0521s\n",
            "62526/63080 (epoch 9.912), train_loss = 0.64998996, time/batch = 0.0521s\n",
            "62527/63080 (epoch 9.912), train_loss = 0.63907731, time/batch = 0.0525s\n",
            "62528/63080 (epoch 9.912), train_loss = 0.65577823, time/batch = 0.0522s\n",
            "62529/63080 (epoch 9.913), train_loss = 0.64614004, time/batch = 0.0522s\n",
            "62530/63080 (epoch 9.913), train_loss = 0.66051984, time/batch = 0.0526s\n",
            "62531/63080 (epoch 9.913), train_loss = 0.64322901, time/batch = 0.0520s\n",
            "62532/63080 (epoch 9.913), train_loss = 0.66304588, time/batch = 0.0520s\n",
            "62533/63080 (epoch 9.913), train_loss = 0.63245445, time/batch = 0.0519s\n",
            "62534/63080 (epoch 9.913), train_loss = 0.65286112, time/batch = 0.0522s\n",
            "62535/63080 (epoch 9.914), train_loss = 0.67501432, time/batch = 0.0518s\n",
            "62536/63080 (epoch 9.914), train_loss = 0.67512470, time/batch = 0.0520s\n",
            "62537/63080 (epoch 9.914), train_loss = 0.65728837, time/batch = 0.0520s\n",
            "62538/63080 (epoch 9.914), train_loss = 0.65881801, time/batch = 0.0522s\n",
            "62539/63080 (epoch 9.914), train_loss = 0.64231569, time/batch = 0.0522s\n",
            "62540/63080 (epoch 9.914), train_loss = 0.65271062, time/batch = 0.0518s\n",
            "62541/63080 (epoch 9.915), train_loss = 0.65799695, time/batch = 0.0520s\n",
            "62542/63080 (epoch 9.915), train_loss = 0.66312575, time/batch = 0.0520s\n",
            "62543/63080 (epoch 9.915), train_loss = 0.64927465, time/batch = 0.0518s\n",
            "62544/63080 (epoch 9.915), train_loss = 0.66917658, time/batch = 0.0536s\n",
            "62545/63080 (epoch 9.915), train_loss = 0.66775411, time/batch = 0.0523s\n",
            "62546/63080 (epoch 9.915), train_loss = 0.63153845, time/batch = 0.0519s\n",
            "62547/63080 (epoch 9.916), train_loss = 0.66202772, time/batch = 0.0524s\n",
            "62548/63080 (epoch 9.916), train_loss = 0.64215243, time/batch = 0.0522s\n",
            "62549/63080 (epoch 9.916), train_loss = 0.65174055, time/batch = 0.0518s\n",
            "62550/63080 (epoch 9.916), train_loss = 0.66856015, time/batch = 0.0535s\n",
            "62551/63080 (epoch 9.916), train_loss = 0.69959849, time/batch = 0.0522s\n",
            "62552/63080 (epoch 9.916), train_loss = 0.66884065, time/batch = 0.0522s\n",
            "62553/63080 (epoch 9.916), train_loss = 0.63993108, time/batch = 0.0520s\n",
            "62554/63080 (epoch 9.917), train_loss = 0.66496241, time/batch = 0.0530s\n",
            "62555/63080 (epoch 9.917), train_loss = 0.66301191, time/batch = 0.0521s\n",
            "62556/63080 (epoch 9.917), train_loss = 0.64825791, time/batch = 0.0516s\n",
            "62557/63080 (epoch 9.917), train_loss = 0.67246944, time/batch = 0.0519s\n",
            "62558/63080 (epoch 9.917), train_loss = 0.65758735, time/batch = 0.0522s\n",
            "62559/63080 (epoch 9.917), train_loss = 0.66743726, time/batch = 0.0525s\n",
            "62560/63080 (epoch 9.918), train_loss = 0.68515521, time/batch = 0.0520s\n",
            "62561/63080 (epoch 9.918), train_loss = 0.66540670, time/batch = 0.0521s\n",
            "62562/63080 (epoch 9.918), train_loss = 0.68795401, time/batch = 0.0522s\n",
            "62563/63080 (epoch 9.918), train_loss = 0.65222448, time/batch = 0.0520s\n",
            "62564/63080 (epoch 9.918), train_loss = 0.66274911, time/batch = 0.0528s\n",
            "62565/63080 (epoch 9.918), train_loss = 0.65964633, time/batch = 0.0530s\n",
            "62566/63080 (epoch 9.919), train_loss = 0.67072338, time/batch = 0.0519s\n",
            "62567/63080 (epoch 9.919), train_loss = 0.67102015, time/batch = 0.0516s\n",
            "62568/63080 (epoch 9.919), train_loss = 0.68054569, time/batch = 0.0523s\n",
            "62569/63080 (epoch 9.919), train_loss = 0.65409225, time/batch = 0.0528s\n",
            "62570/63080 (epoch 9.919), train_loss = 0.64858472, time/batch = 0.0519s\n",
            "62571/63080 (epoch 9.919), train_loss = 0.66243815, time/batch = 0.0530s\n",
            "62572/63080 (epoch 9.919), train_loss = 0.65930271, time/batch = 0.0517s\n",
            "62573/63080 (epoch 9.920), train_loss = 0.66767442, time/batch = 0.0523s\n",
            "62574/63080 (epoch 9.920), train_loss = 0.66707569, time/batch = 0.0520s\n",
            "62575/63080 (epoch 9.920), train_loss = 0.67157429, time/batch = 0.0527s\n",
            "62576/63080 (epoch 9.920), train_loss = 0.68529540, time/batch = 0.0519s\n",
            "62577/63080 (epoch 9.920), train_loss = 0.66952538, time/batch = 0.0522s\n",
            "62578/63080 (epoch 9.920), train_loss = 0.66110164, time/batch = 0.0523s\n",
            "62579/63080 (epoch 9.921), train_loss = 0.64501554, time/batch = 0.0520s\n",
            "62580/63080 (epoch 9.921), train_loss = 0.66279721, time/batch = 0.0522s\n",
            "62581/63080 (epoch 9.921), train_loss = 0.63413435, time/batch = 0.0519s\n",
            "62582/63080 (epoch 9.921), train_loss = 0.66135079, time/batch = 0.0519s\n",
            "62583/63080 (epoch 9.921), train_loss = 0.64045322, time/batch = 0.0527s\n",
            "62584/63080 (epoch 9.921), train_loss = 0.64350039, time/batch = 0.0525s\n",
            "62585/63080 (epoch 9.922), train_loss = 0.64324552, time/batch = 0.0521s\n",
            "62586/63080 (epoch 9.922), train_loss = 0.65125763, time/batch = 0.0524s\n",
            "62587/63080 (epoch 9.922), train_loss = 0.63986772, time/batch = 0.0517s\n",
            "62588/63080 (epoch 9.922), train_loss = 0.65296614, time/batch = 0.0521s\n",
            "62589/63080 (epoch 9.922), train_loss = 0.66091055, time/batch = 0.0526s\n",
            "62590/63080 (epoch 9.922), train_loss = 0.66310632, time/batch = 0.0522s\n",
            "62591/63080 (epoch 9.922), train_loss = 0.64484382, time/batch = 0.0520s\n",
            "62592/63080 (epoch 9.923), train_loss = 0.66411012, time/batch = 0.0521s\n",
            "62593/63080 (epoch 9.923), train_loss = 0.63720959, time/batch = 0.0521s\n",
            "62594/63080 (epoch 9.923), train_loss = 0.63679880, time/batch = 0.0520s\n",
            "62595/63080 (epoch 9.923), train_loss = 0.64614350, time/batch = 0.0522s\n",
            "62596/63080 (epoch 9.923), train_loss = 0.67710131, time/batch = 0.0530s\n",
            "62597/63080 (epoch 9.923), train_loss = 0.66676009, time/batch = 0.0530s\n",
            "62598/63080 (epoch 9.924), train_loss = 0.65370876, time/batch = 0.0523s\n",
            "62599/63080 (epoch 9.924), train_loss = 0.63746196, time/batch = 0.0520s\n",
            "62600/63080 (epoch 9.924), train_loss = 0.66079658, time/batch = 0.0519s\n",
            "62601/63080 (epoch 9.924), train_loss = 0.69353473, time/batch = 0.0528s\n",
            "62602/63080 (epoch 9.924), train_loss = 0.66286659, time/batch = 0.0521s\n",
            "62603/63080 (epoch 9.924), train_loss = 0.69042534, time/batch = 0.0525s\n",
            "62604/63080 (epoch 9.925), train_loss = 0.65847105, time/batch = 0.0522s\n",
            "62605/63080 (epoch 9.925), train_loss = 0.65279144, time/batch = 0.0529s\n",
            "62606/63080 (epoch 9.925), train_loss = 0.63607460, time/batch = 0.0523s\n",
            "62607/63080 (epoch 9.925), train_loss = 0.63874155, time/batch = 0.0516s\n",
            "62608/63080 (epoch 9.925), train_loss = 0.62111264, time/batch = 0.0521s\n",
            "62609/63080 (epoch 9.925), train_loss = 0.65598398, time/batch = 0.0530s\n",
            "62610/63080 (epoch 9.925), train_loss = 0.66188771, time/batch = 0.0518s\n",
            "62611/63080 (epoch 9.926), train_loss = 0.64952344, time/batch = 0.0531s\n",
            "62612/63080 (epoch 9.926), train_loss = 0.64619344, time/batch = 0.0518s\n",
            "62613/63080 (epoch 9.926), train_loss = 0.65552044, time/batch = 0.0525s\n",
            "62614/63080 (epoch 9.926), train_loss = 0.62445563, time/batch = 0.0520s\n",
            "62615/63080 (epoch 9.926), train_loss = 0.64893818, time/batch = 0.0521s\n",
            "62616/63080 (epoch 9.926), train_loss = 0.64303857, time/batch = 0.0513s\n",
            "62617/63080 (epoch 9.927), train_loss = 0.66856855, time/batch = 0.0520s\n",
            "62618/63080 (epoch 9.927), train_loss = 0.66701001, time/batch = 0.0524s\n",
            "62619/63080 (epoch 9.927), train_loss = 0.65253788, time/batch = 0.0518s\n",
            "62620/63080 (epoch 9.927), train_loss = 0.66461033, time/batch = 0.0549s\n",
            "62621/63080 (epoch 9.927), train_loss = 0.67957366, time/batch = 0.0519s\n",
            "62622/63080 (epoch 9.927), train_loss = 0.65692121, time/batch = 0.0522s\n",
            "62623/63080 (epoch 9.928), train_loss = 0.64209205, time/batch = 0.0522s\n",
            "62624/63080 (epoch 9.928), train_loss = 0.64097321, time/batch = 0.0526s\n",
            "62625/63080 (epoch 9.928), train_loss = 0.65461737, time/batch = 0.0528s\n",
            "62626/63080 (epoch 9.928), train_loss = 0.64295059, time/batch = 0.0520s\n",
            "62627/63080 (epoch 9.928), train_loss = 0.64982450, time/batch = 0.0519s\n",
            "62628/63080 (epoch 9.928), train_loss = 0.66464078, time/batch = 0.0524s\n",
            "62629/63080 (epoch 9.929), train_loss = 0.67010510, time/batch = 0.0519s\n",
            "62630/63080 (epoch 9.929), train_loss = 0.66205835, time/batch = 0.0521s\n",
            "62631/63080 (epoch 9.929), train_loss = 0.67591166, time/batch = 0.0519s\n",
            "62632/63080 (epoch 9.929), train_loss = 0.64384925, time/batch = 0.0521s\n",
            "62633/63080 (epoch 9.929), train_loss = 0.65274113, time/batch = 0.0522s\n",
            "62634/63080 (epoch 9.929), train_loss = 0.66378367, time/batch = 0.0522s\n",
            "62635/63080 (epoch 9.929), train_loss = 0.65066075, time/batch = 0.0530s\n",
            "62636/63080 (epoch 9.930), train_loss = 0.66288000, time/batch = 0.0523s\n",
            "62637/63080 (epoch 9.930), train_loss = 0.66183716, time/batch = 0.0527s\n",
            "62638/63080 (epoch 9.930), train_loss = 0.65840203, time/batch = 0.0518s\n",
            "62639/63080 (epoch 9.930), train_loss = 0.65930939, time/batch = 0.0523s\n",
            "62640/63080 (epoch 9.930), train_loss = 0.65622461, time/batch = 0.0522s\n",
            "62641/63080 (epoch 9.930), train_loss = 0.64773309, time/batch = 0.0520s\n",
            "62642/63080 (epoch 9.931), train_loss = 0.65453726, time/batch = 0.0522s\n",
            "62643/63080 (epoch 9.931), train_loss = 0.64272225, time/batch = 0.0520s\n",
            "62644/63080 (epoch 9.931), train_loss = 0.64519191, time/batch = 0.0525s\n",
            "62645/63080 (epoch 9.931), train_loss = 0.63648373, time/batch = 0.0522s\n",
            "62646/63080 (epoch 9.931), train_loss = 0.64493424, time/batch = 0.0523s\n",
            "62647/63080 (epoch 9.931), train_loss = 0.64707083, time/batch = 0.0519s\n",
            "62648/63080 (epoch 9.932), train_loss = 0.64274508, time/batch = 0.0522s\n",
            "62649/63080 (epoch 9.932), train_loss = 0.64951771, time/batch = 0.0520s\n",
            "62650/63080 (epoch 9.932), train_loss = 0.66465449, time/batch = 0.0519s\n",
            "62651/63080 (epoch 9.932), train_loss = 0.65187019, time/batch = 0.0525s\n",
            "62652/63080 (epoch 9.932), train_loss = 0.67277890, time/batch = 0.0523s\n",
            "62653/63080 (epoch 9.932), train_loss = 0.63196075, time/batch = 0.0521s\n",
            "62654/63080 (epoch 9.932), train_loss = 0.65281731, time/batch = 0.0525s\n",
            "62655/63080 (epoch 9.933), train_loss = 0.66845477, time/batch = 0.0520s\n",
            "62656/63080 (epoch 9.933), train_loss = 0.64788884, time/batch = 0.0519s\n",
            "62657/63080 (epoch 9.933), train_loss = 0.64902651, time/batch = 0.0523s\n",
            "62658/63080 (epoch 9.933), train_loss = 0.66742355, time/batch = 0.0522s\n",
            "62659/63080 (epoch 9.933), train_loss = 0.64945740, time/batch = 0.0525s\n",
            "62660/63080 (epoch 9.933), train_loss = 0.64549559, time/batch = 0.0519s\n",
            "62661/63080 (epoch 9.934), train_loss = 0.62565458, time/batch = 0.0535s\n",
            "62662/63080 (epoch 9.934), train_loss = 0.63744456, time/batch = 0.0519s\n",
            "62663/63080 (epoch 9.934), train_loss = 0.66040313, time/batch = 0.0524s\n",
            "62664/63080 (epoch 9.934), train_loss = 0.66495693, time/batch = 0.0519s\n",
            "62665/63080 (epoch 9.934), train_loss = 0.62859344, time/batch = 0.0526s\n",
            "62666/63080 (epoch 9.934), train_loss = 0.65990007, time/batch = 0.0521s\n",
            "62667/63080 (epoch 9.935), train_loss = 0.66223711, time/batch = 0.0519s\n",
            "62668/63080 (epoch 9.935), train_loss = 0.64678621, time/batch = 0.0521s\n",
            "62669/63080 (epoch 9.935), train_loss = 0.63754874, time/batch = 0.0522s\n",
            "62670/63080 (epoch 9.935), train_loss = 0.65548766, time/batch = 0.0522s\n",
            "62671/63080 (epoch 9.935), train_loss = 0.64601940, time/batch = 0.0521s\n",
            "62672/63080 (epoch 9.935), train_loss = 0.64857626, time/batch = 0.0524s\n",
            "62673/63080 (epoch 9.935), train_loss = 0.65541393, time/batch = 0.0521s\n",
            "62674/63080 (epoch 9.936), train_loss = 0.64111573, time/batch = 0.0529s\n",
            "62675/63080 (epoch 9.936), train_loss = 0.64987886, time/batch = 0.0519s\n",
            "62676/63080 (epoch 9.936), train_loss = 0.64609081, time/batch = 0.0534s\n",
            "62677/63080 (epoch 9.936), train_loss = 0.65147126, time/batch = 0.0521s\n",
            "62678/63080 (epoch 9.936), train_loss = 0.62914574, time/batch = 0.0520s\n",
            "62679/63080 (epoch 9.936), train_loss = 0.66072655, time/batch = 0.0523s\n",
            "62680/63080 (epoch 9.937), train_loss = 0.63696212, time/batch = 0.0521s\n",
            "62681/63080 (epoch 9.937), train_loss = 0.64976507, time/batch = 0.0521s\n",
            "62682/63080 (epoch 9.937), train_loss = 0.62395263, time/batch = 0.0522s\n",
            "62683/63080 (epoch 9.937), train_loss = 0.61712313, time/batch = 0.0525s\n",
            "62684/63080 (epoch 9.937), train_loss = 0.62338042, time/batch = 0.0522s\n",
            "62685/63080 (epoch 9.937), train_loss = 0.66029054, time/batch = 0.0521s\n",
            "62686/63080 (epoch 9.938), train_loss = 0.64407355, time/batch = 0.0520s\n",
            "62687/63080 (epoch 9.938), train_loss = 0.64645803, time/batch = 0.0521s\n",
            "62688/63080 (epoch 9.938), train_loss = 0.65393025, time/batch = 0.0518s\n",
            "62689/63080 (epoch 9.938), train_loss = 0.65543914, time/batch = 0.0530s\n",
            "62690/63080 (epoch 9.938), train_loss = 0.67253667, time/batch = 0.0518s\n",
            "62691/63080 (epoch 9.938), train_loss = 0.64616883, time/batch = 0.0522s\n",
            "62692/63080 (epoch 9.938), train_loss = 0.66097593, time/batch = 0.0519s\n",
            "62693/63080 (epoch 9.939), train_loss = 0.65184295, time/batch = 0.0520s\n",
            "62694/63080 (epoch 9.939), train_loss = 0.64693093, time/batch = 0.0519s\n",
            "62695/63080 (epoch 9.939), train_loss = 0.65322781, time/batch = 0.0520s\n",
            "62696/63080 (epoch 9.939), train_loss = 0.65291756, time/batch = 0.0523s\n",
            "62697/63080 (epoch 9.939), train_loss = 0.66625333, time/batch = 0.0518s\n",
            "62698/63080 (epoch 9.939), train_loss = 0.68453616, time/batch = 0.0520s\n",
            "62699/63080 (epoch 9.940), train_loss = 0.64266020, time/batch = 0.0518s\n",
            "62700/63080 (epoch 9.940), train_loss = 0.64049590, time/batch = 0.0521s\n",
            "62701/63080 (epoch 9.940), train_loss = 0.69547850, time/batch = 0.0521s\n",
            "62702/63080 (epoch 9.940), train_loss = 0.66263610, time/batch = 0.0517s\n",
            "62703/63080 (epoch 9.940), train_loss = 0.66611230, time/batch = 0.0522s\n",
            "62704/63080 (epoch 9.940), train_loss = 0.64316487, time/batch = 0.0519s\n",
            "62705/63080 (epoch 9.941), train_loss = 0.64754421, time/batch = 0.0522s\n",
            "62706/63080 (epoch 9.941), train_loss = 0.65573752, time/batch = 0.0517s\n",
            "62707/63080 (epoch 9.941), train_loss = 0.65424496, time/batch = 0.0520s\n",
            "62708/63080 (epoch 9.941), train_loss = 0.64818758, time/batch = 0.0523s\n",
            "62709/63080 (epoch 9.941), train_loss = 0.64629275, time/batch = 0.0519s\n",
            "62710/63080 (epoch 9.941), train_loss = 0.63558584, time/batch = 0.0539s\n",
            "62711/63080 (epoch 9.942), train_loss = 0.66251189, time/batch = 0.0518s\n",
            "62712/63080 (epoch 9.942), train_loss = 0.65301949, time/batch = 0.0517s\n",
            "62713/63080 (epoch 9.942), train_loss = 0.67433327, time/batch = 0.0518s\n",
            "62714/63080 (epoch 9.942), train_loss = 0.67251688, time/batch = 0.0523s\n",
            "62715/63080 (epoch 9.942), train_loss = 0.66995829, time/batch = 0.0524s\n",
            "62716/63080 (epoch 9.942), train_loss = 0.63346249, time/batch = 0.0517s\n",
            "62717/63080 (epoch 9.942), train_loss = 0.67142379, time/batch = 0.0520s\n",
            "62718/63080 (epoch 9.943), train_loss = 0.65653402, time/batch = 0.0519s\n",
            "62719/63080 (epoch 9.943), train_loss = 0.64626223, time/batch = 0.0518s\n",
            "62720/63080 (epoch 9.943), train_loss = 0.66995883, time/batch = 0.0521s\n",
            "62721/63080 (epoch 9.943), train_loss = 0.67578483, time/batch = 0.0520s\n",
            "62722/63080 (epoch 9.943), train_loss = 0.64850944, time/batch = 0.0518s\n",
            "62723/63080 (epoch 9.943), train_loss = 0.67600548, time/batch = 0.0521s\n",
            "62724/63080 (epoch 9.944), train_loss = 0.64763033, time/batch = 0.0519s\n",
            "62725/63080 (epoch 9.944), train_loss = 0.66529381, time/batch = 0.0528s\n",
            "62726/63080 (epoch 9.944), train_loss = 0.68304491, time/batch = 0.0522s\n",
            "62727/63080 (epoch 9.944), train_loss = 0.65178055, time/batch = 0.0520s\n",
            "62728/63080 (epoch 9.944), train_loss = 0.63689244, time/batch = 0.0525s\n",
            "62729/63080 (epoch 9.944), train_loss = 0.69003224, time/batch = 0.0522s\n",
            "62730/63080 (epoch 9.945), train_loss = 0.66569573, time/batch = 0.0523s\n",
            "62731/63080 (epoch 9.945), train_loss = 0.67616034, time/batch = 0.0523s\n",
            "62732/63080 (epoch 9.945), train_loss = 0.69341338, time/batch = 0.0517s\n",
            "62733/63080 (epoch 9.945), train_loss = 0.66803503, time/batch = 0.0520s\n",
            "62734/63080 (epoch 9.945), train_loss = 0.67995101, time/batch = 0.0520s\n",
            "62735/63080 (epoch 9.945), train_loss = 0.65328318, time/batch = 0.0521s\n",
            "62736/63080 (epoch 9.945), train_loss = 0.66277075, time/batch = 0.0511s\n",
            "62737/63080 (epoch 9.946), train_loss = 0.67600930, time/batch = 0.0525s\n",
            "62738/63080 (epoch 9.946), train_loss = 0.65390754, time/batch = 0.0523s\n",
            "62739/63080 (epoch 9.946), train_loss = 0.67844713, time/batch = 0.0530s\n",
            "62740/63080 (epoch 9.946), train_loss = 0.65212107, time/batch = 0.0526s\n",
            "62741/63080 (epoch 9.946), train_loss = 0.66619539, time/batch = 0.0522s\n",
            "62742/63080 (epoch 9.946), train_loss = 0.68446088, time/batch = 0.0530s\n",
            "62743/63080 (epoch 9.947), train_loss = 0.69378257, time/batch = 0.0524s\n",
            "62744/63080 (epoch 9.947), train_loss = 0.66494238, time/batch = 0.0521s\n",
            "62745/63080 (epoch 9.947), train_loss = 0.66727871, time/batch = 0.0546s\n",
            "62746/63080 (epoch 9.947), train_loss = 0.65890628, time/batch = 0.0521s\n",
            "62747/63080 (epoch 9.947), train_loss = 0.67630088, time/batch = 0.0521s\n",
            "62748/63080 (epoch 9.947), train_loss = 0.67641687, time/batch = 0.0522s\n",
            "62749/63080 (epoch 9.948), train_loss = 0.69297564, time/batch = 0.0523s\n",
            "62750/63080 (epoch 9.948), train_loss = 0.67207330, time/batch = 0.0520s\n",
            "62751/63080 (epoch 9.948), train_loss = 0.68633634, time/batch = 0.0530s\n",
            "62752/63080 (epoch 9.948), train_loss = 0.67713320, time/batch = 0.0520s\n",
            "62753/63080 (epoch 9.948), train_loss = 0.67107946, time/batch = 0.0528s\n",
            "62754/63080 (epoch 9.948), train_loss = 0.67981023, time/batch = 0.0515s\n",
            "62755/63080 (epoch 9.948), train_loss = 0.70100820, time/batch = 0.0517s\n",
            "62756/63080 (epoch 9.949), train_loss = 0.69539362, time/batch = 0.0524s\n",
            "62757/63080 (epoch 9.949), train_loss = 0.65587139, time/batch = 0.0517s\n",
            "62758/63080 (epoch 9.949), train_loss = 0.68486816, time/batch = 0.0526s\n",
            "62759/63080 (epoch 9.949), train_loss = 0.64043397, time/batch = 0.0520s\n",
            "62760/63080 (epoch 9.949), train_loss = 0.66935265, time/batch = 0.0521s\n",
            "62761/63080 (epoch 9.949), train_loss = 0.67586905, time/batch = 0.0525s\n",
            "62762/63080 (epoch 9.950), train_loss = 0.68547201, time/batch = 0.0522s\n",
            "62763/63080 (epoch 9.950), train_loss = 0.65908855, time/batch = 0.0521s\n",
            "62764/63080 (epoch 9.950), train_loss = 0.66499084, time/batch = 0.0519s\n",
            "62765/63080 (epoch 9.950), train_loss = 0.66651624, time/batch = 0.0527s\n",
            "62766/63080 (epoch 9.950), train_loss = 0.63357031, time/batch = 0.0524s\n",
            "62767/63080 (epoch 9.950), train_loss = 0.67732984, time/batch = 0.0516s\n",
            "62768/63080 (epoch 9.951), train_loss = 0.66205609, time/batch = 0.0521s\n",
            "62769/63080 (epoch 9.951), train_loss = 0.65305394, time/batch = 0.0521s\n",
            "62770/63080 (epoch 9.951), train_loss = 0.66498965, time/batch = 0.0523s\n",
            "62771/63080 (epoch 9.951), train_loss = 0.65558118, time/batch = 0.0519s\n",
            "62772/63080 (epoch 9.951), train_loss = 0.67987072, time/batch = 0.0526s\n",
            "62773/63080 (epoch 9.951), train_loss = 0.64701879, time/batch = 0.0522s\n",
            "62774/63080 (epoch 9.951), train_loss = 0.64031869, time/batch = 0.0517s\n",
            "62775/63080 (epoch 9.952), train_loss = 0.67177093, time/batch = 0.0522s\n",
            "62776/63080 (epoch 9.952), train_loss = 0.62563831, time/batch = 0.0524s\n",
            "62777/63080 (epoch 9.952), train_loss = 0.65297967, time/batch = 0.0531s\n",
            "62778/63080 (epoch 9.952), train_loss = 0.64569461, time/batch = 0.0518s\n",
            "62779/63080 (epoch 9.952), train_loss = 0.66479236, time/batch = 0.0524s\n",
            "62780/63080 (epoch 9.952), train_loss = 0.64574337, time/batch = 0.0517s\n",
            "62781/63080 (epoch 9.953), train_loss = 0.65662891, time/batch = 0.0522s\n",
            "62782/63080 (epoch 9.953), train_loss = 0.63979751, time/batch = 0.0518s\n",
            "62783/63080 (epoch 9.953), train_loss = 0.66272396, time/batch = 0.0523s\n",
            "62784/63080 (epoch 9.953), train_loss = 0.65901285, time/batch = 0.0519s\n",
            "62785/63080 (epoch 9.953), train_loss = 0.65362501, time/batch = 0.0530s\n",
            "62786/63080 (epoch 9.953), train_loss = 0.65376818, time/batch = 0.0521s\n",
            "62787/63080 (epoch 9.954), train_loss = 0.66000611, time/batch = 0.0520s\n",
            "62788/63080 (epoch 9.954), train_loss = 0.66707313, time/batch = 0.0523s\n",
            "62789/63080 (epoch 9.954), train_loss = 0.69230187, time/batch = 0.0521s\n",
            "62790/63080 (epoch 9.954), train_loss = 0.68133909, time/batch = 0.0519s\n",
            "62791/63080 (epoch 9.954), train_loss = 0.67005986, time/batch = 0.0527s\n",
            "62792/63080 (epoch 9.954), train_loss = 0.63529176, time/batch = 0.0519s\n",
            "62793/63080 (epoch 9.955), train_loss = 0.64515889, time/batch = 0.0520s\n",
            "62794/63080 (epoch 9.955), train_loss = 0.66885251, time/batch = 0.0531s\n",
            "62795/63080 (epoch 9.955), train_loss = 0.65680933, time/batch = 0.0519s\n",
            "62796/63080 (epoch 9.955), train_loss = 0.64547479, time/batch = 0.0519s\n",
            "62797/63080 (epoch 9.955), train_loss = 0.66664040, time/batch = 0.0521s\n",
            "62798/63080 (epoch 9.955), train_loss = 0.65979123, time/batch = 0.0521s\n",
            "62799/63080 (epoch 9.955), train_loss = 0.64932042, time/batch = 0.0522s\n",
            "62800/63080 (epoch 9.956), train_loss = 0.63842070, time/batch = 0.0519s\n",
            "62801/63080 (epoch 9.956), train_loss = 0.66181374, time/batch = 0.0530s\n",
            "62802/63080 (epoch 9.956), train_loss = 0.67019778, time/batch = 0.0520s\n",
            "62803/63080 (epoch 9.956), train_loss = 0.67057347, time/batch = 0.0521s\n",
            "62804/63080 (epoch 9.956), train_loss = 0.66633421, time/batch = 0.0520s\n",
            "62805/63080 (epoch 9.956), train_loss = 0.64756751, time/batch = 0.0526s\n",
            "62806/63080 (epoch 9.957), train_loss = 0.65824062, time/batch = 0.0524s\n",
            "62807/63080 (epoch 9.957), train_loss = 0.65636814, time/batch = 0.0532s\n",
            "62808/63080 (epoch 9.957), train_loss = 0.64656156, time/batch = 0.0522s\n",
            "62809/63080 (epoch 9.957), train_loss = 0.65701288, time/batch = 0.0523s\n",
            "62810/63080 (epoch 9.957), train_loss = 0.65783554, time/batch = 0.0519s\n",
            "62811/63080 (epoch 9.957), train_loss = 0.66344315, time/batch = 0.0517s\n",
            "62812/63080 (epoch 9.958), train_loss = 0.67147285, time/batch = 0.0521s\n",
            "62813/63080 (epoch 9.958), train_loss = 0.65579128, time/batch = 0.0523s\n",
            "62814/63080 (epoch 9.958), train_loss = 0.66271383, time/batch = 0.0521s\n",
            "62815/63080 (epoch 9.958), train_loss = 0.66579372, time/batch = 0.0523s\n",
            "62816/63080 (epoch 9.958), train_loss = 0.67450994, time/batch = 0.0515s\n",
            "62817/63080 (epoch 9.958), train_loss = 0.65766883, time/batch = 0.0518s\n",
            "62818/63080 (epoch 9.958), train_loss = 0.65285623, time/batch = 0.0525s\n",
            "62819/63080 (epoch 9.959), train_loss = 0.66923642, time/batch = 0.0516s\n",
            "62820/63080 (epoch 9.959), train_loss = 0.66775846, time/batch = 0.0519s\n",
            "62821/63080 (epoch 9.959), train_loss = 0.67072397, time/batch = 0.0520s\n",
            "62822/63080 (epoch 9.959), train_loss = 0.66590458, time/batch = 0.0518s\n",
            "62823/63080 (epoch 9.959), train_loss = 0.64404088, time/batch = 0.0527s\n",
            "62824/63080 (epoch 9.959), train_loss = 0.70471108, time/batch = 0.0529s\n",
            "62825/63080 (epoch 9.960), train_loss = 0.68556345, time/batch = 0.0529s\n",
            "62826/63080 (epoch 9.960), train_loss = 0.66585010, time/batch = 0.0523s\n",
            "62827/63080 (epoch 9.960), train_loss = 0.67263353, time/batch = 0.0520s\n",
            "62828/63080 (epoch 9.960), train_loss = 0.66192371, time/batch = 0.0522s\n",
            "62829/63080 (epoch 9.960), train_loss = 0.66781461, time/batch = 0.0513s\n",
            "62830/63080 (epoch 9.960), train_loss = 0.65341979, time/batch = 0.0540s\n",
            "62831/63080 (epoch 9.961), train_loss = 0.66043216, time/batch = 0.0516s\n",
            "62832/63080 (epoch 9.961), train_loss = 0.64697629, time/batch = 0.0521s\n",
            "62833/63080 (epoch 9.961), train_loss = 0.64633095, time/batch = 0.0518s\n",
            "62834/63080 (epoch 9.961), train_loss = 0.63572288, time/batch = 0.0520s\n",
            "62835/63080 (epoch 9.961), train_loss = 0.67833263, time/batch = 0.0530s\n",
            "62836/63080 (epoch 9.961), train_loss = 0.63774014, time/batch = 0.0513s\n",
            "62837/63080 (epoch 9.961), train_loss = 0.65690005, time/batch = 0.0521s\n",
            "62838/63080 (epoch 9.962), train_loss = 0.64700383, time/batch = 0.0522s\n",
            "62839/63080 (epoch 9.962), train_loss = 0.65346277, time/batch = 0.0530s\n",
            "62840/63080 (epoch 9.962), train_loss = 0.64804190, time/batch = 0.0520s\n",
            "62841/63080 (epoch 9.962), train_loss = 0.67925990, time/batch = 0.0523s\n",
            "62842/63080 (epoch 9.962), train_loss = 0.65639466, time/batch = 0.0517s\n",
            "62843/63080 (epoch 9.962), train_loss = 0.67514133, time/batch = 0.0523s\n",
            "62844/63080 (epoch 9.963), train_loss = 0.67023331, time/batch = 0.0520s\n",
            "62845/63080 (epoch 9.963), train_loss = 0.67219460, time/batch = 0.0537s\n",
            "62846/63080 (epoch 9.963), train_loss = 0.68467176, time/batch = 0.0522s\n",
            "62847/63080 (epoch 9.963), train_loss = 0.65413052, time/batch = 0.0519s\n",
            "62848/63080 (epoch 9.963), train_loss = 0.64508289, time/batch = 0.0520s\n",
            "62849/63080 (epoch 9.963), train_loss = 0.68187547, time/batch = 0.0528s\n",
            "62850/63080 (epoch 9.964), train_loss = 0.66412199, time/batch = 0.0526s\n",
            "62851/63080 (epoch 9.964), train_loss = 0.64636308, time/batch = 0.0515s\n",
            "62852/63080 (epoch 9.964), train_loss = 0.69911838, time/batch = 0.0530s\n",
            "62853/63080 (epoch 9.964), train_loss = 0.65881735, time/batch = 0.0527s\n",
            "62854/63080 (epoch 9.964), train_loss = 0.68200421, time/batch = 0.0521s\n",
            "62855/63080 (epoch 9.964), train_loss = 0.68935221, time/batch = 0.0519s\n",
            "62856/63080 (epoch 9.964), train_loss = 0.65136302, time/batch = 0.0524s\n",
            "62857/63080 (epoch 9.965), train_loss = 0.66092670, time/batch = 0.0521s\n",
            "62858/63080 (epoch 9.965), train_loss = 0.66730601, time/batch = 0.0519s\n",
            "62859/63080 (epoch 9.965), train_loss = 0.68088871, time/batch = 0.0523s\n",
            "62860/63080 (epoch 9.965), train_loss = 0.66313225, time/batch = 0.0521s\n",
            "62861/63080 (epoch 9.965), train_loss = 0.67377812, time/batch = 0.0520s\n",
            "62862/63080 (epoch 9.965), train_loss = 0.65436202, time/batch = 0.0537s\n",
            "62863/63080 (epoch 9.966), train_loss = 0.67751223, time/batch = 0.0520s\n",
            "62864/63080 (epoch 9.966), train_loss = 0.69446528, time/batch = 0.0525s\n",
            "62865/63080 (epoch 9.966), train_loss = 0.66254616, time/batch = 0.0518s\n",
            "62866/63080 (epoch 9.966), train_loss = 0.67097658, time/batch = 0.0516s\n",
            "62867/63080 (epoch 9.966), train_loss = 0.66572565, time/batch = 0.0525s\n",
            "62868/63080 (epoch 9.966), train_loss = 0.65626591, time/batch = 0.0522s\n",
            "62869/63080 (epoch 9.967), train_loss = 0.64588124, time/batch = 0.0525s\n",
            "62870/63080 (epoch 9.967), train_loss = 0.66573709, time/batch = 0.0520s\n",
            "62871/63080 (epoch 9.967), train_loss = 0.67007113, time/batch = 0.0521s\n",
            "62872/63080 (epoch 9.967), train_loss = 0.66092205, time/batch = 0.0520s\n",
            "62873/63080 (epoch 9.967), train_loss = 0.66289824, time/batch = 0.0518s\n",
            "62874/63080 (epoch 9.967), train_loss = 0.67691875, time/batch = 0.0524s\n",
            "62875/63080 (epoch 9.968), train_loss = 0.67441517, time/batch = 0.0521s\n",
            "62876/63080 (epoch 9.968), train_loss = 0.65046775, time/batch = 0.0520s\n",
            "62877/63080 (epoch 9.968), train_loss = 0.66412586, time/batch = 0.0519s\n",
            "62878/63080 (epoch 9.968), train_loss = 0.66942728, time/batch = 0.0522s\n",
            "62879/63080 (epoch 9.968), train_loss = 0.67043346, time/batch = 0.0519s\n",
            "62880/63080 (epoch 9.968), train_loss = 0.64815611, time/batch = 0.0519s\n",
            "62881/63080 (epoch 9.968), train_loss = 0.66609800, time/batch = 0.0523s\n",
            "62882/63080 (epoch 9.969), train_loss = 0.66127127, time/batch = 0.0516s\n",
            "62883/63080 (epoch 9.969), train_loss = 0.66258645, time/batch = 0.0519s\n",
            "62884/63080 (epoch 9.969), train_loss = 0.64840245, time/batch = 0.0512s\n",
            "62885/63080 (epoch 9.969), train_loss = 0.64487225, time/batch = 0.0520s\n",
            "62886/63080 (epoch 9.969), train_loss = 0.65586448, time/batch = 0.0520s\n",
            "62887/63080 (epoch 9.969), train_loss = 0.67701536, time/batch = 0.0523s\n",
            "62888/63080 (epoch 9.970), train_loss = 0.66203541, time/batch = 0.0520s\n",
            "62889/63080 (epoch 9.970), train_loss = 0.66154712, time/batch = 0.0528s\n",
            "62890/63080 (epoch 9.970), train_loss = 0.67064720, time/batch = 0.0523s\n",
            "62891/63080 (epoch 9.970), train_loss = 0.65886140, time/batch = 0.0528s\n",
            "62892/63080 (epoch 9.970), train_loss = 0.64679039, time/batch = 0.0518s\n",
            "62893/63080 (epoch 9.970), train_loss = 0.68275845, time/batch = 0.0527s\n",
            "62894/63080 (epoch 9.971), train_loss = 0.67682868, time/batch = 0.0530s\n",
            "62895/63080 (epoch 9.971), train_loss = 0.68134129, time/batch = 0.0520s\n",
            "62896/63080 (epoch 9.971), train_loss = 0.63435727, time/batch = 0.0525s\n",
            "62897/63080 (epoch 9.971), train_loss = 0.66466683, time/batch = 0.0520s\n",
            "62898/63080 (epoch 9.971), train_loss = 0.68313402, time/batch = 0.0521s\n",
            "62899/63080 (epoch 9.971), train_loss = 0.66224211, time/batch = 0.0520s\n",
            "62900/63080 (epoch 9.971), train_loss = 0.64156210, time/batch = 0.0520s\n",
            "62901/63080 (epoch 9.972), train_loss = 0.65120995, time/batch = 0.0522s\n",
            "62902/63080 (epoch 9.972), train_loss = 0.66407073, time/batch = 0.0527s\n",
            "62903/63080 (epoch 9.972), train_loss = 0.67140591, time/batch = 0.0518s\n",
            "62904/63080 (epoch 9.972), train_loss = 0.67164940, time/batch = 0.0527s\n",
            "62905/63080 (epoch 9.972), train_loss = 0.66020989, time/batch = 0.0519s\n",
            "62906/63080 (epoch 9.972), train_loss = 0.67080206, time/batch = 0.0519s\n",
            "62907/63080 (epoch 9.973), train_loss = 0.65219951, time/batch = 0.0520s\n",
            "62908/63080 (epoch 9.973), train_loss = 0.70127106, time/batch = 0.0521s\n",
            "62909/63080 (epoch 9.973), train_loss = 0.64458400, time/batch = 0.0523s\n",
            "62910/63080 (epoch 9.973), train_loss = 0.65785581, time/batch = 0.0519s\n",
            "62911/63080 (epoch 9.973), train_loss = 0.66799963, time/batch = 0.0521s\n",
            "62912/63080 (epoch 9.973), train_loss = 0.67780083, time/batch = 0.0524s\n",
            "62913/63080 (epoch 9.974), train_loss = 0.65903920, time/batch = 0.0527s\n",
            "62914/63080 (epoch 9.974), train_loss = 0.67730248, time/batch = 0.0520s\n",
            "62915/63080 (epoch 9.974), train_loss = 0.65787303, time/batch = 0.0521s\n",
            "62916/63080 (epoch 9.974), train_loss = 0.66267061, time/batch = 0.0518s\n",
            "62917/63080 (epoch 9.974), train_loss = 0.67376065, time/batch = 0.0523s\n",
            "62918/63080 (epoch 9.974), train_loss = 0.66019088, time/batch = 0.0523s\n",
            "62919/63080 (epoch 9.974), train_loss = 0.64892495, time/batch = 0.0531s\n",
            "62920/63080 (epoch 9.975), train_loss = 0.66278213, time/batch = 0.0518s\n",
            "62921/63080 (epoch 9.975), train_loss = 0.63645709, time/batch = 0.0522s\n",
            "62922/63080 (epoch 9.975), train_loss = 0.62553263, time/batch = 0.0520s\n",
            "62923/63080 (epoch 9.975), train_loss = 0.64985967, time/batch = 0.0511s\n",
            "62924/63080 (epoch 9.975), train_loss = 0.65056831, time/batch = 0.0519s\n",
            "62925/63080 (epoch 9.975), train_loss = 0.65563470, time/batch = 0.0523s\n",
            "62926/63080 (epoch 9.976), train_loss = 0.67124671, time/batch = 0.0521s\n",
            "62927/63080 (epoch 9.976), train_loss = 0.65784806, time/batch = 0.0522s\n",
            "62928/63080 (epoch 9.976), train_loss = 0.67432314, time/batch = 0.0521s\n",
            "62929/63080 (epoch 9.976), train_loss = 0.65220618, time/batch = 0.0528s\n",
            "62930/63080 (epoch 9.976), train_loss = 0.65419304, time/batch = 0.0523s\n",
            "62931/63080 (epoch 9.976), train_loss = 0.64441043, time/batch = 0.0519s\n",
            "62932/63080 (epoch 9.977), train_loss = 0.65333891, time/batch = 0.0524s\n",
            "62933/63080 (epoch 9.977), train_loss = 0.67879295, time/batch = 0.0516s\n",
            "62934/63080 (epoch 9.977), train_loss = 0.67491603, time/batch = 0.0523s\n",
            "62935/63080 (epoch 9.977), train_loss = 0.66655958, time/batch = 0.0520s\n",
            "62936/63080 (epoch 9.977), train_loss = 0.67398047, time/batch = 0.0524s\n",
            "62937/63080 (epoch 9.977), train_loss = 0.66064334, time/batch = 0.0524s\n",
            "62938/63080 (epoch 9.977), train_loss = 0.66443819, time/batch = 0.0519s\n",
            "62939/63080 (epoch 9.978), train_loss = 0.66214567, time/batch = 0.0522s\n",
            "62940/63080 (epoch 9.978), train_loss = 0.64832526, time/batch = 0.0515s\n",
            "62941/63080 (epoch 9.978), train_loss = 0.62565356, time/batch = 0.0521s\n",
            "62942/63080 (epoch 9.978), train_loss = 0.65147203, time/batch = 0.0526s\n",
            "62943/63080 (epoch 9.978), train_loss = 0.66047341, time/batch = 0.0517s\n",
            "62944/63080 (epoch 9.978), train_loss = 0.66183931, time/batch = 0.0520s\n",
            "62945/63080 (epoch 9.979), train_loss = 0.65714979, time/batch = 0.0524s\n",
            "62946/63080 (epoch 9.979), train_loss = 0.64804411, time/batch = 0.0522s\n",
            "62947/63080 (epoch 9.979), train_loss = 0.63620818, time/batch = 0.0520s\n",
            "62948/63080 (epoch 9.979), train_loss = 0.66959500, time/batch = 0.0520s\n",
            "62949/63080 (epoch 9.979), train_loss = 0.67003500, time/batch = 0.0525s\n",
            "62950/63080 (epoch 9.979), train_loss = 0.66709387, time/batch = 0.0522s\n",
            "62951/63080 (epoch 9.980), train_loss = 0.67490184, time/batch = 0.0521s\n",
            "62952/63080 (epoch 9.980), train_loss = 0.67283225, time/batch = 0.0521s\n",
            "62953/63080 (epoch 9.980), train_loss = 0.67587394, time/batch = 0.0528s\n",
            "62954/63080 (epoch 9.980), train_loss = 0.67905521, time/batch = 0.0519s\n",
            "62955/63080 (epoch 9.980), train_loss = 0.68680966, time/batch = 0.0527s\n",
            "62956/63080 (epoch 9.980), train_loss = 0.65777928, time/batch = 0.0520s\n",
            "62957/63080 (epoch 9.981), train_loss = 0.64839756, time/batch = 0.0524s\n",
            "62958/63080 (epoch 9.981), train_loss = 0.64909500, time/batch = 0.0520s\n",
            "62959/63080 (epoch 9.981), train_loss = 0.64721954, time/batch = 0.0519s\n",
            "62960/63080 (epoch 9.981), train_loss = 0.66902465, time/batch = 0.0518s\n",
            "62961/63080 (epoch 9.981), train_loss = 0.66101521, time/batch = 0.0526s\n",
            "62962/63080 (epoch 9.981), train_loss = 0.68034637, time/batch = 0.0520s\n",
            "62963/63080 (epoch 9.981), train_loss = 0.67990047, time/batch = 0.0522s\n",
            "62964/63080 (epoch 9.982), train_loss = 0.67450047, time/batch = 0.0519s\n",
            "62965/63080 (epoch 9.982), train_loss = 0.67027110, time/batch = 0.0522s\n",
            "62966/63080 (epoch 9.982), train_loss = 0.66174114, time/batch = 0.0519s\n",
            "62967/63080 (epoch 9.982), train_loss = 0.67605627, time/batch = 0.0523s\n",
            "62968/63080 (epoch 9.982), train_loss = 0.66815013, time/batch = 0.0539s\n",
            "62969/63080 (epoch 9.982), train_loss = 0.67463720, time/batch = 0.0519s\n",
            "62970/63080 (epoch 9.983), train_loss = 0.66271311, time/batch = 0.0519s\n",
            "62971/63080 (epoch 9.983), train_loss = 0.65658307, time/batch = 0.0519s\n",
            "62972/63080 (epoch 9.983), train_loss = 0.68183798, time/batch = 0.0523s\n",
            "62973/63080 (epoch 9.983), train_loss = 0.64618683, time/batch = 0.0519s\n",
            "62974/63080 (epoch 9.983), train_loss = 0.64562923, time/batch = 0.0514s\n",
            "62975/63080 (epoch 9.983), train_loss = 0.65955317, time/batch = 0.0518s\n",
            "62976/63080 (epoch 9.984), train_loss = 0.67679828, time/batch = 0.0519s\n",
            "62977/63080 (epoch 9.984), train_loss = 0.66281825, time/batch = 0.0520s\n",
            "62978/63080 (epoch 9.984), train_loss = 0.66258168, time/batch = 0.0526s\n",
            "62979/63080 (epoch 9.984), train_loss = 0.67200124, time/batch = 0.0519s\n",
            "62980/63080 (epoch 9.984), train_loss = 0.65427798, time/batch = 0.0521s\n",
            "62981/63080 (epoch 9.984), train_loss = 0.66026896, time/batch = 0.0522s\n",
            "62982/63080 (epoch 9.984), train_loss = 0.66483402, time/batch = 0.0521s\n",
            "62983/63080 (epoch 9.985), train_loss = 0.66066790, time/batch = 0.0528s\n",
            "62984/63080 (epoch 9.985), train_loss = 0.69013131, time/batch = 0.0520s\n",
            "62985/63080 (epoch 9.985), train_loss = 0.67271221, time/batch = 0.0518s\n",
            "62986/63080 (epoch 9.985), train_loss = 0.66514862, time/batch = 0.0522s\n",
            "62987/63080 (epoch 9.985), train_loss = 0.69346470, time/batch = 0.0528s\n",
            "62988/63080 (epoch 9.985), train_loss = 0.66544515, time/batch = 0.0525s\n",
            "62989/63080 (epoch 9.986), train_loss = 0.67319191, time/batch = 0.0525s\n",
            "62990/63080 (epoch 9.986), train_loss = 0.68584466, time/batch = 0.0520s\n",
            "62991/63080 (epoch 9.986), train_loss = 0.67240220, time/batch = 0.0522s\n",
            "62992/63080 (epoch 9.986), train_loss = 0.67413861, time/batch = 0.0521s\n",
            "62993/63080 (epoch 9.986), train_loss = 0.65892512, time/batch = 0.0521s\n",
            "62994/63080 (epoch 9.986), train_loss = 0.67342609, time/batch = 0.0522s\n",
            "62995/63080 (epoch 9.987), train_loss = 0.65496284, time/batch = 0.0516s\n",
            "62996/63080 (epoch 9.987), train_loss = 0.66451192, time/batch = 0.0520s\n",
            "62997/63080 (epoch 9.987), train_loss = 0.64386058, time/batch = 0.0524s\n",
            "62998/63080 (epoch 9.987), train_loss = 0.66662616, time/batch = 0.0518s\n",
            "62999/63080 (epoch 9.987), train_loss = 0.67334008, time/batch = 0.0520s\n",
            "evaluating loss over split index 1\n",
            "1/333...\n",
            "2/333...\n",
            "3/333...\n",
            "4/333...\n",
            "5/333...\n",
            "6/333...\n",
            "7/333...\n",
            "8/333...\n",
            "9/333...\n",
            "10/333...\n",
            "11/333...\n",
            "12/333...\n",
            "13/333...\n",
            "14/333...\n",
            "15/333...\n",
            "16/333...\n",
            "17/333...\n",
            "18/333...\n",
            "19/333...\n",
            "20/333...\n",
            "21/333...\n",
            "22/333...\n",
            "23/333...\n",
            "24/333...\n",
            "25/333...\n",
            "26/333...\n",
            "27/333...\n",
            "28/333...\n",
            "29/333...\n",
            "30/333...\n",
            "31/333...\n",
            "32/333...\n",
            "33/333...\n",
            "34/333...\n",
            "35/333...\n",
            "36/333...\n",
            "37/333...\n",
            "38/333...\n",
            "39/333...\n",
            "40/333...\n",
            "41/333...\n",
            "42/333...\n",
            "43/333...\n",
            "44/333...\n",
            "45/333...\n",
            "46/333...\n",
            "47/333...\n",
            "48/333...\n",
            "49/333...\n",
            "50/333...\n",
            "51/333...\n",
            "52/333...\n",
            "53/333...\n",
            "54/333...\n",
            "55/333...\n",
            "56/333...\n",
            "57/333...\n",
            "58/333...\n",
            "59/333...\n",
            "60/333...\n",
            "61/333...\n",
            "62/333...\n",
            "63/333...\n",
            "64/333...\n",
            "65/333...\n",
            "66/333...\n",
            "67/333...\n",
            "68/333...\n",
            "69/333...\n",
            "70/333...\n",
            "71/333...\n",
            "72/333...\n",
            "73/333...\n",
            "74/333...\n",
            "75/333...\n",
            "76/333...\n",
            "77/333...\n",
            "78/333...\n",
            "79/333...\n",
            "80/333...\n",
            "81/333...\n",
            "82/333...\n",
            "83/333...\n",
            "84/333...\n",
            "85/333...\n",
            "86/333...\n",
            "87/333...\n",
            "88/333...\n",
            "89/333...\n",
            "90/333...\n",
            "91/333...\n",
            "92/333...\n",
            "93/333...\n",
            "94/333...\n",
            "95/333...\n",
            "96/333...\n",
            "97/333...\n",
            "98/333...\n",
            "99/333...\n",
            "100/333...\n",
            "101/333...\n",
            "102/333...\n",
            "103/333...\n",
            "104/333...\n",
            "105/333...\n",
            "106/333...\n",
            "107/333...\n",
            "108/333...\n",
            "109/333...\n",
            "110/333...\n",
            "111/333...\n",
            "112/333...\n",
            "113/333...\n",
            "114/333...\n",
            "115/333...\n",
            "116/333...\n",
            "117/333...\n",
            "118/333...\n",
            "119/333...\n",
            "120/333...\n",
            "121/333...\n",
            "122/333...\n",
            "123/333...\n",
            "124/333...\n",
            "125/333...\n",
            "126/333...\n",
            "127/333...\n",
            "128/333...\n",
            "129/333...\n",
            "130/333...\n",
            "131/333...\n",
            "132/333...\n",
            "133/333...\n",
            "134/333...\n",
            "135/333...\n",
            "136/333...\n",
            "137/333...\n",
            "138/333...\n",
            "139/333...\n",
            "140/333...\n",
            "141/333...\n",
            "142/333...\n",
            "143/333...\n",
            "144/333...\n",
            "145/333...\n",
            "146/333...\n",
            "147/333...\n",
            "148/333...\n",
            "149/333...\n",
            "150/333...\n",
            "151/333...\n",
            "152/333...\n",
            "153/333...\n",
            "154/333...\n",
            "155/333...\n",
            "156/333...\n",
            "157/333...\n",
            "158/333...\n",
            "159/333...\n",
            "160/333...\n",
            "161/333...\n",
            "162/333...\n",
            "163/333...\n",
            "164/333...\n",
            "165/333...\n",
            "166/333...\n",
            "167/333...\n",
            "168/333...\n",
            "169/333...\n",
            "170/333...\n",
            "171/333...\n",
            "172/333...\n",
            "173/333...\n",
            "174/333...\n",
            "175/333...\n",
            "176/333...\n",
            "177/333...\n",
            "178/333...\n",
            "179/333...\n",
            "180/333...\n",
            "181/333...\n",
            "182/333...\n",
            "183/333...\n",
            "184/333...\n",
            "185/333...\n",
            "186/333...\n",
            "187/333...\n",
            "188/333...\n",
            "189/333...\n",
            "190/333...\n",
            "191/333...\n",
            "192/333...\n",
            "193/333...\n",
            "194/333...\n",
            "195/333...\n",
            "196/333...\n",
            "197/333...\n",
            "198/333...\n",
            "199/333...\n",
            "200/333...\n",
            "201/333...\n",
            "202/333...\n",
            "203/333...\n",
            "204/333...\n",
            "205/333...\n",
            "206/333...\n",
            "207/333...\n",
            "208/333...\n",
            "209/333...\n",
            "210/333...\n",
            "211/333...\n",
            "212/333...\n",
            "213/333...\n",
            "214/333...\n",
            "215/333...\n",
            "216/333...\n",
            "217/333...\n",
            "218/333...\n",
            "219/333...\n",
            "220/333...\n",
            "221/333...\n",
            "222/333...\n",
            "223/333...\n",
            "224/333...\n",
            "225/333...\n",
            "226/333...\n",
            "227/333...\n",
            "228/333...\n",
            "229/333...\n",
            "230/333...\n",
            "231/333...\n",
            "232/333...\n",
            "233/333...\n",
            "234/333...\n",
            "235/333...\n",
            "236/333...\n",
            "237/333...\n",
            "238/333...\n",
            "239/333...\n",
            "240/333...\n",
            "241/333...\n",
            "242/333...\n",
            "243/333...\n",
            "244/333...\n",
            "245/333...\n",
            "246/333...\n",
            "247/333...\n",
            "248/333...\n",
            "249/333...\n",
            "250/333...\n",
            "251/333...\n",
            "252/333...\n",
            "253/333...\n",
            "254/333...\n",
            "255/333...\n",
            "256/333...\n",
            "257/333...\n",
            "258/333...\n",
            "259/333...\n",
            "260/333...\n",
            "261/333...\n",
            "262/333...\n",
            "263/333...\n",
            "264/333...\n",
            "265/333...\n",
            "266/333...\n",
            "267/333...\n",
            "268/333...\n",
            "269/333...\n",
            "270/333...\n",
            "271/333...\n",
            "272/333...\n",
            "273/333...\n",
            "274/333...\n",
            "275/333...\n",
            "276/333...\n",
            "277/333...\n",
            "278/333...\n",
            "279/333...\n",
            "280/333...\n",
            "281/333...\n",
            "282/333...\n",
            "283/333...\n",
            "284/333...\n",
            "285/333...\n",
            "286/333...\n",
            "287/333...\n",
            "288/333...\n",
            "289/333...\n",
            "290/333...\n",
            "291/333...\n",
            "292/333...\n",
            "293/333...\n",
            "294/333...\n",
            "295/333...\n",
            "296/333...\n",
            "297/333...\n",
            "298/333...\n",
            "299/333...\n",
            "300/333...\n",
            "301/333...\n",
            "302/333...\n",
            "303/333...\n",
            "304/333...\n",
            "305/333...\n",
            "306/333...\n",
            "307/333...\n",
            "308/333...\n",
            "309/333...\n",
            "310/333...\n",
            "311/333...\n",
            "312/333...\n",
            "313/333...\n",
            "314/333...\n",
            "315/333...\n",
            "316/333...\n",
            "317/333...\n",
            "318/333...\n",
            "319/333...\n",
            "320/333...\n",
            "321/333...\n",
            "322/333...\n",
            "323/333...\n",
            "324/333...\n",
            "325/333...\n",
            "326/333...\n",
            "327/333...\n",
            "328/333...\n",
            "329/333...\n",
            "330/333...\n",
            "331/333...\n",
            "332/333...\n",
            "333/333...\n",
            "saving checkpoint to /content/drive/MyDrive/Kontur_task/check/lm_lstm_epoch9.99_0.6066.pt\n",
            "63000/63080 (epoch 9.987), train_loss = 0.66791517, time/batch = 0.0521s\n",
            "63001/63080 (epoch 9.987), train_loss = 0.68473953, time/batch = 0.0600s\n",
            "63002/63080 (epoch 9.988), train_loss = 0.68380117, time/batch = 0.0595s\n",
            "63003/63080 (epoch 9.988), train_loss = 0.65727961, time/batch = 0.0577s\n",
            "63004/63080 (epoch 9.988), train_loss = 0.65229136, time/batch = 0.0569s\n",
            "63005/63080 (epoch 9.988), train_loss = 0.65682477, time/batch = 0.0543s\n",
            "63006/63080 (epoch 9.988), train_loss = 0.64353359, time/batch = 0.0543s\n",
            "63007/63080 (epoch 9.988), train_loss = 0.66338491, time/batch = 0.0527s\n",
            "63008/63080 (epoch 9.989), train_loss = 0.64795166, time/batch = 0.0527s\n",
            "63009/63080 (epoch 9.989), train_loss = 0.64926070, time/batch = 0.0521s\n",
            "63010/63080 (epoch 9.989), train_loss = 0.67970932, time/batch = 0.0529s\n",
            "63011/63080 (epoch 9.989), train_loss = 0.65446758, time/batch = 0.0528s\n",
            "63012/63080 (epoch 9.989), train_loss = 0.64285642, time/batch = 0.0524s\n",
            "63013/63080 (epoch 9.989), train_loss = 0.65438086, time/batch = 0.0523s\n",
            "63014/63080 (epoch 9.990), train_loss = 0.62501723, time/batch = 0.0530s\n",
            "63015/63080 (epoch 9.990), train_loss = 0.62868720, time/batch = 0.0525s\n",
            "63016/63080 (epoch 9.990), train_loss = 0.65950179, time/batch = 0.0532s\n",
            "63017/63080 (epoch 9.990), train_loss = 0.66141313, time/batch = 0.0527s\n",
            "63018/63080 (epoch 9.990), train_loss = 0.64317644, time/batch = 0.0526s\n",
            "63019/63080 (epoch 9.990), train_loss = 0.67552602, time/batch = 0.0524s\n",
            "63020/63080 (epoch 9.990), train_loss = 0.67161429, time/batch = 0.0525s\n",
            "63021/63080 (epoch 9.991), train_loss = 0.67614424, time/batch = 0.0526s\n",
            "63022/63080 (epoch 9.991), train_loss = 0.65398216, time/batch = 0.0513s\n",
            "63023/63080 (epoch 9.991), train_loss = 0.65175289, time/batch = 0.0525s\n",
            "63024/63080 (epoch 9.991), train_loss = 0.67921114, time/batch = 0.0528s\n",
            "63025/63080 (epoch 9.991), train_loss = 0.64355499, time/batch = 0.0523s\n",
            "63026/63080 (epoch 9.991), train_loss = 0.65240508, time/batch = 0.0536s\n",
            "63027/63080 (epoch 9.992), train_loss = 0.66282254, time/batch = 0.0522s\n",
            "63028/63080 (epoch 9.992), train_loss = 0.64658058, time/batch = 0.0527s\n",
            "63029/63080 (epoch 9.992), train_loss = 0.67017204, time/batch = 0.0524s\n",
            "63030/63080 (epoch 9.992), train_loss = 0.67549789, time/batch = 0.0530s\n",
            "63031/63080 (epoch 9.992), train_loss = 0.65849036, time/batch = 0.0532s\n",
            "63032/63080 (epoch 9.992), train_loss = 0.65335804, time/batch = 0.0523s\n",
            "63033/63080 (epoch 9.993), train_loss = 0.65566576, time/batch = 0.0526s\n",
            "63034/63080 (epoch 9.993), train_loss = 0.65117234, time/batch = 0.0523s\n",
            "63035/63080 (epoch 9.993), train_loss = 0.67455989, time/batch = 0.0538s\n",
            "63036/63080 (epoch 9.993), train_loss = 0.67695075, time/batch = 0.0531s\n",
            "63037/63080 (epoch 9.993), train_loss = 0.64379120, time/batch = 0.0526s\n",
            "63038/63080 (epoch 9.993), train_loss = 0.65283018, time/batch = 0.0526s\n",
            "63039/63080 (epoch 9.994), train_loss = 0.65868026, time/batch = 0.0525s\n",
            "63040/63080 (epoch 9.994), train_loss = 0.63818824, time/batch = 0.0527s\n",
            "63041/63080 (epoch 9.994), train_loss = 0.65484256, time/batch = 0.0525s\n",
            "63042/63080 (epoch 9.994), train_loss = 0.65264267, time/batch = 0.0522s\n",
            "63043/63080 (epoch 9.994), train_loss = 0.67373163, time/batch = 0.0533s\n",
            "63044/63080 (epoch 9.994), train_loss = 0.66953772, time/batch = 0.0522s\n",
            "63045/63080 (epoch 9.994), train_loss = 0.67518795, time/batch = 0.0527s\n",
            "63046/63080 (epoch 9.995), train_loss = 0.65922326, time/batch = 0.0522s\n",
            "63047/63080 (epoch 9.995), train_loss = 0.68547642, time/batch = 0.0521s\n",
            "63048/63080 (epoch 9.995), train_loss = 0.65690207, time/batch = 0.0524s\n",
            "63049/63080 (epoch 9.995), train_loss = 0.67017180, time/batch = 0.0538s\n",
            "63050/63080 (epoch 9.995), train_loss = 0.68954498, time/batch = 0.0524s\n",
            "63051/63080 (epoch 9.995), train_loss = 0.71192145, time/batch = 0.0524s\n",
            "63052/63080 (epoch 9.996), train_loss = 0.67324066, time/batch = 0.0523s\n",
            "63053/63080 (epoch 9.996), train_loss = 0.69307560, time/batch = 0.0525s\n",
            "63054/63080 (epoch 9.996), train_loss = 0.67899549, time/batch = 0.0525s\n",
            "63055/63080 (epoch 9.996), train_loss = 0.66074902, time/batch = 0.0524s\n",
            "63056/63080 (epoch 9.996), train_loss = 0.65644705, time/batch = 0.0531s\n",
            "63057/63080 (epoch 9.996), train_loss = 0.64766794, time/batch = 0.0521s\n",
            "63058/63080 (epoch 9.997), train_loss = 0.64191377, time/batch = 0.0524s\n",
            "63059/63080 (epoch 9.997), train_loss = 0.65935946, time/batch = 0.0523s\n",
            "63060/63080 (epoch 9.997), train_loss = 0.67339700, time/batch = 0.0520s\n",
            "63061/63080 (epoch 9.997), train_loss = 0.66239846, time/batch = 0.0517s\n",
            "63062/63080 (epoch 9.997), train_loss = 0.65315109, time/batch = 0.0525s\n",
            "63063/63080 (epoch 9.997), train_loss = 0.65083975, time/batch = 0.0521s\n",
            "63064/63080 (epoch 9.997), train_loss = 0.61584854, time/batch = 0.0524s\n",
            "63065/63080 (epoch 9.998), train_loss = 0.65263635, time/batch = 0.0524s\n",
            "63066/63080 (epoch 9.998), train_loss = 0.65248060, time/batch = 0.0523s\n",
            "63067/63080 (epoch 9.998), train_loss = 0.64701879, time/batch = 0.0523s\n",
            "63068/63080 (epoch 9.998), train_loss = 0.65807831, time/batch = 0.0523s\n",
            "63069/63080 (epoch 9.998), train_loss = 0.64776027, time/batch = 0.0521s\n",
            "63070/63080 (epoch 9.998), train_loss = 0.66712141, time/batch = 0.0519s\n",
            "63071/63080 (epoch 9.999), train_loss = 0.65345639, time/batch = 0.0520s\n",
            "63072/63080 (epoch 9.999), train_loss = 0.65473753, time/batch = 0.0524s\n",
            "63073/63080 (epoch 9.999), train_loss = 0.67286909, time/batch = 0.0526s\n",
            "63074/63080 (epoch 9.999), train_loss = 0.66387641, time/batch = 0.0532s\n",
            "63075/63080 (epoch 9.999), train_loss = 0.65238303, time/batch = 0.0541s\n",
            "63076/63080 (epoch 9.999), train_loss = 0.66317582, time/batch = 0.0533s\n",
            "63077/63080 (epoch 10.000), train_loss = 0.66420680, time/batch = 0.0521s\n",
            "63078/63080 (epoch 10.000), train_loss = 0.64615750, time/batch = 0.0525s\n",
            "63079/63080 (epoch 10.000), train_loss = 0.64262414, time/batch = 0.0524s\n",
            "decayed learning rate by a factor 0.97 to 0.0097\n",
            "evaluating loss over split index 1\n",
            "1/333...\n",
            "2/333...\n",
            "3/333...\n",
            "4/333...\n",
            "5/333...\n",
            "6/333...\n",
            "7/333...\n",
            "8/333...\n",
            "9/333...\n",
            "10/333...\n",
            "11/333...\n",
            "12/333...\n",
            "13/333...\n",
            "14/333...\n",
            "15/333...\n",
            "16/333...\n",
            "17/333...\n",
            "18/333...\n",
            "19/333...\n",
            "20/333...\n",
            "21/333...\n",
            "22/333...\n",
            "23/333...\n",
            "24/333...\n",
            "25/333...\n",
            "26/333...\n",
            "27/333...\n",
            "28/333...\n",
            "29/333...\n",
            "30/333...\n",
            "31/333...\n",
            "32/333...\n",
            "33/333...\n",
            "34/333...\n",
            "35/333...\n",
            "36/333...\n",
            "37/333...\n",
            "38/333...\n",
            "39/333...\n",
            "40/333...\n",
            "41/333...\n",
            "42/333...\n",
            "43/333...\n",
            "44/333...\n",
            "45/333...\n",
            "46/333...\n",
            "47/333...\n",
            "48/333...\n",
            "49/333...\n",
            "50/333...\n",
            "51/333...\n",
            "52/333...\n",
            "53/333...\n",
            "54/333...\n",
            "55/333...\n",
            "56/333...\n",
            "57/333...\n",
            "58/333...\n",
            "59/333...\n",
            "60/333...\n",
            "61/333...\n",
            "62/333...\n",
            "63/333...\n",
            "64/333...\n",
            "65/333...\n",
            "66/333...\n",
            "67/333...\n",
            "68/333...\n",
            "69/333...\n",
            "70/333...\n",
            "71/333...\n",
            "72/333...\n",
            "73/333...\n",
            "74/333...\n",
            "75/333...\n",
            "76/333...\n",
            "77/333...\n",
            "78/333...\n",
            "79/333...\n",
            "80/333...\n",
            "81/333...\n",
            "82/333...\n",
            "83/333...\n",
            "84/333...\n",
            "85/333...\n",
            "86/333...\n",
            "87/333...\n",
            "88/333...\n",
            "89/333...\n",
            "90/333...\n",
            "91/333...\n",
            "92/333...\n",
            "93/333...\n",
            "94/333...\n",
            "95/333...\n",
            "96/333...\n",
            "97/333...\n",
            "98/333...\n",
            "99/333...\n",
            "100/333...\n",
            "101/333...\n",
            "102/333...\n",
            "103/333...\n",
            "104/333...\n",
            "105/333...\n",
            "106/333...\n",
            "107/333...\n",
            "108/333...\n",
            "109/333...\n",
            "110/333...\n",
            "111/333...\n",
            "112/333...\n",
            "113/333...\n",
            "114/333...\n",
            "115/333...\n",
            "116/333...\n",
            "117/333...\n",
            "118/333...\n",
            "119/333...\n",
            "120/333...\n",
            "121/333...\n",
            "122/333...\n",
            "123/333...\n",
            "124/333...\n",
            "125/333...\n",
            "126/333...\n",
            "127/333...\n",
            "128/333...\n",
            "129/333...\n",
            "130/333...\n",
            "131/333...\n",
            "132/333...\n",
            "133/333...\n",
            "134/333...\n",
            "135/333...\n",
            "136/333...\n",
            "137/333...\n",
            "138/333...\n",
            "139/333...\n",
            "140/333...\n",
            "141/333...\n",
            "142/333...\n",
            "143/333...\n",
            "144/333...\n",
            "145/333...\n",
            "146/333...\n",
            "147/333...\n",
            "148/333...\n",
            "149/333...\n",
            "150/333...\n",
            "151/333...\n",
            "152/333...\n",
            "153/333...\n",
            "154/333...\n",
            "155/333...\n",
            "156/333...\n",
            "157/333...\n",
            "158/333...\n",
            "159/333...\n",
            "160/333...\n",
            "161/333...\n",
            "162/333...\n",
            "163/333...\n",
            "164/333...\n",
            "165/333...\n",
            "166/333...\n",
            "167/333...\n",
            "168/333...\n",
            "169/333...\n",
            "170/333...\n",
            "171/333...\n",
            "172/333...\n",
            "173/333...\n",
            "174/333...\n",
            "175/333...\n",
            "176/333...\n",
            "177/333...\n",
            "178/333...\n",
            "179/333...\n",
            "180/333...\n",
            "181/333...\n",
            "182/333...\n",
            "183/333...\n",
            "184/333...\n",
            "185/333...\n",
            "186/333...\n",
            "187/333...\n",
            "188/333...\n",
            "189/333...\n",
            "190/333...\n",
            "191/333...\n",
            "192/333...\n",
            "193/333...\n",
            "194/333...\n",
            "195/333...\n",
            "196/333...\n",
            "197/333...\n",
            "198/333...\n",
            "199/333...\n",
            "200/333...\n",
            "201/333...\n",
            "202/333...\n",
            "203/333...\n",
            "204/333...\n",
            "205/333...\n",
            "206/333...\n",
            "207/333...\n",
            "208/333...\n",
            "209/333...\n",
            "210/333...\n",
            "211/333...\n",
            "212/333...\n",
            "213/333...\n",
            "214/333...\n",
            "215/333...\n",
            "216/333...\n",
            "217/333...\n",
            "218/333...\n",
            "219/333...\n",
            "220/333...\n",
            "221/333...\n",
            "222/333...\n",
            "223/333...\n",
            "224/333...\n",
            "225/333...\n",
            "226/333...\n",
            "227/333...\n",
            "228/333...\n",
            "229/333...\n",
            "230/333...\n",
            "231/333...\n",
            "232/333...\n",
            "233/333...\n",
            "234/333...\n",
            "235/333...\n",
            "236/333...\n",
            "237/333...\n",
            "238/333...\n",
            "239/333...\n",
            "240/333...\n",
            "241/333...\n",
            "242/333...\n",
            "243/333...\n",
            "244/333...\n",
            "245/333...\n",
            "246/333...\n",
            "247/333...\n",
            "248/333...\n",
            "249/333...\n",
            "250/333...\n",
            "251/333...\n",
            "252/333...\n",
            "253/333...\n",
            "254/333...\n",
            "255/333...\n",
            "256/333...\n",
            "257/333...\n",
            "258/333...\n",
            "259/333...\n",
            "260/333...\n",
            "261/333...\n",
            "262/333...\n",
            "263/333...\n",
            "264/333...\n",
            "265/333...\n",
            "266/333...\n",
            "267/333...\n",
            "268/333...\n",
            "269/333...\n",
            "270/333...\n",
            "271/333...\n",
            "272/333...\n",
            "273/333...\n",
            "274/333...\n",
            "275/333...\n",
            "276/333...\n",
            "277/333...\n",
            "278/333...\n",
            "279/333...\n",
            "280/333...\n",
            "281/333...\n",
            "282/333...\n",
            "283/333...\n",
            "284/333...\n",
            "285/333...\n",
            "286/333...\n",
            "287/333...\n",
            "288/333...\n",
            "289/333...\n",
            "290/333...\n",
            "291/333...\n",
            "292/333...\n",
            "293/333...\n",
            "294/333...\n",
            "295/333...\n",
            "296/333...\n",
            "297/333...\n",
            "298/333...\n",
            "299/333...\n",
            "300/333...\n",
            "301/333...\n",
            "302/333...\n",
            "303/333...\n",
            "304/333...\n",
            "305/333...\n",
            "306/333...\n",
            "307/333...\n",
            "308/333...\n",
            "309/333...\n",
            "310/333...\n",
            "311/333...\n",
            "312/333...\n",
            "313/333...\n",
            "314/333...\n",
            "315/333...\n",
            "316/333...\n",
            "317/333...\n",
            "318/333...\n",
            "319/333...\n",
            "320/333...\n",
            "321/333...\n",
            "322/333...\n",
            "323/333...\n",
            "324/333...\n",
            "325/333...\n",
            "326/333...\n",
            "327/333...\n",
            "328/333...\n",
            "329/333...\n",
            "330/333...\n",
            "331/333...\n",
            "332/333...\n",
            "333/333...\n",
            "saving checkpoint to /content/drive/MyDrive/Kontur_task/check/lm_lstm_epoch10.00_0.6058.pt\n",
            "63080/63080 (epoch 10.000), train_loss = 0.63205922, time/batch = 0.0528s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICJdbTTik_-E",
        "outputId": "27e663f3-06d3-4f73-cde5-e4a2ed379def"
      },
      "source": [
        "!wc -l /content/drive/MyDrive/Kontur_task/test.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "581386 /content/drive/MyDrive/Kontur_task/test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c9KFrSFk_7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5adcdcc6-b9e5-4bfc-b01b-3e5e64d37db7"
      },
      "source": [
        "!cat \"/content/drive/MyDrive/test.lower.txt\" | python pytorch-char-rnn-truecase/truecase.py /content/drive/MyDrive/lm_lstm_epoch10.00_0.6058.pt >> /content/drive/MyDrive/result.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using CUDA on GPU 0 ...\n",
            "creating an lstm...\n",
            "performing document-level truecasing...\n",
            "memory is carried over to the next line\n",
            "num characters:  48% 5124386/10769074 [3:32:02<7:52:36, 199.06it/s]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}